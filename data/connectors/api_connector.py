# data/connectors/api_connector.py - å¢å¼ºç‰ˆ
"""
ğŸš€ AIé©±åŠ¨çš„æ™ºèƒ½APIè¿æ¥å™¨ - å¢å¼ºç‰ˆ
åœ¨åŸæœ‰åŠŸèƒ½åŸºç¡€ä¸Šæ–°å¢ï¼š
- ç¬¬8ä¸ªAPIæ”¯æŒ (äº§å“åŒºé—´åˆ°æœŸæ•°æ®)
- æ™ºèƒ½æŸ¥è¯¢ç±»å‹è¯†åˆ«å’ŒAPIç»„åˆé€‰æ‹©
- AIæ•°æ®éªŒè¯å’Œé¢„å¤„ç†
- ä¸ºåˆ†æä¼˜åŒ–çš„æ•°æ®æ ¼å¼è½¬æ¢

å¢å¼ºç‰¹ç‚¹ï¼š
- ğŸ§  AIé©±åŠ¨çš„æ•°æ®è·å–ç­–ç•¥
- ğŸ” æ™ºèƒ½æ•°æ®è´¨é‡æ£€æŸ¥
- âš¡ ä¼˜åŒ–çš„æ•°æ®é¢„å¤„ç†æµç¨‹
- ğŸ“Š åˆ†æå‹å¥½çš„æ•°æ®æ ¼å¼
"""

import requests
import asyncio
import aiohttp
import logging
from typing import Dict, Any, List, Optional, Union
from datetime import datetime, timedelta
import json
import time
from functools import wraps
import hashlib

# å¯¼å…¥æˆ‘ä»¬åˆšå†™çš„å·¥å…·ç±»
from utils.helpers.date_utils import DateUtils, create_date_utils
from utils.helpers.validation_utils import ValidationUtils, create_validation_utils, ValidationLevel

logger = logging.getLogger(__name__)


class QueryType:
    """æŸ¥è¯¢ç±»å‹å¸¸é‡"""
    REALTIME = "realtime"  # å®æ—¶çŠ¶æ€æŸ¥è¯¢
    HISTORICAL = "historical"  # å†å²è¶‹åŠ¿åˆ†æ
    EXPIRY = "expiry"  # åˆ°æœŸæ•°æ®åˆ†æ
    USER_ANALYSIS = "user_analysis"  # ç”¨æˆ·è¡Œä¸ºåˆ†æ
    PREDICTION = "prediction"  # é¢„æµ‹åˆ†æ
    COMPREHENSIVE = "comprehensive"  # ç»¼åˆåˆ†æ


class APIConnector:
    """
    ğŸš€ AIé©±åŠ¨çš„æ™ºèƒ½APIè¿æ¥å™¨ - å¢å¼ºç‰ˆ

    æ–°å¢åŠŸèƒ½ï¼š
    1. AIé©±åŠ¨çš„æŸ¥è¯¢ç­–ç•¥
    2. æ™ºèƒ½æ•°æ®éªŒè¯å’Œé¢„å¤„ç†
    3. åˆ†æä¼˜åŒ–çš„æ•°æ®æ ¼å¼
    4. ç¬¬8ä¸ªAPIå®Œæ•´æ”¯æŒ
    """

    def __init__(self, config: Optional[Dict] = None, claude_client=None, gpt_client=None):
        """
        åˆå§‹åŒ–å¢å¼ºç‰ˆAPIè¿æ¥å™¨

        Args:
            config: APIé…ç½®
            claude_client: Claudeå®¢æˆ·ç«¯ï¼Œç”¨äºæ™ºèƒ½æŸ¥è¯¢åˆ†æ
            gpt_client: GPTå®¢æˆ·ç«¯ï¼Œç”¨äºæ•°æ®éªŒè¯
        """
        # ä¿ç•™åŸæœ‰é…ç½®é€»è¾‘
        self.config = config or self._load_default_config()
        self.base_url = self.config.get('base_url', 'https://api2.3foxzthtdgfy.com')
        self.api_key = self.config.get('api_key', 'f22bf0ec9c61dce227d8f5d64998e883')

        # å¹¶å‘æ§åˆ¶
        self.semaphore = asyncio.Semaphore(self.config.get('max_concurrent', 10))
        self.session = None

        # ç¼“å­˜ç®¡ç†
        self.cache = {}
        self.cache_ttl = self.config.get('cache_ttl', 300)  # 5åˆ†é’Ÿç¼“å­˜

        # ç†”æ–­å™¨çŠ¶æ€
        self.circuit_breaker = {
            'failure_count': 0,
            'last_failure_time': None,
            'state': 'closed'  # closed, open, half_open
        }

        # ğŸ†• AIå¢å¼ºåŠŸèƒ½
        self.claude_client = claude_client
        self.gpt_client = gpt_client
        self.date_utils = create_date_utils(claude_client)
        self.validator = create_validation_utils(claude_client, gpt_client)

        # ğŸ†• æ™ºèƒ½æŸ¥è¯¢ç»Ÿè®¡
        self.query_stats = {
            'total_queries': 0,
            'ai_optimized_queries': 0,
            'cache_hits': 0,
            'validation_failures': 0
        }

        logger.info("Enhanced APIConnector initialized with AI capabilities")

    def _load_default_config(self) -> Dict:
        """åŠ è½½é»˜è®¤é…ç½®"""
        return {
            'base_url': 'https://api2.3foxzthtdgfy.com',
            'api_key': 'f22bf0ec9c61dce227d8f5d64998e883',
            'max_concurrent': 10,
            'timeout': 30,
            'max_retries': 3,
            'retry_delay': 1.0,
            'cache_ttl': 300,
            'circuit_breaker_threshold': 5,
            'circuit_breaker_timeout': 60,
            # ğŸ†• AIå¢å¼ºé…ç½®
            'enable_ai_validation': True,
            'enable_smart_caching': True,
            'data_quality_threshold': 0.8
        }

    # ============= ä¿ç•™åŸæœ‰æ ¸å¿ƒæ–¹æ³• (ç•¥ä½œå¢å¼º) =============

    async def _get_session(self):
        """è·å–æˆ–åˆ›å»ºaiohttpä¼šè¯"""
        try:
            if self.session is None or self.session.closed:
                # æ£€æŸ¥äº‹ä»¶å¾ªç¯æ˜¯å¦æ­£åœ¨è¿è¡Œ
                try:
                    loop = asyncio.get_running_loop()
                    if loop.is_closed():
                        raise RuntimeError("Event loop is closed")
                except RuntimeError:
                    raise RuntimeError("No running event loop")
                    
                timeout = aiohttp.ClientTimeout(total=self.config.get('timeout', 30))
                self.session = aiohttp.ClientSession(timeout=timeout)
            return self.session
        except Exception as e:
            logger.error(f"Failed to get or create session: {str(e)}")
            raise

    def _generate_cache_key(self, endpoint: str, params: Dict = None) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = f"{endpoint}_{params or {} }"
        return hashlib.md5(key_data.encode()).hexdigest()

    def _is_cache_valid(self, cache_entry: Dict) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        return time.time() - cache_entry['timestamp'] < self.cache_ttl

    def _should_bypass_circuit_breaker(self) -> bool:
        """æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€"""
        if self.circuit_breaker['state'] == 'closed':
            return True
        elif self.circuit_breaker['state'] == 'open':
            if (time.time() - self.circuit_breaker['last_failure_time'] >
                    self.config.get('circuit_breaker_timeout', 60)):
                self.circuit_breaker['state'] = 'half_open'
                return True
            return False
        else:  # half_open
            return True

    def _update_circuit_breaker(self, success: bool):
        """æ›´æ–°ç†”æ–­å™¨çŠ¶æ€"""
        if success:
            if self.circuit_breaker['state'] == 'half_open':
                self.circuit_breaker['state'] = 'closed'
            self.circuit_breaker['failure_count'] = 0
        else:
            self.circuit_breaker['failure_count'] += 1
            self.circuit_breaker['last_failure_time'] = time.time()

            threshold = self.config.get('circuit_breaker_threshold', 5)
            if self.circuit_breaker['failure_count'] >= threshold:
                self.circuit_breaker['state'] = 'open'
                logger.warning(f"Circuit breaker opened due to {threshold} failures")

    async def _make_request(self, endpoint: str, params: Dict = None,
                            use_cache: bool = True, enable_ai_validation: bool = True) -> Dict[str, Any]:
        """
        ğŸš€ å¢å¼ºç‰ˆHTTPè¯·æ±‚æ–¹æ³•
        æ–°å¢AIéªŒè¯å’Œæ™ºèƒ½ç¼“å­˜
        """
        self.query_stats['total_queries'] += 1

        # æ£€æŸ¥ç†”æ–­å™¨
        if not self._should_bypass_circuit_breaker():
            return {
                "success": False,
                "message": "Service temporarily unavailable (circuit breaker open)"
            }

        # ğŸ†• æ™ºèƒ½ç¼“å­˜æ£€æŸ¥
        cache_key = self._generate_cache_key(endpoint, params)
        if use_cache and self.config.get('enable_smart_caching', True):
            cached_result = await self._smart_cache_lookup(cache_key, endpoint)
            if cached_result:
                self.query_stats['cache_hits'] += 1
                logger.info(f"Smart cache hit for {endpoint}")
                return cached_result

        # å‡†å¤‡è¯·æ±‚å‚æ•°
        request_params = {'key': self.api_key}
        if params:
            request_params.update(params)

        url = f"{self.base_url}{endpoint}"

        # å¹¶å‘æ§åˆ¶
        async with self.semaphore:
            try:
                session = await self._get_session()
            except RuntimeError as e:
                if "Event loop is closed" in str(e):
                    logger.error(f"Cannot make request to {endpoint}: Event loop is closed")
                    return {
                        "success": False,
                        "message": "Cannot process request: Event loop is closed"
                    }
                raise

            # é‡è¯•æœºåˆ¶
            max_retries = self.config.get('max_retries', 3)
            retry_delay = self.config.get('retry_delay', 1.0)

            for attempt in range(max_retries + 1):
                try:
                    logger.info(f"Making request to {endpoint} (attempt {attempt + 1})")

                    async with session.get(url, params=request_params) as response:
                        if response.status == 200:
                            data = await response.json()

                            # éªŒè¯å“åº”æ ¼å¼
                            if isinstance(data, dict) and 'result' in data:
                                result = {
                                    "success": data.get('result', False),
                                    "data": data.get('data'),
                                    "status": data.get('status', 0),
                                    "endpoint": endpoint,
                                    "request_params": request_params,
                                    "timestamp": datetime.now().isoformat()
                                }

                                if not result["success"]:
                                    result["message"] = f"API returned error: status={data.get('status', 'unknown')}"
                                else:
                                    # ğŸ†• AIæ•°æ®éªŒè¯
                                    if enable_ai_validation and self.config.get('enable_ai_validation', True):
                                        validation_result = await self._ai_validate_response(result, endpoint)
                                        result["validation"] = validation_result

                                        if not validation_result.get("is_valid", True):
                                            self.query_stats['validation_failures'] += 1
                                            logger.warning(f"Data validation failed for {endpoint}")
                            else:
                                result = {
                                    "success": False,
                                    "message": "Invalid API response format"
                                }

                            # æ›´æ–°ç†”æ–­å™¨ï¼ˆæˆåŠŸï¼‰
                            self._update_circuit_breaker(True)

                            # ğŸ†• æ™ºèƒ½ç¼“å­˜
                            if result["success"] and use_cache:
                                await self._smart_cache_store(cache_key, result, endpoint)

                            return result

                        else:
                            raise aiohttp.ClientError(f"HTTP {response.status}")

                except asyncio.CancelledError:
                    logger.warning(f"Request to {endpoint} was cancelled")
                    return {
                        "success": False,
                        "message": "Request cancelled"
                    }
                except RuntimeError as e:
                    if "Event loop is closed" in str(e):
                        logger.error(f"Cannot continue request to {endpoint}: Event loop is closed")
                        return {
                            "success": False,
                            "message": "Cannot process request: Event loop is closed"
                        }
                    logger.warning(f"Request attempt {attempt + 1} failed: {str(e)}")
                except Exception as e:
                    logger.warning(f"Request attempt {attempt + 1} failed: {str(e)}")

                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                    if attempt == max_retries:
                        self._update_circuit_breaker(False)
                        return {
                            "success": False,
                            "message": f"API request failed after {max_retries + 1} attempts: {str(e)}"
                        }

                    # ç­‰å¾…åé‡è¯•
                    try:
                        await asyncio.sleep(retry_delay * (2 ** attempt))
                    except asyncio.CancelledError:
                        logger.warning(f"Sleep before retry was cancelled for {endpoint}")
                        return {
                            "success": False,
                            "message": "Request retry cancelled"
                        }

    # ============= ğŸ†• æ–°å¢ç¬¬8ä¸ªAPIæ–¹æ³• =============

    async def intelligent_data_fetch_enhanced(self, query_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ§  å¢å¼ºç‰ˆæ™ºèƒ½æ•°æ®è·å– - åŸºäºClaudeçš„ç²¾ç¡®åˆ†æ
        """
        try:
            logger.info("ğŸ§  å¼€å§‹å¢å¼ºç‰ˆæ™ºèƒ½æ•°æ®è·å–")

            api_calls = query_analysis.get("execution_plan", {}).get("api_calls", [])
            time_entities = query_analysis.get("query_understanding", {}).get("time_entities", [])

            # æŒ‰ä¼˜å…ˆçº§æ’åºAPIè°ƒç”¨
            sorted_calls = sorted(api_calls, key=lambda x: x.get("priority", 999))

            # å¹¶è¡Œæ‰§è¡ŒAPIè°ƒç”¨
            tasks = []
            task_metadata = []

            for api_call in sorted_calls:
                method = api_call.get("api_method")
                params = api_call.get("params", {})

                # åŠ¨æ€è°ƒç”¨å¯¹åº”çš„æ–¹æ³•
                if hasattr(self, method):
                    api_method = getattr(self, method)
                    if params:
                        task = api_method(**params)
                    else:
                        task = api_method()
                    tasks.append(task)
                    task_metadata.append({
                        "method": method,
                        "params": params,
                        "reason": api_call.get("reason", "")
                    })

            # æ‰§è¡Œæ‰€æœ‰APIè°ƒç”¨
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # æ•´ç†ç»“æœ
            organized_data = {}
            for i, (result, metadata) in enumerate(zip(results, task_metadata)):
                if not isinstance(result, Exception) and result.get("success"):
                    organized_data[metadata["method"]] = {
                        "data": result.get("data"),
                        "metadata": metadata,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    logger.error(f"APIè°ƒç”¨å¤±è´¥: {metadata['method']}, é”™è¯¯: {result}")

            return {
                "success": True,
                "data_type": "intelligent_package",
                "organized_data": organized_data,
                "query_analysis": query_analysis,
                "execution_summary": {
                    "total_api_calls": len(tasks),
                    "successful_calls": len(organized_data),
                    "failed_calls": len(tasks) - len(organized_data)
                },
                "package_timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"âŒ å¢å¼ºç‰ˆæ™ºèƒ½æ•°æ®è·å–å¤±è´¥: {str(e)}")
            return await self._fetch_basic_data_package()
    async def get_product_end_interval(self, start_date: str, end_date: str) -> Dict[str, Any]:
        """
        ğŸ†• è·å–åŒºé—´äº§å“åˆ°æœŸæ•°æ® - ç¬¬8ä¸ªAPI

        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYYMMDD)
            end_date: ç»“æŸæ—¥æœŸ (YYYYMMDD)

        Returns:
            Dict[str, Any]: åŒºé—´åˆ°æœŸæ•°æ®
        """
        try:
            logger.info(f"ğŸ” è·å–åŒºé—´åˆ°æœŸæ•°æ®: {start_date} åˆ° {end_date}")

            # ğŸ†• ä½¿ç”¨AIéªŒè¯æ—¥æœŸå‚æ•°
            if self.date_utils:
                start_valid = self.date_utils.validate_api_date_format(start_date)
                end_valid = self.date_utils.validate_api_date_format(end_date)

                if not start_valid or not end_valid:
                    return {
                        "success": False,
                        "message": f"æ—¥æœŸæ ¼å¼é”™è¯¯: start={start_date}, end={end_date}"
                    }

            params = {
                'start_date': start_date,
                'end_date': end_date
            }

            result = await self._make_request('/api/sta/product_end_interval', params)

            # ğŸ†• ä¸ºåŒºé—´æ•°æ®æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            if result.get("success") and result.get("data"):
                result["data"] = await self._enhance_interval_data(result["data"], start_date, end_date)

            return result

        except Exception as e:
            logger.error(f"âŒ åŒºé—´åˆ°æœŸæ•°æ®è·å–å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": f"åŒºé—´æ•°æ®è·å–å¤±è´¥: {str(e)}"
            }

    async def _enhance_interval_data(self, interval_data: Dict[str, Any],
                                     start_date: str, end_date: str) -> Dict[str, Any]:
        """å¢å¼ºåŒºé—´æ•°æ®ï¼Œæ·»åŠ ç»Ÿè®¡ä¿¡æ¯"""

        enhanced_data = interval_data.copy()

        try:
            # è®¡ç®—æ—¥æœŸèŒƒå›´
            start_dt = datetime.strptime(start_date, "%Y%m%d")
            end_dt = datetime.strptime(end_date, "%Y%m%d")
            total_days = (end_dt - start_dt).days + 1

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            total_amount = float(interval_data.get("åˆ°æœŸé‡‘é¢", 0))
            total_quantity = int(interval_data.get("åˆ°æœŸæ•°é‡", 0))

            enhanced_data["interval_stats"] = {
                "total_days": total_days,
                "daily_average_amount": total_amount / total_days if total_days > 0 else 0,
                "daily_average_quantity": total_quantity / total_days if total_days > 0 else 0,
                "start_date_formatted": start_dt.strftime("%Y-%m-%d"),
                "end_date_formatted": end_dt.strftime("%Y-%m-%d")
            }

            # ğŸ†• å¦‚æœæœ‰äº§å“åˆ—è¡¨ï¼Œè®¡ç®—æ¯ä¸ªäº§å“çš„å¹³å‡åˆ°æœŸé‡
            if "äº§å“åˆ—è¡¨" in interval_data:
                for product in enhanced_data["äº§å“åˆ—è¡¨"]:
                    product_amount = float(product.get("åˆ°æœŸé‡‘é¢", 0))
                    product_quantity = int(product.get("åˆ°æœŸæ•°é‡", 0))

                    product["daily_stats"] = {
                        "avg_daily_amount": product_amount / total_days if total_days > 0 else 0,
                        "avg_daily_quantity": product_quantity / total_days if total_days > 0 else 0
                    }

        except Exception as e:
            logger.warning(f"åŒºé—´æ•°æ®å¢å¼ºå¤±è´¥: {str(e)}")

        return enhanced_data

    # ============= ğŸ†• AIé©±åŠ¨çš„æ™ºèƒ½æ•°æ®è·å– =============

    async def intelligent_data_fetch(self, query_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ§  AIé©±åŠ¨çš„æ™ºèƒ½æ•°æ®è·å–
        æ ¹æ®æŸ¥è¯¢åˆ†æç»“æœï¼Œæ™ºèƒ½é€‰æ‹©å’Œç»„åˆAPIè°ƒç”¨

        Args:
            query_analysis: æŸ¥è¯¢åˆ†æç»“æœ (æ¥è‡ªquery_parser)

        Returns:
            Dict[str, Any]: æ™ºèƒ½ç»„åˆçš„æ•°æ®ç»“æœ
        """
        try:
            logger.info("ğŸ§  å¼€å§‹æ™ºèƒ½æ•°æ®è·å–")
            self.query_stats['ai_optimized_queries'] += 1

            query_type = query_analysis.get("query_type", "realtime")
            data_requirements = query_analysis.get("data_requirements", {})
            time_range = query_analysis.get("time_range", {})

            # ğŸ†• æ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©APIç»„åˆç­–ç•¥
            if query_type == QueryType.REALTIME:
                return await self._fetch_realtime_data_package()
            elif query_type == QueryType.HISTORICAL:
                return await self._fetch_historical_data_package(time_range)
            elif query_type == QueryType.EXPIRY:
                return await self._fetch_expiry_data_package(time_range)
            elif query_type == QueryType.USER_ANALYSIS:
                return await self._fetch_user_analysis_package(time_range)
            elif query_type == QueryType.PREDICTION:
                return await self._fetch_prediction_data_package(time_range)
            elif query_type == QueryType.COMPREHENSIVE:
                return await self._fetch_comprehensive_data_package(time_range)
            else:
                # é»˜è®¤è·å–åŸºç¡€æ•°æ®
                return await self._fetch_basic_data_package()

        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½æ•°æ®è·å–å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": f"æ™ºèƒ½æ•°æ®è·å–å¤±è´¥: {str(e)}",
                "fallback_data": await self._fetch_basic_data_package()
            }

    async def _fetch_realtime_data_package(self) -> Dict[str, Any]:
        """è·å–å®æ—¶æ•°æ®åŒ…"""
        logger.info("ğŸ“Š è·å–å®æ—¶æ•°æ®åŒ…")

        # å¹¶è¡Œè·å–å®æ—¶ç›¸å…³æ•°æ®
        tasks = [
            self.get_system_data(),
            self.get_expiring_products_today(),
            self.get_expiring_products_tomorrow()
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        return {
            "success": True,
            "data_type": "realtime_package",
            "system_data": results[0] if len(results) > 0 and not isinstance(results[0], Exception) else None,
            "today_expiry": results[1] if len(results) > 1 and not isinstance(results[1], Exception) else None,
            "tomorrow_expiry": results[2] if len(results) > 2 and not isinstance(results[2], Exception) else None,
            "package_timestamp": datetime.now().isoformat()
        }

    async def _fetch_historical_data_package(self, time_range: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–å†å²æ•°æ®åŒ…"""
        logger.info(f"ğŸ“ˆ è·å–å†å²æ•°æ®åŒ…: {time_range}")

        start_date = time_range.get("start_date", "")
        end_date = time_range.get("end_date", "")

        # è½¬æ¢æ—¥æœŸæ ¼å¼ä¸ºAPIæ ¼å¼
        if self.date_utils:
            start_api = self.date_utils.date_to_api_format(start_date)
            end_api = self.date_utils.date_to_api_format(end_date)
        else:
            start_api = start_date.replace("-", "")
            end_api = end_date.replace("-", "")

        # å¹¶è¡Œè·å–å†å²æ•°æ®
        tasks = [
            self.get_date_range_data(start_api, end_api, ["daily"]),
            self.get_date_range_data(start_api, end_api, ["user_daily"]),
            self.get_system_data()  # å½“å‰çŠ¶æ€ä½œä¸ºå¯¹æ¯”
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        return {
            "success": True,
            "data_type": "historical_package",
            "daily_data": results[0] if len(results) > 0 and not isinstance(results[0], Exception) else None,
            "user_daily_data": results[1] if len(results) > 1 and not isinstance(results[1], Exception) else None,
            "current_state": results[2] if len(results) > 2 and not isinstance(results[2], Exception) else None,
            "time_range": {
                "start_date": start_date,
                "end_date": end_date,
                "api_format": {"start": start_api, "end": end_api}
            },
            "package_timestamp": datetime.now().isoformat()
        }

    async def _fetch_expiry_data_package(self, time_range: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–åˆ°æœŸæ•°æ®åŒ…"""
        logger.info(f"â° è·å–åˆ°æœŸæ•°æ®åŒ…: {time_range}")

        start_date = time_range.get("start_date", "")
        end_date = time_range.get("end_date", "")

        # è½¬æ¢æ—¥æœŸæ ¼å¼
        if self.date_utils:
            start_api = self.date_utils.date_to_api_format(start_date)
            end_api = self.date_utils.date_to_api_format(end_date)
        else:
            start_api = start_date.replace("-", "")
            end_api = end_date.replace("-", "")

        # å¹¶è¡Œè·å–åˆ°æœŸç›¸å…³æ•°æ®
        tasks = [
            self.get_product_end_interval(start_api, end_api),  # ğŸ†• ä½¿ç”¨æ–°API
            self.get_product_data(),  # äº§å“è¯¦æƒ…
            self.get_system_data()  # å½“å‰çŠ¶æ€
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        return {
            "success": True,
            "data_type": "expiry_package",
            "interval_expiry": results[0] if len(results) > 0 and not isinstance(results[0], Exception) else None,
            "product_details": results[1] if len(results) > 1 and not isinstance(results[1], Exception) else None,
            "current_system": results[2] if len(results) > 2 and not isinstance(results[2], Exception) else None,
            "analysis_period": {
                "start_date": start_date,
                "end_date": end_date
            },
            "package_timestamp": datetime.now().isoformat()
        }

    async def _fetch_comprehensive_data_package(self, time_range: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–ç»¼åˆæ•°æ®åŒ… (æ‰€æœ‰æ•°æ®)"""
        logger.info(f"ğŸ¯ è·å–ç»¼åˆæ•°æ®åŒ…: {time_range}")

        # è·å–å„ç§æ•°æ®åŒ…
        realtime_task = self._fetch_realtime_data_package()
        historical_task = self._fetch_historical_data_package(time_range)
        expiry_task = self._fetch_expiry_data_package(time_range)

        packages = await asyncio.gather(realtime_task, historical_task, expiry_task, return_exceptions=True)

        return {
            "success": True,
            "data_type": "comprehensive_package",
            "realtime_package": packages[0] if len(packages) > 0 and not isinstance(packages[0], Exception) else None,
            "historical_package": packages[1] if len(packages) > 1 and not isinstance(packages[1], Exception) else None,
            "expiry_package": packages[2] if len(packages) > 2 and not isinstance(packages[2], Exception) else None,
            "package_metadata": {
                "total_api_calls": sum(self._count_api_calls(pkg) for pkg in packages if isinstance(pkg, dict)),
                "data_completeness": self._calculate_data_completeness(packages),
                "generation_time": datetime.now().isoformat()
            }
        }

    # ============= ğŸ†• AIæ•°æ®éªŒè¯å’Œæ™ºèƒ½ç¼“å­˜ =============

    async def _ai_validate_response(self, response: Dict[str, Any], endpoint: str) -> Dict[str, Any]:
        """AIéªŒè¯APIå“åº”"""

        if not self.validator:
            return {"is_valid": True, "confidence": 0.5, "method": "no_validator"}

        try:
            # æ ¹æ®endpointç¡®å®šéªŒè¯çº§åˆ«
            validation_level = ValidationLevel.STANDARD
            if "product_end" in endpoint or "system" in endpoint:
                validation_level = ValidationLevel.AI_ENHANCED

            validation_result = await self.validator.validate_api_response(
                response,
                expected_fields=self._get_expected_fields(endpoint)
            )

            return {
                "is_valid": validation_result.is_valid,
                "confidence": validation_result.overall_score,
                "issues_count": len(validation_result.issues),
                "validation_level": validation_level.value,
                "method": "ai_enhanced"
            }

        except Exception as e:
            logger.error(f"AIéªŒè¯å¤±è´¥: {str(e)}")
            return {"is_valid": True, "confidence": 0.3, "error": str(e)}

    async def _smart_cache_lookup(self, cache_key: str, endpoint: str) -> Optional[Dict[str, Any]]:
        """æ™ºèƒ½ç¼“å­˜æŸ¥æ‰¾"""

        if cache_key not in self.cache:
            return None

        cache_entry = self.cache[cache_key]

        # ğŸ†• æ ¹æ®æ•°æ®ç±»å‹è°ƒæ•´ç¼“å­˜æœ‰æ•ˆæœŸ
        dynamic_ttl = self._calculate_dynamic_ttl(endpoint)

        if time.time() - cache_entry['timestamp'] < dynamic_ttl:
            # ğŸ†• ç¼“å­˜å‘½ä¸­æ—¶è¿›è¡Œæ•°æ®æ–°é²œåº¦æ£€æŸ¥
            if await self._is_cached_data_fresh(cache_entry, endpoint):
                return cache_entry['data']

        # æ¸…é™¤è¿‡æœŸç¼“å­˜
        del self.cache[cache_key]
        return None

    async def _smart_cache_store(self, cache_key: str, data: Dict[str, Any], endpoint: str):
        """æ™ºèƒ½ç¼“å­˜å­˜å‚¨"""

        # ğŸ†• åªç¼“å­˜é«˜è´¨é‡æ•°æ®
        if self._should_cache_data(data, endpoint):
            self.cache[cache_key] = {
                'data': data,
                'timestamp': time.time(),
                'endpoint': endpoint,
                'quality_score': await self._calculate_data_quality_score(data)
            }

            # é™åˆ¶ç¼“å­˜å¤§å°
            if len(self.cache) > 1000:
                self._cleanup_cache()

    def _calculate_dynamic_ttl(self, endpoint: str) -> float:
        """æ ¹æ®endpointåŠ¨æ€è®¡ç®—TTL"""

        # ä¸åŒç±»å‹æ•°æ®çš„ç¼“å­˜ç­–ç•¥
        if "system" in endpoint:
            return 60  # ç³»ç»Ÿæ•°æ®1åˆ†é’Ÿ
        elif "day" in endpoint:
            return 300  # æ¯æ—¥æ•°æ®5åˆ†é’Ÿ
        elif "product_end" in endpoint:
            return 180  # åˆ°æœŸæ•°æ®3åˆ†é’Ÿ
        elif "product" in endpoint:
            return 600  # äº§å“æ•°æ®10åˆ†é’Ÿ
        else:
            return self.cache_ttl  # é»˜è®¤TTL

    async def _is_cached_data_fresh(self, cache_entry: Dict[str, Any], endpoint: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ•°æ®æ–°é²œåº¦"""

        # ğŸ†• å¯¹äºé‡è¦æ•°æ®ï¼Œå¯ä»¥è¿›è¡Œè½»é‡çº§éªŒè¯
        if "system" in endpoint:
            # ç³»ç»Ÿæ•°æ®å¯ä»¥å¿«é€Ÿæ£€æŸ¥æ—¶é—´æˆ³
            cached_data = cache_entry.get('data', {})
            cached_timestamp = cached_data.get('timestamp', '')

            try:
                cache_time = datetime.fromisoformat(cached_timestamp.replace('Z', '+00:00'))
                now = datetime.now()

                # å¦‚æœç¼“å­˜æ•°æ®è¶…è¿‡1å°æ—¶ï¼Œå¯èƒ½éœ€è¦æ›´æ–°
                if (now - cache_time).total_seconds() > 3600:
                    return False
            except:
                pass

        return True

    def _should_cache_data(self, data: Dict[str, Any], endpoint: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç¼“å­˜æ•°æ®"""

        # åŸºç¡€æ£€æŸ¥
        if not data.get("success", False):
            return False

        # æ£€æŸ¥æ•°æ®è´¨é‡é˜ˆå€¼
        validation_info = data.get("validation", {})
        if validation_info.get("confidence", 1.0) < self.config.get('data_quality_threshold', 0.8):
            return False

        return True

    async def _calculate_data_quality_score(self, data: Dict[str, Any]) -> float:
        """è®¡ç®—æ•°æ®è´¨é‡åˆ†æ•°"""

        score = 1.0

        # åŸºç¡€è´¨é‡æ£€æŸ¥
        if not data.get("success", False):
            score -= 0.5

        # éªŒè¯ç»“æœæ£€æŸ¥
        validation_info = data.get("validation", {})
        if validation_info:
            score = min(score, validation_info.get("confidence", 1.0))

        # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        data_content = data.get("data", {})
        if isinstance(data_content, dict) and len(data_content) == 0:
            score -= 0.3

        return max(0.0, score)

    # ============= ğŸ†• ä¿ç•™å¹¶å¢å¼ºåŸæœ‰æ–¹æ³• =============

    async def get_system_data(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿæ¦‚è§ˆæ•°æ® - å¢å¼ºç‰ˆ"""
        result = await self._make_request('/api/sta/system')

        # ğŸ†• ä¸ºç³»ç»Ÿæ•°æ®æ·»åŠ åˆ†æå‹å¥½çš„æ ¼å¼
        if result.get("success") and result.get("data"):
            result["data"] = await self._enhance_system_data(result["data"])

        return result

    async def get_daily_data(self, date: Optional[str] = None) -> Dict[str, Any]:
        """è·å–æ¯æ—¥æ•°æ® - å¢å¼ºç‰ˆ"""
        params = {}
        if date:
            params['date'] = date

        result = await self._make_request('/api/sta/day', params)

        # ğŸ†• ä¸ºæ¯æ—¥æ•°æ®æ·»åŠ è¶‹åŠ¿åˆ†æå‡†å¤‡
        if result.get("success") and result.get("data"):
            result["data"] = await self._enhance_daily_data(result["data"], date)

        return result

    async def _enhance_system_data(self, system_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¢å¼ºç³»ç»Ÿæ•°æ®"""
        enhanced = system_data.copy()

        try:
            # ğŸ†• æ·»åŠ è®¡ç®—å­—æ®µ
            total_balance = float(enhanced.get("æ€»ä½™é¢", 0))
            total_inflow = float(enhanced.get("æ€»å…¥é‡‘", 0))
            total_outflow = float(enhanced.get("æ€»å‡ºé‡‘", 0))

            enhanced["computed_metrics"] = {
                "net_flow": total_inflow - total_outflow,
                "outflow_ratio": (total_outflow / total_inflow) if total_inflow > 0 else 0,
                "balance_utilization": (total_balance / total_inflow) if total_inflow > 0 else 0
            }

            # ğŸ†• ç”¨æˆ·ç»Ÿè®¡å¢å¼º
            user_stats = enhanced.get("ç”¨æˆ·ç»Ÿè®¡", {})
            total_users = user_stats.get("æ€»ç”¨æˆ·æ•°", 0)
            active_users = user_stats.get("æ´»è·ƒç”¨æˆ·æ•°", 0)

            if total_users > 0:
                enhanced["user_metrics"] = {
                    "activity_rate": (active_users / total_users),
                    "avg_balance_per_user": total_balance / total_users,
                    "avg_investment_per_user": float(enhanced.get("æ€»æŠ•èµ„é‡‘é¢", 0)) / total_users
                }

        except Exception as e:
            logger.warning(f"ç³»ç»Ÿæ•°æ®å¢å¼ºå¤±è´¥: {str(e)}")

        return enhanced

    async def _enhance_daily_data(self, daily_data: Dict[str, Any], date: Optional[str]) -> Dict[str, Any]:
        """å¢å¼ºæ¯æ—¥æ•°æ®"""
        enhanced = daily_data.copy()

        try:
            # ğŸ†• æ·»åŠ æ—¥æœŸå…ƒæ•°æ®
            if date and self.date_utils:
                date_info = self.date_utils.get_date_info(
                    self.date_utils.api_format_to_date(date)
                )
                enhanced["date_metadata"] = date_info

            # ğŸ†• æ·»åŠ æ¯”ç‡è®¡ç®—
            inflow = float(enhanced.get("å…¥é‡‘", 0))
            outflow = float(enhanced.get("å‡ºé‡‘", 0))

            enhanced["daily_metrics"] = {
                "net_flow": inflow - outflow,
                "flow_ratio": (inflow / outflow) if outflow > 0 else float('inf'),
                "activity_score": (float(enhanced.get("è´­ä¹°äº§å“æ•°é‡", 0)) +
                                   float(enhanced.get("åˆ°æœŸäº§å“æ•°é‡", 0))) / 2
            }

        except Exception as e:
            logger.warning(f"æ¯æ—¥æ•°æ®å¢å¼ºå¤±è´¥: {str(e)}")

        return enhanced

    # ============= ğŸ†• ä¾¿æ·æ–¹æ³•å’Œå·¥å…·å‡½æ•° =============

    def _get_expected_fields(self, endpoint: str) -> List[str]:
        """è·å–endpointæœŸæœ›çš„å­—æ®µ"""
        field_map = {
            '/api/sta/system': ['æ€»ä½™é¢', 'æ€»å…¥é‡‘', 'æ€»å‡ºé‡‘', 'ç”¨æˆ·ç»Ÿè®¡'],
            '/api/sta/day': ['æ—¥æœŸ', 'æ³¨å†Œäººæ•°', 'å…¥é‡‘', 'å‡ºé‡‘'],
            '/api/sta/product': ['äº§å“æ€»æ•°', 'äº§å“åˆ—è¡¨'],
            '/api/sta/product_end': ['æ—¥æœŸ', 'åˆ°æœŸæ•°é‡', 'åˆ°æœŸé‡‘é¢'],
            '/api/sta/product_end_interval': ['æ—¥æœŸ', 'åˆ°æœŸæ•°é‡', 'åˆ°æœŸé‡‘é¢']
        }
        return field_map.get(endpoint, [])

    def _count_api_calls(self, package: Dict[str, Any]) -> int:
        """è®¡ç®—æ•°æ®åŒ…ä¸­çš„APIè°ƒç”¨æ¬¡æ•°"""
        if not isinstance(package, dict):
            return 0

        count = 0
        for key, value in package.items():
            if isinstance(value, dict) and value.get("endpoint"):
                count += 1
            elif isinstance(value, dict):
                count += self._count_api_calls(value)

        return count

    def _calculate_data_completeness(self, packages: List[Any]) -> float:
        """è®¡ç®—æ•°æ®å®Œæ•´æ€§å¾—åˆ†"""
        if not packages:
            return 0.0

        successful_packages = sum(1 for pkg in packages
                                  if isinstance(pkg, dict) and pkg.get("success", False))

        return successful_packages / len(packages)

    def _cleanup_cache(self):
        """æ¸…ç†ç¼“å­˜"""
        # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
        if self.cache:
            oldest_key = min(self.cache.keys(),
                             key=lambda k: self.cache[k]['timestamp'])
            del self.cache[oldest_key]

    async def _fetch_basic_data_package(self) -> Dict[str, Any]:
        """è·å–åŸºç¡€æ•°æ®åŒ… (é™çº§æ–¹æ¡ˆ)"""
        logger.info("ğŸ“¦ è·å–åŸºç¡€æ•°æ®åŒ…")

        system_data = await self.get_system_data()
        return {
            "success": True,
            "data_type": "basic_package",
            "system_data": system_data,
            "package_timestamp": datetime.now().isoformat()
        }

    async def _fetch_user_analysis_package(self, time_range: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·åˆ†ææ•°æ®åŒ…"""
        logger.info("ğŸ‘¥ è·å–ç”¨æˆ·åˆ†ææ•°æ®åŒ…")

        tasks = [
            self.get_user_data(page=1),
            self.get_system_data()
        ]

        # å¦‚æœæœ‰æ—¶é—´èŒƒå›´ï¼Œæ·»åŠ ç”¨æˆ·æ¯æ—¥æ•°æ®
        if time_range.get("start_date"):
            start_api = self.date_utils.date_to_api_format(time_range["start_date"])
            end_api = self.date_utils.date_to_api_format(time_range["end_date"])
            tasks.append(self.get_date_range_data(start_api, end_api, ["user_daily"]))

        results = await asyncio.gather(*tasks, return_exceptions=True)

        return {
            "success": True,
            "data_type": "user_analysis_package",
            "user_data": results[0] if len(results) > 0 and not isinstance(results[0], Exception) else None,
            "system_data": results[1] if len(results) > 1 and not isinstance(results[1], Exception) else None,
            "user_daily_data": results[2] if len(results) > 2 and not isinstance(results[2], Exception) else None,
            "package_timestamp": datetime.now().isoformat()
        }

    async def _fetch_prediction_data_package(self, time_range: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–é¢„æµ‹åˆ†ææ•°æ®åŒ…"""
        logger.info("ğŸ”® è·å–é¢„æµ‹åˆ†ææ•°æ®åŒ…")

        # é¢„æµ‹éœ€è¦æ›´é•¿çš„å†å²æ•°æ®
        historical_package = await self._fetch_historical_data_package(time_range)
        realtime_package = await self._fetch_realtime_data_package()

        return {
            "success": True,
            "data_type": "prediction_package",
            "historical_data": historical_package,
            "current_snapshot": realtime_package,
            "prediction_metadata": {
                "historical_depth": time_range,
                "data_quality": "enhanced_for_prediction"
            },
            "package_timestamp": datetime.now().isoformat()
        }

    # ============= ä¿ç•™åŸæœ‰æ–¹æ³• (å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜) =============

    async def get_product_data(self) -> Dict[str, Any]:
        """è·å–äº§å“æ•°æ®"""
        return await self._make_request('/api/sta/product')

    async def get_user_daily_data(self, date: Optional[str] = None) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·æ¯æ—¥æ•°æ®"""
        params = {}
        if date:
            params['date'] = date
        return await self._make_request('/api/sta/user_daily', params)

    async def get_user_data(self, page: int = 1) -> Dict[str, Any]:
        """è·å–è¯¦ç»†ç”¨æˆ·æ•°æ®"""
        params = {'page': page}
        return await self._make_request('/api/sta/user', params)

    async def get_product_end_data(self, date: str) -> Dict[str, Any]:
        """è·å–äº§å“åˆ°æœŸæ•°æ®"""
        params = {'date': date}
        return await self._make_request('/api/sta/product_end', params)

    # ğŸ†• å¢å¼ºç‰ˆä¾¿æ·æ–¹æ³•
    async def get_expiring_products_today(self) -> Dict[str, Any]:
        """è·å–ä»Šæ—¥åˆ°æœŸäº§å“"""
        today = datetime.now().strftime('%Y%m%d')
        return await self.get_product_end_data(today)

    async def get_expiring_products_tomorrow(self) -> Dict[str, Any]:
        """è·å–æ˜æ—¥åˆ°æœŸäº§å“"""
        tomorrow = (datetime.now() + timedelta(days=1)).strftime('%Y%m%d')
        return await self.get_product_end_data(tomorrow)

    async def get_expiring_products_week(self) -> Dict[str, Any]:
        """è·å–æœ¬å‘¨åˆ°æœŸäº§å“"""
        today = datetime.now()
        week_end = today + timedelta(days=6)
        return await self.get_product_end_interval(
            today.strftime('%Y%m%d'),
            week_end.strftime('%Y%m%d')
        )

    async def get_expiring_products_range(self, start_date: str, end_date: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šèŒƒå›´åˆ°æœŸäº§å“"""
        return await self.get_product_end_interval(start_date, end_date)

    # ============= ä¿ç•™åŸæœ‰çš„æ‰¹é‡æ•°æ®è·å–æ–¹æ³• =============

    async def get_date_range_data(self, start_date: str, end_date: str,
                                  data_types: List[str] = None) -> Dict[str, Any]:
        """
        æ™ºèƒ½è·å–æ—¥æœŸèŒƒå›´æ•°æ® - ä¿ç•™åŸæœ‰é€»è¾‘ï¼Œå¢åŠ AIéªŒè¯
        """
        logger.info(f"Getting range data from {start_date} to {end_date}")

        try:
            # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨
            dates = self._generate_date_list(start_date, end_date)
            logger.info(f"Generated {len(dates)} dates for range query")

            # é»˜è®¤æ•°æ®ç±»å‹
            if data_types is None:
                data_types = ['daily', 'product_end']

            # å‡†å¤‡æ‰¹é‡ä»»åŠ¡
            tasks = []
            task_metadata = []

            for date in dates:
                for data_type in data_types:
                    if data_type == 'daily':
                        task = self.get_daily_data(date)
                        tasks.append(task)
                        task_metadata.append({'type': 'daily', 'date': date})
                    elif data_type == 'product_end':
                        task = self.get_product_end_data(date)
                        tasks.append(task)
                        task_metadata.append({'type': 'product_end', 'date': date})
                    elif data_type == 'user_daily':
                        task = self.get_user_daily_data(date)
                        tasks.append(task)
                        task_metadata.append({'type': 'user_daily', 'date': date})

            logger.info(f"Executing {len(tasks)} API calls concurrently")

            # åˆ†æ‰¹æ‰§è¡Œï¼ˆé¿å…è¿‡å¤šå¹¶å‘ï¼‰
            batch_size = self.config.get('batch_size', 20)
            all_results = []

            for i in range(0, len(tasks), batch_size):
                batch_tasks = tasks[i:i + batch_size]
                batch_metadata = task_metadata[i:i + batch_size]

                logger.info(f"Processing batch {i // batch_size + 1}, size: {len(batch_tasks)}")

                # æ‰§è¡Œæ‰¹æ¬¡
                batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)

                # å¤„ç†ç»“æœ
                for result, metadata in zip(batch_results, batch_metadata):
                    if isinstance(result, Exception):
                        logger.error(f"Task failed: {metadata}, error: {str(result)}")
                        all_results.append({
                            'metadata': metadata,
                            'success': False,
                            'error': str(result)
                        })
                    else:
                        all_results.append({
                            'metadata': metadata,
                            'success': result.get('success', False),
                            'data': result.get('data') if result.get('success') else None,
                            'error': result.get('message') if not result.get('success') else None
                        })

                # æ‰¹æ¬¡é—´éš”ï¼Œé¿å…APIé™åˆ¶
                if i + batch_size < len(tasks):
                    await asyncio.sleep(0.5)

            # æ•´ç†ç»“æœ
            organized_results = self._organize_range_results(all_results, dates, data_types)

            success_count = sum(1 for r in all_results if r['success'])
            total_count = len(all_results)

            return {
                "success": True,
                "data": organized_results,
                "metadata": {
                    "date_range": {
                        "start_date": start_date,
                        "end_date": end_date,
                        "total_days": len(dates)
                    },
                    "data_types": data_types,
                    "execution_stats": {
                        "total_api_calls": total_count,
                        "successful_calls": success_count,
                        "success_rate": success_count / total_count if total_count > 0 else 0
                    }
                }
            }

        except Exception as e:
            logger.error(f"Date range data retrieval failed: {str(e)}")
            return {
                "success": False,
                "message": f"Failed to retrieve date range data: {str(e)}"
            }

    def _generate_date_list(self, start_date: str, end_date: str) -> List[str]:
        """ç”Ÿæˆæ—¥æœŸåˆ—è¡¨"""
        try:
            start_dt = datetime.strptime(start_date, '%Y%m%d')
            end_dt = datetime.strptime(end_date, '%Y%m%d')

            dates = []
            current_dt = start_dt

            while current_dt <= end_dt:
                dates.append(current_dt.strftime('%Y%m%d'))
                current_dt += timedelta(days=1)

            return dates

        except ValueError as e:
            logger.error(f"Invalid date format: {e}")
            return []

    def _organize_range_results(self, results: List[Dict], dates: List[str],
                                data_types: List[str]) -> Dict[str, Any]:
        """æ•´ç†æ‰¹é‡æŸ¥è¯¢ç»“æœ"""
        organized = {
            'by_date': {},
            'by_type': {dt: {} for dt in data_types},
            'summary': {
                'successful_dates': [],
                'failed_dates': [],
                'data_completeness': {}
            }
        }

        # æŒ‰æ—¥æœŸå’Œç±»å‹ç»„ç»‡æ•°æ®
        for result in results:
            metadata = result['metadata']
            date = metadata['date']
            data_type = metadata['type']

            # æŒ‰æ—¥æœŸç»„ç»‡
            if date not in organized['by_date']:
                organized['by_date'][date] = {}

            organized['by_date'][date][data_type] = {
                'success': result['success'],
                'data': result.get('data'),
                'error': result.get('error')
            }

            # æŒ‰ç±»å‹ç»„ç»‡
            organized['by_type'][data_type][date] = {
                'success': result['success'],
                'data': result.get('data'),
                'error': result.get('error')
            }

        # è®¡ç®—æ‘˜è¦ç»Ÿè®¡
        for date in dates:
            date_results = organized['by_date'].get(date, {})
            successful_types = [dt for dt in data_types
                                if date_results.get(dt, {}).get('success', False)]

            if len(successful_types) == len(data_types):
                organized['summary']['successful_dates'].append(date)
            elif len(successful_types) == 0:
                organized['summary']['failed_dates'].append(date)

        # æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡
        for data_type in data_types:
            successful_count = sum(1 for date in dates
                                   if organized['by_type'][data_type].get(date, {}).get('success', False))
            organized['summary']['data_completeness'][data_type] = {
                'successful_days': successful_count,
                'total_days': len(dates),
                'completeness_rate': successful_count / len(dates) if dates else 0
            }

        return organized

    # ============= ğŸ†• ç»Ÿè®¡å’Œç›‘æ§æ–¹æ³• =============

    def get_connector_stats(self) -> Dict[str, Any]:
        """è·å–è¿æ¥å™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "query_statistics": self.query_stats,
            "circuit_breaker_status": self.circuit_breaker,
            "cache_statistics": {
                "cache_size": len(self.cache),
                "cache_hit_rate": (self.query_stats['cache_hits'] /
                                   max(self.query_stats['total_queries'], 1)) * 100
            },
            "ai_enhancement_status": {
                "claude_available": self.claude_client is not None,
                "gpt_available": self.gpt_client is not None,
                "date_utils_available": self.date_utils is not None,
                "validator_available": self.validator is not None
            }
        }

    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æµ‹è¯•åŸºç¡€APIè°ƒç”¨
            test_result = await self.get_system_data()

            return {
                "status": "healthy" if test_result.get("success") else "degraded",
                "api_connectivity": test_result.get("success", False),
                "circuit_breaker_state": self.circuit_breaker['state'],
                "ai_capabilities": {
                    "claude_ready": self.claude_client is not None,
                    "gpt_ready": self.gpt_client is not None,
                    "validation_ready": self.validator is not None
                },
                "performance_stats": self.query_stats,
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    # ============= èµ„æºæ¸…ç† =============

    async def close(self):
        """å…³é—­è¿æ¥å™¨ï¼Œæ¸…ç†èµ„æº"""
        if self.session and not self.session.closed:
            await self.session.close()
            logger.info("Enhanced APIConnector session closed")


# ============= å·¥å‚å‡½æ•° =============

def create_enhanced_api_connector(config: Optional[Dict] = None,
                                  claude_client=None,
                                  gpt_client=None) -> APIConnector:
    """
    åˆ›å»ºå¢å¼ºç‰ˆAPIè¿æ¥å™¨å®ä¾‹

    Args:
        config: é…ç½®å­—å…¸
        claude_client: Claudeå®¢æˆ·ç«¯å®ä¾‹
        gpt_client: GPTå®¢æˆ·ç«¯å®ä¾‹

    Returns:
        APIConnector: å¢å¼ºç‰ˆAPIè¿æ¥å™¨å®ä¾‹
    """
    return APIConnector(config, claude_client, gpt_client)


# ============= ä½¿ç”¨ç¤ºä¾‹ =============

async def main():
    """ä½¿ç”¨ç¤ºä¾‹"""
    connector = create_enhanced_api_connector()

    try:
        print("=== å¢å¼ºç‰ˆAPIè¿æ¥å™¨æµ‹è¯• ===")

        # 1. åŸºç¡€APIæµ‹è¯•
        system_data = await connector.get_system_data()
        print(f"ç³»ç»Ÿæ•°æ®è·å–: {'æˆåŠŸ' if system_data.get('success') else 'å¤±è´¥'}")

        # 2. ğŸ†• æ–°APIæµ‹è¯•
        interval_data = await connector.get_product_end_interval("20240601", "20240630")
        print(f"åŒºé—´åˆ°æœŸæ•°æ®: {'æˆåŠŸ' if interval_data.get('success') else 'å¤±è´¥'}")

        # 3. ğŸ†• æ™ºèƒ½æ•°æ®åŒ…æµ‹è¯•
        query_analysis = {
            "query_type": QueryType.REALTIME,
            "data_requirements": {},
            "time_range": {}
        }

        intelligent_data = await connector.intelligent_data_fetch(query_analysis)
        print(f"æ™ºèƒ½æ•°æ®è·å–: {'æˆåŠŸ' if intelligent_data.get('success') else 'å¤±è´¥'}")

        # 4. ç»Ÿè®¡ä¿¡æ¯
        stats = connector.get_connector_stats()
        print(f"æ€»æŸ¥è¯¢æ¬¡æ•°: {stats['query_statistics']['total_queries']}")
        print(f"AIä¼˜åŒ–æŸ¥è¯¢: {stats['query_statistics']['ai_optimized_queries']}")

        # 5. å¥åº·æ£€æŸ¥
        health = await connector.health_check()
        print(f"ç³»ç»ŸçŠ¶æ€: {health['status']}")

    finally:
        await connector.close()


if __name__ == "__main__":
    asyncio.run(main())