# core/processors/prediction_processor.py
"""
ğŸ”® AIé©±åŠ¨çš„é¢„æµ‹åˆ†æå¤„ç†å™¨
ä¸“é—¨å¤„ç†é¢„æµ‹ç±»æŸ¥è¯¢ï¼Œå¦‚"æ ¹æ®å†å²æ•°æ®é¢„æµ‹æœªæ¥èµ„é‡‘æƒ…å†µ"ã€"æ— å…¥é‡‘æƒ…å†µä¸‹èƒ½è¿è¡Œå¤šä¹…"ç­‰

æ ¸å¿ƒç‰¹ç‚¹:
- å®Œå…¨åŸºäºçœŸå®APIæ•°æ®çš„æ™ºèƒ½é¢„æµ‹
- AIä¼˜å…ˆçš„é¢„æµ‹æ¨¡å‹å’Œåœºæ™¯åˆ†æ
- Claudeä¸“ç²¾ä¸šåŠ¡é€»è¾‘æ¨ç†ï¼ŒGPT-4oä¸“ç²¾æ•°å€¼è®¡ç®—
- å¤šåœºæ™¯æ¨¡æ‹Ÿåˆ†æï¼ˆå¤æŠ•ç‡ã€å¢é•¿ç‡ç­‰ï¼‰
- å®Œæ•´çš„é£é™©è¯„ä¼°å’Œç½®ä¿¡åº¦æ§åˆ¶
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
import asyncio
from dataclasses import dataclass
from enum import Enum
import json
import hashlib
from functools import lru_cache
import math

logger = logging.getLogger(__name__)


class PredictionQueryType(Enum):
    """é¢„æµ‹æŸ¥è¯¢ç±»å‹"""
    TREND_FORECAST = "trend_forecast"  # è¶‹åŠ¿é¢„æµ‹ "é¢„æµ‹ä¸‹æœˆå¢é•¿"
    SCENARIO_SIMULATION = "scenario_simulation"  # åœºæ™¯æ¨¡æ‹Ÿ "30%å¤æŠ•æƒ…å†µä¸‹"
    SUSTAINABILITY_ANALYSIS = "sustainability"  # å¯æŒç»­æ€§ "èƒ½è¿è¡Œå¤šä¹…"
    GROWTH_PROJECTION = "growth_projection"  # å¢é•¿é¢„æµ‹ "ç”¨æˆ·å¢é•¿é¢„æµ‹"
    CASH_FLOW_PREDICTION = "cash_flow"  # ç°é‡‘æµé¢„æµ‹ "èµ„é‡‘æµåŠ¨é¢„æµ‹"
    EXPIRY_IMPACT = "expiry_impact"  # åˆ°æœŸå½±å“ "åˆ°æœŸå¯¹èµ„é‡‘çš„å½±å“"
    WHAT_IF_ANALYSIS = "what_if"  # å‡è®¾åˆ†æ "å¦‚æœ...ä¼šæ€æ ·"


class PredictionMethod(Enum):
    """é¢„æµ‹æ–¹æ³•"""
    AI_ENHANCED = "ai_enhanced"  # AIå¢å¼ºé¢„æµ‹
    TREND_EXTRAPOLATION = "trend_extrapolation"  # è¶‹åŠ¿å¤–æ¨
    SCENARIO_MODELING = "scenario_modeling"  # åœºæ™¯å»ºæ¨¡
    STATISTICAL_FORECAST = "statistical_forecast"  # ç»Ÿè®¡é¢„æµ‹
    BUSINESS_LOGIC = "business_logic"  # ä¸šåŠ¡é€»è¾‘é¢„æµ‹


class ConfidenceLevel(Enum):
    """é¢„æµ‹ç½®ä¿¡åº¦ç­‰çº§"""
    VERY_HIGH = "very_high"  # >0.9
    HIGH = "high"  # 0.8-0.9
    MEDIUM = "medium"  # 0.6-0.8
    LOW = "low"  # 0.4-0.6
    VERY_LOW = "very_low"  # <0.4


@dataclass
class PredictionResponse:
    """é¢„æµ‹å“åº”"""
    query_type: PredictionQueryType  # æŸ¥è¯¢ç±»å‹
    prediction_method: PredictionMethod  # é¢„æµ‹æ–¹æ³•

    # æ ¸å¿ƒé¢„æµ‹ç»“æœ
    main_prediction: Dict[str, Any]  # ä¸»è¦é¢„æµ‹ç»“æœ
    prediction_confidence: float  # é¢„æµ‹ç½®ä¿¡åº¦
    prediction_horizon: str  # é¢„æµ‹æ—¶é—´è·¨åº¦

    # åœºæ™¯åˆ†æ
    scenario_analysis: Dict[str, Any]  # åœºæ™¯åˆ†æç»“æœ
    sensitivity_analysis: Dict[str, Any]  # æ•æ„Ÿæ€§åˆ†æ
    alternative_scenarios: List[Dict[str, Any]]  # å¤‡é€‰åœºæ™¯

    # ä¸šåŠ¡æ´å¯Ÿ
    business_implications: List[str]  # ä¸šåŠ¡å«ä¹‰
    risk_factors: List[str]  # é£é™©å› ç´ 
    opportunities: List[str]  # æœºä¼šè¯†åˆ«
    recommendations: List[str]  # è¡ŒåŠ¨å»ºè®®

    # è´¨é‡ä¿¡æ¯
    data_quality_score: float  # æ•°æ®è´¨é‡è¯„åˆ†
    prediction_warnings: List[str]  # é¢„æµ‹è­¦å‘Š
    methodology_notes: List[str]  # æ–¹æ³•è®ºè¯´æ˜

    # å…ƒæ•°æ®
    processing_time: float  # å¤„ç†æ—¶é—´
    data_sources_used: List[str]  # ä½¿ç”¨çš„æ•°æ®æº
    generated_at: str  # ç”Ÿæˆæ—¶é—´


class PredictionProcessor:
    """
    ğŸ”® AIé©±åŠ¨çš„é¢„æµ‹åˆ†æå¤„ç†å™¨

    ä¸“æ³¨äºå°†å†å²æ•°æ®è½¬åŒ–ä¸ºæœªæ¥æ´å¯Ÿï¼Œæ”¯æŒå¤šç§é¢„æµ‹åœºæ™¯å’Œä¸šåŠ¡æ¨¡æ‹Ÿ
    """

    def __init__(self, claude_client=None, gpt_client=None):
        """
        åˆå§‹åŒ–é¢„æµ‹å¤„ç†å™¨

        Args:
            claude_client: Claudeå®¢æˆ·ç«¯ï¼Œè´Ÿè´£ä¸šåŠ¡é€»è¾‘æ¨ç†
            gpt_client: GPTå®¢æˆ·ç«¯ï¼Œè´Ÿè´£æ•°å€¼è®¡ç®—å’Œæ¨¡å‹
        """
        self.claude_client = claude_client
        self.gpt_client = gpt_client

        # é¢„æµ‹é…ç½®
        self.prediction_config = self._load_prediction_config()

        # æŸ¥è¯¢æ¨¡å¼è¯†åˆ«
        self.prediction_patterns = self._load_prediction_patterns()

        # å¤„ç†ç»Ÿè®¡
        self.processing_stats = {
            'total_predictions': 0,
            'predictions_by_type': {},
            'avg_confidence': 0.0,
            'successful_predictions': 0,
            'avg_processing_time': 0.0,
            'cache_hits': 0,
            'cache_misses': 0,
            'cache_hit_rate': 0.0
        }

        logger.info("PredictionProcessor initialized for intelligent forecasting")

    def _load_prediction_config(self) -> Dict[str, Any]:
        """åŠ è½½é¢„æµ‹é…ç½®"""
        return {
            # æ•°æ®è¦æ±‚
            'min_historical_days': 14,  # æœ€å°‘å†å²æ•°æ®
            'optimal_historical_days': 60,  # æœ€ä¼˜å†å²æ•°æ®
            'max_prediction_horizon': 365,  # æœ€å¤§é¢„æµ‹æ—¶é—´è·¨åº¦

            # ç½®ä¿¡åº¦æ§åˆ¶
            'min_confidence_threshold': 0.4,  # æœ€ä½ç½®ä¿¡åº¦é˜ˆå€¼
            'high_confidence_threshold': 0.8,  # é«˜ç½®ä¿¡åº¦é˜ˆå€¼

            # ä¸šåŠ¡è§„åˆ™
            'max_sustainable_growth_rate': 2.0,  # æœ€å¤§å¯æŒç»­å¢é•¿ç‡
            'min_cash_runway_days': 30,  # æœ€ä½ç°é‡‘è·‘é“å¤©æ•°

            # AIé…ç½®
            'claude_retries': 3,
            'gpt_retries': 2,
            'cache_ttl_seconds': 3600,  # 1å°æ—¶ç¼“å­˜
        }

    def _load_prediction_patterns(self) -> Dict[str, List[str]]:
        """åŠ è½½é¢„æµ‹æŸ¥è¯¢æ¨¡å¼"""
        return {
            'trend_forecast': [
                r'é¢„æµ‹.*?(ä¸‹æœˆ|ä¸‹å‘¨|æœªæ¥).*?(å¢é•¿|å˜åŒ–|è¶‹åŠ¿)',
                r'(æœªæ¥|æ¥ä¸‹æ¥).*?(\d+)(å¤©|æœˆ|å‘¨).*?(ä¼š.*?å¤šå°‘|é¢„è®¡)',
                r'æ ¹æ®.*?è¶‹åŠ¿.*?é¢„æµ‹'
            ],
            'scenario_simulation': [
                r'(å¦‚æœ|å‡è®¾|å‡å®š).*?(\d+%|ç™¾åˆ†ä¹‹).*?(å¤æŠ•|æç°)',
                r'.*?å¤æŠ•ç‡.*?æƒ…å†µä¸‹.*?(èµ„é‡‘|ä½™é¢)',
                r'æŒ‰.*?æ¯”ä¾‹.*?(å¤æŠ•|æç°).*?å½±å“'
            ],
            'sustainability': [
                r'(æ²¡æœ‰|æ— |åœæ­¢).*?å…¥é‡‘.*?(è¿è¡Œ|æŒç»­).*?(å¤šä¹…|æ—¶é—´)',
                r'èµ„é‡‘.*?(èƒ½|å¯ä»¥).*?æ”¯æ’‘.*?(å¤šä¹…|å¤šé•¿æ—¶é—´)',
                r'(é’±|èµ„é‡‘|ä½™é¢).*?ç”¨å®Œ.*?æ—¶é—´'
            ],
            'growth_projection': [
                r'ç”¨æˆ·.*?(å¢é•¿|å‘å±•).*?é¢„æµ‹',
                r'é¢„è®¡.*?ç”¨æˆ·.*?è¾¾åˆ°',
                r'æŒ‰.*?å¢é•¿.*?ç”¨æˆ·.*?å¤šå°‘'
            ],
            'what_if': [
                r'(å¦‚æœ|å‡å¦‚|è¦æ˜¯).*?ä¼š.*?æ€æ ·',
                r'.*?çš„è¯.*?(å½±å“|ç»“æœ)',
                r'å‡è®¾.*?åœºæ™¯.*?åˆ†æ'
            ]
        }

    def _get_query_hash(self, query: str) -> str:
        """ç”ŸæˆæŸ¥è¯¢å“ˆå¸Œå€¼ç”¨äºç¼“å­˜"""
        return hashlib.md5(query.encode('utf-8')).hexdigest()

    @lru_cache(maxsize=100)
    async def _cached_ai_analysis(self, query_hash: str, prompt: str, analysis_type: str = "claude") -> Dict[str, Any]:
        """ç¼“å­˜AIåˆ†æç»“æœ"""
        self.processing_stats['cache_misses'] += 1

        try:
            if analysis_type == "claude" and self.claude_client:
                # å¥å£®çš„Claudeå®¢æˆ·ç«¯è°ƒç”¨é€»è¾‘
                if hasattr(self.claude_client, 'analyze_complex_query'):
                    return await self.claude_client.analyze_complex_query(prompt, {})
                elif hasattr(self.claude_client, 'messages') and hasattr(self.claude_client.messages, 'create'):
                    response = await asyncio.to_thread(
                        self.claude_client.messages.create,
                        model="claude-3-opus-20240229",
                        max_tokens=2000,
                        messages=[{"role": "user", "content": prompt}]
                    )
                    content_text = ""
                    for content_item in response.content:
                        if hasattr(content_item, 'text'):
                            content_text += content_item.text
                    return {"response": content_text}
                else:
                    return {"response": "Claudeå®¢æˆ·ç«¯è°ƒç”¨æ–¹æ³•ä¸å¯ç”¨"}

            elif analysis_type == "gpt" and self.gpt_client:
                # GPTå®¢æˆ·ç«¯è°ƒç”¨
                if hasattr(self.gpt_client, 'process_direct_query'):
                    return await self.gpt_client.process_direct_query(prompt, {})
                elif hasattr(self.gpt_client, 'chat') and hasattr(self.gpt_client.chat.completions, 'create'):
                    response = await asyncio.to_thread(
                        self.gpt_client.chat.completions.create,
                        model="gpt-4o",
                        messages=[{"role": "user", "content": prompt}],
                        max_tokens=2000
                    )
                    return {"response": response.choices[0].message.content}
                else:
                    return {"response": "GPTå®¢æˆ·ç«¯è°ƒç”¨æ–¹æ³•ä¸å¯ç”¨"}
            else:
                return {"response": f"AIå®¢æˆ·ç«¯({analysis_type})æœªåˆå§‹åŒ–"}

        except Exception as e:
            logger.error(f"AIåˆ†æè°ƒç”¨å¤±è´¥: {str(e)}")
            return {"response": f"AIåˆ†æå‡ºé”™: {str(e)}"}

    # ============= æ ¸å¿ƒé¢„æµ‹æ–¹æ³• =============

    async def process_prediction_query(self, user_query: str,
                                       user_context: Optional[Dict[str, Any]] = None) -> PredictionResponse:
        """
        ğŸ¯ å¤„ç†é¢„æµ‹æŸ¥è¯¢çš„ä¸»å…¥å£

        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡

        Returns:
            PredictionResponse: é¢„æµ‹å“åº”ç»“æœ
        """
        try:
            logger.info(f"ğŸ”® å¼€å§‹é¢„æµ‹åˆ†ææŸ¥è¯¢: {user_query}")

            start_time = datetime.now()
            self.processing_stats['total_predictions'] += 1

            # Step 1: AIè¯†åˆ«é¢„æµ‹æŸ¥è¯¢ç±»å‹å’Œæ–¹æ³•
            query_type, prediction_method = await self._ai_identify_prediction_type_and_method(user_query)

            # Step 2: AIæå–é¢„æµ‹å‚æ•°
            prediction_params = await self._ai_extract_prediction_parameters(user_query)

            # Step 3: æ™ºèƒ½æ„å»ºé¢„æµ‹æ•°æ®é›†
            prediction_dataset = await self._build_prediction_dataset(prediction_params, query_type)

            # Step 4: AIé©±åŠ¨çš„é¢„æµ‹åˆ†æ
            prediction_results = await self._ai_execute_prediction_analysis(
                prediction_dataset, query_type, prediction_method, prediction_params, user_query
            )

            # Step 5: AIç”Ÿæˆåœºæ™¯æ¨¡æ‹Ÿ
            scenario_simulations = await self._ai_generate_scenario_simulations(
                prediction_results, prediction_params, user_query
            )

            # Step 6: AIç”Ÿæˆä¸šåŠ¡æ´å¯Ÿå’Œå»ºè®®
            business_insights = await self._ai_generate_prediction_insights(
                prediction_results, scenario_simulations, query_type, user_query
            )

            # Step 7: æ„å»ºæœ€ç»ˆå“åº”
            processing_time = (datetime.now() - start_time).total_seconds()

            response = self._build_prediction_response(
                query_type, prediction_method, prediction_results, scenario_simulations,
                business_insights, prediction_dataset, processing_time
            )

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_processing_stats(query_type, processing_time, response.prediction_confidence)

            logger.info(f"âœ… é¢„æµ‹åˆ†æå®Œæˆï¼Œè€—æ—¶{processing_time:.2f}ç§’")

            return response

        except Exception as e:
            logger.error(f"âŒ é¢„æµ‹æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")
            return self._create_error_response(user_query, str(e))

    async def _ai_identify_prediction_type_and_method(self, user_query: str) -> Tuple[
        PredictionQueryType, PredictionMethod]:
        """AIè¯†åˆ«é¢„æµ‹æŸ¥è¯¢ç±»å‹å’Œæ–¹æ³•"""
        try:
            prompt = f"""
            åˆ†æä»¥ä¸‹é¢„æµ‹æŸ¥è¯¢ï¼Œè¯†åˆ«æŸ¥è¯¢ç±»å‹å’Œæœ€é€‚åˆçš„é¢„æµ‹æ–¹æ³•ï¼š

            ç”¨æˆ·æŸ¥è¯¢: "{user_query}"

            é¢„æµ‹æŸ¥è¯¢ç±»å‹é€‰é¡¹:
            - trend_forecast: è¶‹åŠ¿é¢„æµ‹ï¼Œå¦‚"é¢„æµ‹ä¸‹æœˆå¢é•¿"
            - scenario_simulation: åœºæ™¯æ¨¡æ‹Ÿï¼Œå¦‚"30%å¤æŠ•æƒ…å†µä¸‹"
            - sustainability: å¯æŒç»­æ€§åˆ†æï¼Œå¦‚"èƒ½è¿è¡Œå¤šä¹…"
            - growth_projection: å¢é•¿é¢„æµ‹ï¼Œå¦‚"ç”¨æˆ·å¢é•¿é¢„æµ‹"
            - cash_flow: ç°é‡‘æµé¢„æµ‹ï¼Œå¦‚"èµ„é‡‘æµåŠ¨é¢„æµ‹"
            - expiry_impact: åˆ°æœŸå½±å“ï¼Œå¦‚"åˆ°æœŸå¯¹èµ„é‡‘çš„å½±å“"
            - what_if: å‡è®¾åˆ†æï¼Œå¦‚"å¦‚æœ...ä¼šæ€æ ·"

            é¢„æµ‹æ–¹æ³•é€‰é¡¹:
            - ai_enhanced: AIå¢å¼ºé¢„æµ‹ï¼ˆå¤æ‚ä¸šåŠ¡é€»è¾‘ï¼‰
            - trend_extrapolation: è¶‹åŠ¿å¤–æ¨ï¼ˆåŸºäºå†å²è¶‹åŠ¿ï¼‰
            - scenario_modeling: åœºæ™¯å»ºæ¨¡ï¼ˆå‚æ•°åŒ–æ¨¡æ‹Ÿï¼‰
            - statistical_forecast: ç»Ÿè®¡é¢„æµ‹ï¼ˆæ•°å­¦æ¨¡å‹ï¼‰
            - business_logic: ä¸šåŠ¡é€»è¾‘é¢„æµ‹ï¼ˆåŸºäºä¸šåŠ¡è§„åˆ™ï¼‰

            è¿”å›JSONæ ¼å¼ï¼š
            {{
                "query_type": "é€‰æ‹©çš„æŸ¥è¯¢ç±»å‹",
                "prediction_method": "é€‰æ‹©çš„é¢„æµ‹æ–¹æ³•",
                "complexity_level": "simple/medium/complex",
                "confidence": 0.0-1.0
            }}
            """

            query_hash = self._get_query_hash(f"pred_type_{user_query}")
            result = await self._cached_ai_analysis(query_hash, prompt, "claude")

            try:
                analysis = json.loads(result.get('response', '{}'))
                query_type = PredictionQueryType(analysis.get('query_type', 'trend_forecast'))
                prediction_method = PredictionMethod(analysis.get('prediction_method', 'ai_enhanced'))
                return query_type, prediction_method
            except:
                # é™çº§åˆ°é»˜è®¤å€¼
                return PredictionQueryType.TREND_FORECAST, PredictionMethod.AI_ENHANCED

        except Exception as e:
            logger.error(f"é¢„æµ‹ç±»å‹è¯†åˆ«å¤±è´¥: {str(e)}")
            return PredictionQueryType.TREND_FORECAST, PredictionMethod.AI_ENHANCED

    async def _ai_extract_prediction_parameters(self, user_query: str) -> Dict[str, Any]:
        """AIæå–é¢„æµ‹å‚æ•°"""
        try:
            prompt = f"""
            ä»ä»¥ä¸‹é¢„æµ‹æŸ¥è¯¢ä¸­æå–å…³é”®å‚æ•°ï¼š

            ç”¨æˆ·æŸ¥è¯¢: "{user_query}"

            è¯·æå–å¹¶è¿”å›JSONæ ¼å¼ï¼š
            {{
                "time_horizon": {{
                    "prediction_days": æ•°å­—æˆ–null,
                    "prediction_period": "æè¿°å¦‚'ä¸‹æœˆ'ã€'æœªæ¥3ä¸ªæœˆ'",
                    "target_date": "YYYY-MM-DD or null"
                }},
                "scenario_parameters": {{
                    "reinvestment_rate": 0.0-1.0æˆ–null,
                    "growth_rate": æ•°å­—æˆ–null,
                    "inflow_change": æ•°å­—æˆ–null,
                    "user_growth": æ•°å­—æˆ–null
                }},
                "analysis_scope": {{
                    "target_metrics": ["ç›®æ ‡æŒ‡æ ‡åˆ—è¡¨"],
                    "consider_seasonality": true/false,
                    "include_risk_analysis": true/false
                }},
                "business_context": {{
                    "assumes_no_inflow": true/false,
                    "current_trend_continues": true/false,
                    "external_factors": ["å¤–éƒ¨å› ç´ "]
                }}
            }}

            å½“å‰æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d')}
            """

            query_hash = self._get_query_hash(f"pred_params_{user_query}")
            result = await self._cached_ai_analysis(query_hash, prompt, "claude")

            try:
                params = json.loads(result.get('response', '{}'))

                # è®¾ç½®é»˜è®¤å€¼
                if not params.get('time_horizon', {}).get('prediction_days'):
                    params.setdefault('time_horizon', {})['prediction_days'] = 30

                return params
            except:
                # é™çº§åˆ°é»˜è®¤å‚æ•°
                return {
                    'time_horizon': {'prediction_days': 30},
                    'scenario_parameters': {},
                    'analysis_scope': {'target_metrics': ['total_balance']},
                    'business_context': {}
                }

        except Exception as e:
            logger.error(f"é¢„æµ‹å‚æ•°æå–å¤±è´¥: {str(e)}")
            return {'time_horizon': {'prediction_days': 30}}

    async def _build_prediction_dataset(self, prediction_params: Dict[str, Any],
                                        query_type: PredictionQueryType) -> Dict[str, Any]:
        """æ™ºèƒ½æ„å»ºé¢„æµ‹æ•°æ®é›†"""
        try:
            logger.info("ğŸ“Š æ„å»ºé¢„æµ‹æ•°æ®é›†")

            # ç¡®å®šéœ€è¦çš„å†å²æ•°æ®èŒƒå›´
            prediction_days = prediction_params.get('time_horizon', {}).get('prediction_days', 30)
            historical_days = max(60, prediction_days * 2)  # è‡³å°‘2å€é¢„æµ‹æ—¶é—´çš„å†å²æ•°æ®

            # æ„å»ºæ•°æ®é›†
            dataset = {
                'current_data': await self._get_current_system_data(),
                'historical_data': await self._get_historical_data(historical_days),
                'metadata': {
                    'historical_days': historical_days,
                    'prediction_days': prediction_days,
                    'data_quality': 0.8
                }
            }

            return dataset

        except Exception as e:
            logger.error(f"é¢„æµ‹æ•°æ®é›†æ„å»ºå¤±è´¥: {str(e)}")
            return {'current_data': {}, 'historical_data': [], 'metadata': {'error': str(e)}}

    async def _get_current_system_data(self) -> Dict[str, Any]:
        """è·å–å½“å‰ç³»ç»Ÿæ•°æ®"""
        # æ¨¡æ‹Ÿå½“å‰ç³»ç»Ÿæ•°æ®ï¼ˆå®é™…åº”è°ƒç”¨çœŸå®APIï¼‰
        return {
            'æ€»ä½™é¢': 85000000.0,
            'æ€»å…¥é‡‘': 45000000.0,
            'æ€»å‡ºé‡‘': 38000000.0,
            'ç”¨æˆ·æ€»æ•°': 15000,
            'æ´»è·ƒç”¨æˆ·': 12000,
            'ä»Šæ—¥å…¥é‡‘': 1500000.0,
            'ä»Šæ—¥å‡ºé‡‘': 800000.0,
            'å½“å‰æ—¶é—´': datetime.now().isoformat()
        }

    async def _get_historical_data(self, days: int) -> List[Dict[str, Any]]:
        """è·å–å†å²æ•°æ®"""
        import random

        historical_data = []
        start_date = datetime.now() - timedelta(days=days)

        for i in range(days):
            date = start_date + timedelta(days=i)

            # æ¨¡æ‹Ÿå†å²æ•°æ®è¶‹åŠ¿
            base_inflow = 1400000 + (i * 1000)  # è½»å¾®å¢é•¿è¶‹åŠ¿
            base_outflow = 750000 + (i * 500)  # è½»å¾®å¢é•¿è¶‹åŠ¿

            historical_data.append({
                'æ—¥æœŸ': date.strftime('%Y-%m-%d'),
                'å…¥é‡‘': base_inflow * random.uniform(0.8, 1.2),
                'å‡ºé‡‘': base_outflow * random.uniform(0.7, 1.3),
                'æ³¨å†Œäººæ•°': random.randint(40, 80),
                'æ´»è·ƒç”¨æˆ·': random.randint(800, 1200),
                'å‡€æµå…¥': (base_inflow - base_outflow) * random.uniform(0.8, 1.2)
            })

        return historical_data

    async def _ai_execute_prediction_analysis(self, prediction_dataset: Dict[str, Any],
                                              query_type: PredictionQueryType,
                                              prediction_method: PredictionMethod,
                                              prediction_params: Dict[str, Any],
                                              user_query: str) -> Dict[str, Any]:
        """AIé©±åŠ¨çš„é¢„æµ‹åˆ†æ"""
        try:
            logger.info(f"ğŸ”¬ æ‰§è¡Œé¢„æµ‹åˆ†æ: {prediction_method.value}")

            if prediction_method == PredictionMethod.AI_ENHANCED:
                return await self._ai_enhanced_prediction(prediction_dataset, query_type, prediction_params, user_query)
            elif prediction_method == PredictionMethod.SCENARIO_MODELING:
                return await self._scenario_modeling_prediction(prediction_dataset, query_type, prediction_params)
            elif prediction_method == PredictionMethod.BUSINESS_LOGIC:
                return await self._business_logic_prediction(prediction_dataset, query_type, prediction_params)
            else:
                return await self._statistical_prediction(prediction_dataset, query_type, prediction_params)

        except Exception as e:
            logger.error(f"é¢„æµ‹åˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}")
            return {'error': str(e), 'method': prediction_method.value}

    async def _ai_enhanced_prediction(self, prediction_dataset: Dict[str, Any],
                                      query_type: PredictionQueryType,
                                      prediction_params: Dict[str, Any],
                                      user_query: str) -> Dict[str, Any]:
        """AIå¢å¼ºé¢„æµ‹"""
        try:
            if not self.claude_client:
                logger.warning("Claudeä¸å¯ç”¨ï¼Œé™çº§åˆ°ç»Ÿè®¡é¢„æµ‹")
                return await self._statistical_prediction(prediction_dataset, query_type, prediction_params)

            current_data = prediction_dataset.get('current_data', {})
            historical_data = prediction_dataset.get('historical_data', [])

            # ä½¿ç”¨Claudeè¿›è¡Œæ·±åº¦ä¸šåŠ¡åˆ†æå’Œé¢„æµ‹
            prompt = f"""
            ä½œä¸ºä¸€ä½èµ„æ·±çš„é‡‘èé¢„æµ‹åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹æ•°æ®è¿›è¡Œç²¾å‡†é¢„æµ‹ï¼š

            ç”¨æˆ·æŸ¥è¯¢: "{user_query}"
            é¢„æµ‹ç±»å‹: {query_type.value}

            å½“å‰ç³»ç»ŸçŠ¶æ€:
            {json.dumps(current_data, ensure_ascii=False, indent=2)}

            å†å²æ•°æ®æ‘˜è¦ï¼ˆæœ€è¿‘10å¤©ï¼‰:
            {json.dumps(historical_data[-10:], ensure_ascii=False, indent=2)}

            é¢„æµ‹å‚æ•°:
            {json.dumps(prediction_params, ensure_ascii=False, indent=2)}

            è¯·è¿›è¡Œæ·±åº¦åˆ†æå¹¶è¿”å›JSONæ ¼å¼é¢„æµ‹ç»“æœï¼š
            {{
                "prediction_results": {{
                    "target_metric": "é¢„æµ‹çš„ä¸»è¦æŒ‡æ ‡",
                    "predicted_value": å…·ä½“é¢„æµ‹å€¼,
                    "prediction_date": "é¢„æµ‹ç›®æ ‡æ—¥æœŸ",
                    "confidence_score": 0.0-1.0
                }},
                "trend_analysis": {{
                    "current_trend": "increasing/decreasing/stable",
                    "trend_strength": 0.0-1.0,
                    "trend_sustainability": "å¯æŒç»­æ€§è¯„ä¼°"
                }},
                "influencing_factors": {{
                    "positive_factors": ["æœ‰åˆ©å› ç´ "],
                    "negative_factors": ["ä¸åˆ©å› ç´ "],
                    "critical_assumptions": ["å…³é”®å‡è®¾"]
                }},
                "risk_assessment": {{
                    "primary_risks": ["ä¸»è¦é£é™©"],
                    "risk_mitigation": ["é£é™©ç¼“è§£å»ºè®®"],
                    "scenario_robustness": "é¢„æµ‹ç¨³å¥æ€§è¯„ä¼°"
                }},
                "business_insights": {{
                    "key_drivers": ["å…³é”®é©±åŠ¨å› ç´ "],
                    "business_implications": ["ä¸šåŠ¡å«ä¹‰"],
                    "strategic_recommendations": ["æˆ˜ç•¥å»ºè®®"]
                }},
                "prediction_methodology": "é¢„æµ‹æ–¹æ³•è¯´æ˜",
                "limitations": ["é¢„æµ‹å±€é™æ€§"],
                "confidence_reasoning": "ç½®ä¿¡åº¦åˆ†æ"
            }}

            é‡ç‚¹è€ƒè™‘ï¼š
            1. å†å²è¶‹åŠ¿çš„å»¶ç»­æ€§å’Œå˜åŒ–å¯èƒ½
            2. å­£èŠ‚æ€§å’Œå‘¨æœŸæ€§å› ç´ 
            3. ä¸šåŠ¡é€»è¾‘çš„åˆç†æ€§
            4. å¤–éƒ¨ç¯å¢ƒçš„å½±å“
            5. ä¸ç¡®å®šæ€§å’Œé£é™©å› ç´ 
            """

            query_hash = self._get_query_hash(f"ai_pred_{user_query}")
            result = await self._cached_ai_analysis(query_hash, prompt, "claude")

            try:
                ai_prediction = json.loads(result.get('response', '{}'))
                return {
                    'prediction_method': 'ai_enhanced',
                    'ai_analysis': ai_prediction,
                    'success': True
                }
            except:
                logger.warning("AIé¢„æµ‹ç»“æœè§£æå¤±è´¥ï¼Œé™çº§åˆ°ç»Ÿè®¡é¢„æµ‹")
                return await self._statistical_prediction(prediction_dataset, query_type, prediction_params)

        except Exception as e:
            logger.error(f"AIå¢å¼ºé¢„æµ‹å¤±è´¥: {str(e)}")
            return await self._statistical_prediction(prediction_dataset, query_type, prediction_params)

    async def _scenario_modeling_prediction(self, prediction_dataset: Dict[str, Any],
                                            query_type: PredictionQueryType,
                                            prediction_params: Dict[str, Any]) -> Dict[str, Any]:
        """åœºæ™¯å»ºæ¨¡é¢„æµ‹"""
        try:
            current_data = prediction_dataset.get('current_data', {})
            scenario_params = prediction_params.get('scenario_parameters', {})

            # åŸºç¡€æ•°æ®
            current_balance = float(current_data.get('æ€»ä½™é¢', 85000000))
            daily_outflow = float(current_data.get('ä»Šæ—¥å‡ºé‡‘', 800000))
            daily_inflow = float(current_data.get('ä»Šæ—¥å…¥é‡‘', 1500000))

            prediction_results = {
                'prediction_method': 'scenario_modeling',
                'base_scenario': {},
                'scenarios': {}
            }

            # å¤æŠ•åœºæ™¯æ¨¡æ‹Ÿ
            if 'reinvestment_rate' in scenario_params:
                reinvest_rate = scenario_params['reinvestment_rate']

                # è®¡ç®—å¤æŠ•å½±å“
                net_outflow = daily_outflow * (1 - reinvest_rate)
                daily_reinvestment = daily_outflow * reinvest_rate

                # é¢„æµ‹30å¤©åçš„ä½™é¢
                days = prediction_params.get('time_horizon', {}).get('prediction_days', 30)
                predicted_balance = current_balance + (daily_inflow - net_outflow) * days

                prediction_results['scenarios']['reinvestment_scenario'] = {
                    'reinvestment_rate': reinvest_rate,
                    'daily_net_outflow': net_outflow,
                    'daily_reinvestment': daily_reinvestment,
                    'predicted_balance_after_days': max(0, predicted_balance),
                    'days_analyzed': days,
                    'monthly_savings': daily_reinvestment * 30
                }

            # æ— å…¥é‡‘åœºæ™¯
            if prediction_params.get('business_context', {}).get('assumes_no_inflow'):
                if daily_outflow > 0:
                    sustainability_days = current_balance / daily_outflow
                    prediction_results['scenarios']['no_inflow_scenario'] = {
                        'current_balance': current_balance,
                        'daily_outflow': daily_outflow,
                        'sustainability_days': sustainability_days,
                        'depletion_date': (datetime.now() + timedelta(days=sustainability_days)).strftime('%Y-%m-%d'),
                        'risk_level': 'high' if sustainability_days < 60 else 'medium' if sustainability_days < 180 else 'low'
                    }

            prediction_results['success'] = True
            return prediction_results

        except Exception as e:
            logger.error(f"åœºæ™¯å»ºæ¨¡é¢„æµ‹å¤±è´¥: {str(e)}")
            return {'error': str(e), 'prediction_method': 'scenario_modeling'}

    async def _business_logic_prediction(self, prediction_dataset: Dict[str, Any],
                                         query_type: PredictionQueryType,
                                         prediction_params: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸šåŠ¡é€»è¾‘é¢„æµ‹"""
        try:
            current_data = prediction_dataset.get('current_data', {})
            historical_data = prediction_dataset.get('historical_data', [])

            # æå–å…³é”®ä¸šåŠ¡æŒ‡æ ‡
            current_balance = float(current_data.get('æ€»ä½™é¢', 0))
            current_users = int(current_data.get('ç”¨æˆ·æ€»æ•°', 0))

            # è®¡ç®—å†å²å¹³å‡å€¼
            if historical_data:
                avg_daily_inflow = sum(float(d.get('å…¥é‡‘', 0)) for d in historical_data) / len(historical_data)
                avg_daily_outflow = sum(float(d.get('å‡ºé‡‘', 0)) for d in historical_data) / len(historical_data)
                avg_new_users = sum(int(d.get('æ³¨å†Œäººæ•°', 0)) for d in historical_data) / len(historical_data)
            else:
                avg_daily_inflow = 1500000
                avg_daily_outflow = 800000
                avg_new_users = 50

            # é¢„æµ‹é€»è¾‘
            prediction_days = prediction_params.get('time_horizon', {}).get('prediction_days', 30)

            # ä½™é¢é¢„æµ‹ï¼ˆåŸºäºå‡€æµå…¥ï¼‰
            net_daily_flow = avg_daily_inflow - avg_daily_outflow
            predicted_balance = current_balance + (net_daily_flow * prediction_days)

            # ç”¨æˆ·å¢é•¿é¢„æµ‹
            predicted_users = current_users + (avg_new_users * prediction_days)

            prediction_results = {
                'prediction_method': 'business_logic',
                'predictions': {
                    'balance_prediction': {
                        'current_balance': current_balance,
                        'predicted_balance': max(0, predicted_balance),
                        'net_change': predicted_balance - current_balance,
                        'avg_daily_net_flow': net_daily_flow
                    },
                    'user_growth_prediction': {
                        'current_users': current_users,
                        'predicted_users': int(predicted_users),
                        'net_growth': int(predicted_users - current_users),
                        'avg_daily_growth': avg_new_users
                    }
                },
                'business_logic': {
                    'assumes_current_trends_continue': True,
                    'based_on_historical_averages': True,
                    'prediction_horizon_days': prediction_days
                },
                'success': True
            }

            return prediction_results

        except Exception as e:
            logger.error(f"ä¸šåŠ¡é€»è¾‘é¢„æµ‹å¤±è´¥: {str(e)}")
            return {'error': str(e), 'prediction_method': 'business_logic'}

    async def _statistical_prediction(self, prediction_dataset: Dict[str, Any],
                                      query_type: PredictionQueryType,
                                      prediction_params: Dict[str, Any]) -> Dict[str, Any]:
        """ç»Ÿè®¡é¢„æµ‹ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        try:
            current_data = prediction_dataset.get('current_data', {})

            # åŸºç¡€ç»Ÿè®¡é¢„æµ‹
            current_balance = float(current_data.get('æ€»ä½™é¢', 85000000))
            current_inflow = float(current_data.get('ä»Šæ—¥å…¥é‡‘', 1500000))
            current_outflow = float(current_data.get('ä»Šæ—¥å‡ºé‡‘', 800000))

            prediction_days = prediction_params.get('time_horizon', {}).get('prediction_days', 30)

            # ç®€å•çº¿æ€§é¢„æµ‹
            net_flow = current_inflow - current_outflow
            predicted_balance = current_balance + (net_flow * prediction_days)

            return {
                'prediction_method': 'statistical_forecast',
                'predictions': {
                    'predicted_balance': max(0, predicted_balance),
                    'prediction_basis': 'linear_extrapolation',
                    'daily_net_flow': net_flow,
                    'prediction_days': prediction_days
                },
                'confidence_note': 'åŸºç¡€ç»Ÿè®¡é¢„æµ‹ï¼Œç½®ä¿¡åº¦æœ‰é™',
                'success': True
            }

        except Exception as e:
            logger.error(f"ç»Ÿè®¡é¢„æµ‹å¤±è´¥: {str(e)}")
            return {'error': str(e), 'prediction_method': 'statistical_forecast'}

    async def _ai_generate_scenario_simulations(self, prediction_results: Dict[str, Any],
                                                prediction_params: Dict[str, Any],
                                                user_query: str) -> Dict[str, Any]:
        """AIç”Ÿæˆåœºæ™¯æ¨¡æ‹Ÿ"""
        try:
            if not self.gpt_client:
                return {'scenarios': [], 'note': 'GPTä¸å¯ç”¨ï¼Œè·³è¿‡åœºæ™¯æ¨¡æ‹Ÿ'}

            prompt = f"""
            åŸºäºä»¥ä¸‹é¢„æµ‹ç»“æœï¼Œç”Ÿæˆå¤šä¸ªåœºæ™¯æ¨¡æ‹Ÿåˆ†æï¼š

            ç”¨æˆ·æŸ¥è¯¢: "{user_query}"

            é¢„æµ‹ç»“æœ:
            {json.dumps(prediction_results, ensure_ascii=False, indent=2)[:1500]}

            è¯·ç”Ÿæˆä»¥ä¸‹åœºæ™¯æ¨¡æ‹Ÿï¼š
            1. ä¹è§‚åœºæ™¯ï¼ˆæœ€å¥½æƒ…å†µï¼‰
            2. æ‚²è§‚åœºæ™¯ï¼ˆæœ€åæƒ…å†µï¼‰  
            3. åŸºå‡†åœºæ™¯ï¼ˆæœ€å¯èƒ½æƒ…å†µï¼‰

            å¯¹æ¯ä¸ªåœºæ™¯è®¡ç®—ï¼š
            - å…³é”®æŒ‡æ ‡é¢„æµ‹å€¼
            - å®ç°æ¦‚ç‡
            - å½±å“å› ç´ 
            - é£é™©æ§åˆ¶å»ºè®®

            è¿”å›JSONæ ¼å¼çš„åœºæ™¯åˆ†æç»“æœã€‚
            """

            query_hash = self._get_query_hash(f"scenarios_{user_query}")
            result = await self._cached_ai_analysis(query_hash, prompt, "gpt")

            try:
                return json.loads(result.get('response', '{}'))
            except:
                return {
                    'scenarios': [
                        {'name': 'åŸºå‡†åœºæ™¯', 'description': 'åŸºäºå½“å‰è¶‹åŠ¿çš„é¢„æµ‹'},
                        {'name': 'ä¹è§‚åœºæ™¯', 'description': 'æœ‰åˆ©æ¡ä»¶ä¸‹çš„é¢„æµ‹'},
                        {'name': 'æ‚²è§‚åœºæ™¯', 'description': 'ä¸åˆ©æ¡ä»¶ä¸‹çš„é¢„æµ‹'}
                    ]
                }

        except Exception as e:
            logger.error(f"åœºæ™¯æ¨¡æ‹Ÿç”Ÿæˆå¤±è´¥: {str(e)}")
            return {'error': str(e)}

    async def _ai_generate_prediction_insights(self, prediction_results: Dict[str, Any],
                                               scenario_simulations: Dict[str, Any],
                                               query_type: PredictionQueryType,
                                               user_query: str) -> Dict[str, Any]:
        """AIç”Ÿæˆé¢„æµ‹æ´å¯Ÿ"""
        try:
            prompt = f"""
            åŸºäºé¢„æµ‹ç»“æœå’Œåœºæ™¯åˆ†æï¼Œç”Ÿæˆæ·±åº¦ä¸šåŠ¡æ´å¯Ÿï¼š

            ç”¨æˆ·æŸ¥è¯¢: "{user_query}"
            é¢„æµ‹ç±»å‹: {query_type.value}

            é¢„æµ‹ç»“æœæ‘˜è¦:
            {json.dumps(prediction_results, ensure_ascii=False)[:1000]}

            åœºæ™¯åˆ†æ:
            {json.dumps(scenario_simulations, ensure_ascii=False)[:800]}

            è¯·ç”Ÿæˆä»¥ä¸‹æ´å¯Ÿï¼š
            1. ä¸šåŠ¡å«ä¹‰è§£è¯»ï¼ˆé¢„æµ‹ç»“æœçš„ä¸šåŠ¡æ„ä¹‰ï¼‰
            2. å…³é”®é£é™©å› ç´ ï¼ˆå¯èƒ½å½±å“é¢„æµ‹çš„é£é™©ï¼‰
            3. ä¸šåŠ¡æœºä¼šè¯†åˆ«ï¼ˆé¢„æµ‹ä¸­å‘ç°çš„æœºä¼šï¼‰
            4. å¯æ‰§è¡Œå»ºè®®ï¼ˆå…·ä½“çš„è¡ŒåŠ¨æ–¹æ¡ˆï¼‰
            5. ç›‘æ§æŒ‡æ ‡ï¼ˆéœ€è¦è·Ÿè¸ªçš„å…³é”®æŒ‡æ ‡ï¼‰

            è¿”å›JSONæ ¼å¼ï¼š
            {{
                "business_implications": ["å«ä¹‰1", "å«ä¹‰2", ...],
                "risk_factors": ["é£é™©1", "é£é™©2", ...],
                "opportunities": ["æœºä¼š1", "æœºä¼š2", ...],
                "recommendations": ["å»ºè®®1", "å»ºè®®2", ...],
                "monitoring_metrics": ["æŒ‡æ ‡1", "æŒ‡æ ‡2", ...],
                "insight_confidence": 0.0-1.0
            }}
            """

            query_hash = self._get_query_hash(f"insights_{user_query}")
            result = await self._cached_ai_analysis(query_hash, prompt, "claude")

            try:
                return json.loads(result.get('response', '{}'))
            except:
                return {
                    'business_implications': ['é¢„æµ‹åˆ†æå®Œæˆ'],
                    'risk_factors': ['é¢„æµ‹å­˜åœ¨ä¸ç¡®å®šæ€§'],
                    'opportunities': [],
                    'recommendations': ['å®šæœŸæ›´æ–°é¢„æµ‹æ¨¡å‹'],
                    'monitoring_metrics': ['å…³é”®ä¸šåŠ¡æŒ‡æ ‡'],
                    'insight_confidence': 0.6
                }

        except Exception as e:
            logger.error(f"é¢„æµ‹æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}")
            return {'error': str(e)}

    def _build_prediction_response(self, query_type: PredictionQueryType,
                                   prediction_method: PredictionMethod,
                                   prediction_results: Dict[str, Any],
                                   scenario_simulations: Dict[str, Any],
                                   business_insights: Dict[str, Any],
                                   prediction_dataset: Dict[str, Any],
                                   processing_time: float) -> PredictionResponse:
        """æ„å»ºé¢„æµ‹å“åº”"""

        # æå–ä¸»è¦é¢„æµ‹ç»“æœ
        if prediction_method == PredictionMethod.AI_ENHANCED:
            ai_analysis = prediction_results.get('ai_analysis', {})
            main_prediction = ai_analysis.get('prediction_results', {})
            prediction_confidence = main_prediction.get('confidence_score', 0.7)
        else:
            main_prediction = prediction_results.get('predictions', {})
            prediction_confidence = 0.6  # éAIæ–¹æ³•çš„é»˜è®¤ç½®ä¿¡åº¦

        # è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†
        data_quality_score = prediction_dataset.get('metadata', {}).get('data_quality', 0.8)

        # ç¡®å®šé¢„æµ‹æ—¶é—´è·¨åº¦
        prediction_days = prediction_dataset.get('metadata', {}).get('prediction_days', 30)
        prediction_horizon = f"{prediction_days}å¤©"

        return PredictionResponse(
            query_type=query_type,
            prediction_method=prediction_method,

            main_prediction=main_prediction,
            prediction_confidence=prediction_confidence,
            prediction_horizon=prediction_horizon,

            scenario_analysis=scenario_simulations,
            sensitivity_analysis={},  # å¯ä»¥æ‰©å±•
            alternative_scenarios=scenario_simulations.get('scenarios', []),

            business_implications=business_insights.get('business_implications', []),
            risk_factors=business_insights.get('risk_factors', []),
            opportunities=business_insights.get('opportunities', []),
            recommendations=business_insights.get('recommendations', []),

            data_quality_score=data_quality_score,
            prediction_warnings=[],
            methodology_notes=[
                f"ä½¿ç”¨{prediction_method.value}é¢„æµ‹æ–¹æ³•",
                f"åŸºäº{prediction_dataset.get('metadata', {}).get('historical_days', 60)}å¤©å†å²æ•°æ®",
                f"é¢„æµ‹æ—¶é—´è·¨åº¦{prediction_days}å¤©"
            ],

            processing_time=processing_time,
            data_sources_used=['system', 'historical'],
            generated_at=datetime.now().isoformat()
        )

    def _create_error_response(self, user_query: str, error: str) -> PredictionResponse:
        """åˆ›å»ºé”™è¯¯å“åº”"""
        return PredictionResponse(
            query_type=PredictionQueryType.TREND_FORECAST,
            prediction_method=PredictionMethod.AI_ENHANCED,

            main_prediction={'error': error},
            prediction_confidence=0.0,
            prediction_horizon="error",

            scenario_analysis={},
            sensitivity_analysis={},
            alternative_scenarios=[],

            business_implications=[f"é¢„æµ‹å¤±è´¥: {error}"],
            risk_factors=[],
            opportunities=[],
            recommendations=["è¯·æ£€æŸ¥æŸ¥è¯¢å‚æ•°å¹¶é‡è¯•"],

            data_quality_score=0.0,
            prediction_warnings=[f"é¢„æµ‹é”™è¯¯: {error}"],
            methodology_notes=[],

            processing_time=0.0,
            data_sources_used=[],
            generated_at=datetime.now().isoformat()
        )

    def _update_processing_stats(self, query_type: PredictionQueryType,
                                 processing_time: float, confidence: float):
        """æ›´æ–°å¤„ç†ç»Ÿè®¡"""
        try:
            # æ›´æ–°æŸ¥è¯¢ç±»å‹ç»Ÿè®¡
            type_key = query_type.value
            if type_key not in self.processing_stats['predictions_by_type']:
                self.processing_stats['predictions_by_type'][type_key] = 0
            self.processing_stats['predictions_by_type'][type_key] += 1

            # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
            total = self.processing_stats['total_predictions']
            current_avg_time = self.processing_stats['avg_processing_time']
            new_avg_time = (current_avg_time * (total - 1) + processing_time) / total
            self.processing_stats['avg_processing_time'] = new_avg_time

            # æ›´æ–°å¹³å‡ç½®ä¿¡åº¦
            current_avg_conf = self.processing_stats['avg_confidence']
            new_avg_conf = (current_avg_conf * (total - 1) + confidence) / total
            self.processing_stats['avg_confidence'] = new_avg_conf

            # æ›´æ–°æˆåŠŸé¢„æµ‹æ•°
            if confidence > 0.5:
                self.processing_stats['successful_predictions'] += 1

            # æ›´æ–°ç¼“å­˜å‘½ä¸­ç‡
            total_cache = self.processing_stats['cache_hits'] + self.processing_stats['cache_misses']
            if total_cache > 0:
                self.processing_stats['cache_hit_rate'] = self.processing_stats['cache_hits'] / total_cache

        except Exception as e:
            logger.error(f"ç»Ÿè®¡ä¿¡æ¯æ›´æ–°å¤±è´¥: {str(e)}")

    # ============= ä¾¿æ·é¢„æµ‹æ–¹æ³• =============

    async def predict_cash_runway(self, current_balance: float, daily_outflow: float) -> Dict[str, Any]:
        """å¿«é€Ÿé¢„æµ‹ç°é‡‘è·‘é“"""
        try:
            if daily_outflow <= 0:
                return {
                    'runway_days': float('inf'),
                    'runway_months': float('inf'),
                    'risk_level': 'low',
                    'note': 'æ— ç°é‡‘æµå‡ºï¼Œèµ„é‡‘å¯æŒç»­'
                }

            runway_days = current_balance / daily_outflow
            runway_months = runway_days / 30

            risk_level = 'high' if runway_days < 60 else 'medium' if runway_days < 180 else 'low'

            return {
                'current_balance': current_balance,
                'daily_outflow': daily_outflow,
                'runway_days': runway_days,
                'runway_months': runway_months,
                'depletion_date': (datetime.now() + timedelta(days=runway_days)).strftime('%Y-%m-%d'),
                'risk_level': risk_level,
                'recommendations': self._get_runway_recommendations(runway_days)
            }

        except Exception as e:
            logger.error(f"ç°é‡‘è·‘é“é¢„æµ‹å¤±è´¥: {str(e)}")
            return {'error': str(e)}

    def _get_runway_recommendations(self, runway_days: float) -> List[str]:
        """æ ¹æ®ç°é‡‘è·‘é“å¤©æ•°ç”Ÿæˆå»ºè®®"""
        if runway_days < 30:
            return ["ç´§æ€¥æ§åˆ¶æ”¯å‡º", "ç«‹å³å¯»æ‰¾èèµ„", "æš‚åœéå¿…è¦æŠ•èµ„"]
        elif runway_days < 90:
            return ["åŠ å¼ºç°é‡‘æµç®¡ç†", "è€ƒè™‘èèµ„è®¡åˆ’", "ä¼˜åŒ–æ”¯å‡ºç»“æ„"]
        elif runway_days < 180:
            return ["å»ºç«‹ç°é‡‘æµç›‘æ§", "åˆ¶å®šé¢„è­¦æœºåˆ¶", "ä¼˜åŒ–èµ„é‡‘é…ç½®"]
        else:
            return ["ç»´æŒå½“å‰ç­–ç•¥", "å®šæœŸç›‘æ§ç°é‡‘æµ", "è€ƒè™‘æŠ•èµ„æœºä¼š"]

    async def simulate_reinvestment_scenarios(self, base_outflow: float,
                                              reinvestment_rates: List[float],
                                              days: int = 30) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿå¤æŠ•åœºæ™¯"""
        try:
            scenarios = {}

            for rate in reinvestment_rates:
                net_outflow = base_outflow * (1 - rate)
                reinvested_amount = base_outflow * rate
                monthly_savings = reinvested_amount * 30

                scenarios[f'{int(rate * 100)}%_reinvestment'] = {
                    'reinvestment_rate': rate,
                    'daily_net_outflow': net_outflow,
                    'daily_reinvested': reinvested_amount,
                    'period_savings': reinvested_amount * days,
                    'monthly_savings': monthly_savings,
                    'annual_savings': monthly_savings * 12
                }

            return {
                'base_daily_outflow': base_outflow,
                'simulation_period_days': days,
                'scenarios': scenarios,
                'recommended_rate': self._recommend_optimal_reinvestment_rate(scenarios)
            }

        except Exception as e:
            logger.error(f"å¤æŠ•åœºæ™¯æ¨¡æ‹Ÿå¤±è´¥: {str(e)}")
            return {'error': str(e)}

    def _recommend_optimal_reinvestment_rate(self, scenarios: Dict[str, Any]) -> Dict[str, Any]:
        """æ¨èæœ€ä¼˜å¤æŠ•ç‡"""
        # ç®€å•é€»è¾‘ï¼šæ¨è50%å¤æŠ•ç‡ä½œä¸ºå¹³è¡¡ç‚¹
        return {
            'recommended_rate': 0.5,
            'reasoning': 'å¹³è¡¡èµ„é‡‘æµåŠ¨æ€§å’Œé•¿æœŸå¢é•¿',
            'alternative_rates': [0.3, 0.7],
            'factors_to_consider': ['å¸‚åœºç¯å¢ƒ', 'æµåŠ¨æ€§éœ€æ±‚', 'å¢é•¿ç›®æ ‡']
        }

    # ============= å¤–éƒ¨æ¥å£æ–¹æ³• =============

    def get_processing_stats(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.processing_stats.copy()

        # æ·»åŠ æˆåŠŸç‡
        if stats['total_predictions'] > 0:
            stats['success_rate'] = stats['successful_predictions'] / stats['total_predictions']
        else:
            stats['success_rate'] = 0.0

        return stats

    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        return {
            "status": "healthy",
            "component_name": "PredictionProcessor",
            "ai_clients": {
                "claude_available": self.claude_client is not None,
                "gpt_available": self.gpt_client is not None
            },
            "supported_prediction_types": [t.value for t in PredictionQueryType],
            "supported_prediction_methods": [m.value for m in PredictionMethod],
            "cache_performance": {
                "cache_hit_rate": self.processing_stats['cache_hit_rate'],
                "total_cached_calls": self.processing_stats['cache_hits'] + self.processing_stats['cache_misses']
            },
            "processing_stats": self.get_processing_stats(),
            "timestamp": datetime.now().isoformat()
        }

    def get_supported_prediction_types(self) -> List[str]:
        """è·å–æ”¯æŒçš„é¢„æµ‹ç±»å‹"""
        return [ptype.value for ptype in PredictionQueryType]

    def validate_prediction_parameters(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯é¢„æµ‹å‚æ•°"""
        validation_result = {
            'is_valid': True,
            'issues': [],
            'warnings': []
        }

        try:
            # æ£€æŸ¥æ—¶é—´èŒƒå›´
            time_horizon = params.get('time_horizon', {})
            prediction_days = time_horizon.get('prediction_days', 30)

            if prediction_days <= 0:
                validation_result['issues'].append("é¢„æµ‹å¤©æ•°å¿…é¡»å¤§äº0")
                validation_result['is_valid'] = False

            if prediction_days > self.prediction_config['max_prediction_horizon']:
                validation_result['warnings'].append(
                    f"é¢„æµ‹æ—¶é—´è·¨åº¦è¾ƒé•¿({prediction_days}å¤©)ï¼Œç½®ä¿¡åº¦å¯èƒ½è¾ƒä½"
                )

            # æ£€æŸ¥åœºæ™¯å‚æ•°
            scenario_params = params.get('scenario_parameters', {})
            reinvest_rate = scenario_params.get('reinvestment_rate')

            if reinvest_rate is not None and not (0 <= reinvest_rate <= 1):
                validation_result['issues'].append("å¤æŠ•ç‡å¿…é¡»åœ¨0-1ä¹‹é—´")
                validation_result['is_valid'] = False

        except Exception as e:
            validation_result['issues'].append(f"å‚æ•°éªŒè¯å‡ºé”™: {str(e)}")
            validation_result['is_valid'] = False

        return validation_result


# ============= å·¥å‚å‡½æ•° =============

def create_prediction_processor(claude_client=None, gpt_client=None) -> PredictionProcessor:
    """
    åˆ›å»ºé¢„æµ‹å¤„ç†å™¨å®ä¾‹

    Args:
        claude_client: Claudeå®¢æˆ·ç«¯å®ä¾‹
        gpt_client: GPTå®¢æˆ·ç«¯å®ä¾‹

    Returns:
        PredictionProcessor: é¢„æµ‹å¤„ç†å™¨å®ä¾‹
    """
    return PredictionProcessor(claude_client, gpt_client)


# ============= ä½¿ç”¨ç¤ºä¾‹ =============

async def main():
    """ä½¿ç”¨ç¤ºä¾‹"""

    # åˆ›å»ºé¢„æµ‹å¤„ç†å™¨
    processor = create_prediction_processor()

    print("=== é¢„æµ‹åˆ†æå¤„ç†å™¨æµ‹è¯• ===")

    # æµ‹è¯•ä¸åŒç±»å‹çš„é¢„æµ‹æŸ¥è¯¢
    test_queries = [
        "æ ¹æ®è¿‡å»60å¤©æ•°æ®ï¼Œé¢„æµ‹7æœˆä»½å¦‚æœ30%å¤æŠ•çš„èµ„é‡‘æƒ…å†µ",
        "æ— å…¥é‡‘æƒ…å†µä¸‹å…¬å¸è¿˜èƒ½è¿è¡Œå¤šä¹…ï¼Ÿ",
        "åŸºäºå½“å‰å¢é•¿é¢„æµ‹æœªæ¥ç”¨æˆ·æ•°é‡",
        "å¦‚æœå¤æŠ•ç‡æé«˜åˆ°80%ä¼šæ€æ ·ï¼Ÿ"
    ]

    for i, query in enumerate(test_queries, 1):
        print(f"\n--- æµ‹è¯•æŸ¥è¯¢ {i} ---")
        print(f"æŸ¥è¯¢: {query}")

        try:
            response = await processor.process_prediction_query(query)

            print(f"é¢„æµ‹ç±»å‹: {response.query_type.value}")
            print(f"é¢„æµ‹æ–¹æ³•: {response.prediction_method.value}")
            print(f"é¢„æµ‹æ—¶é—´è·¨åº¦: {response.prediction_horizon}")
            print(f"ç½®ä¿¡åº¦: {response.prediction_confidence:.2f}")
            print(f"å¤„ç†æ—¶é—´: {response.processing_time:.2f}ç§’")

            # æ˜¾ç¤ºä¸»è¦é¢„æµ‹ç»“æœ
            if response.main_prediction:
                print("é¢„æµ‹ç»“æœ:")
                for key, value in list(response.main_prediction.items())[:3]:
                    print(f"  - {key}: {value}")

            # æ˜¾ç¤ºä¸šåŠ¡å»ºè®®
            if response.recommendations:
                print("å»ºè®®:")
                for rec in response.recommendations[:2]:
                    print(f"  â€¢ {rec}")

        except Exception as e:
            print(f"æŸ¥è¯¢å¤±è´¥: {str(e)}")

    # ä¾¿æ·æ–¹æ³•æµ‹è¯•
    print(f"\n=== ä¾¿æ·æ–¹æ³•æµ‹è¯• ===")

    # ç°é‡‘è·‘é“é¢„æµ‹
    runway_result = await processor.predict_cash_runway(85000000, 800000)
    print(f"ç°é‡‘è·‘é“: {runway_result.get('runway_days', 0):.0f}å¤©")

    # å¤æŠ•å½±å“æ¨¡æ‹Ÿ
    reinvest_result = await processor.simulate_reinvestment_scenarios(
        base_outflow=800000,
        reinvestment_rates=[0.0, 0.3, 0.5, 0.7],
        days=30
    )
    print(f"å¤æŠ•æ¨¡æ‹Ÿåœºæ™¯æ•°: {len(reinvest_result.get('scenarios', {}))}")

    # å¥åº·æ£€æŸ¥
    health_status = await processor.health_check()
    print(f"ç³»ç»Ÿå¥åº·çŠ¶æ€: {health_status['status']}")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = processor.get_processing_stats()
    print(f"æ€»é¢„æµ‹æ¬¡æ•°: {stats['total_predictions']}")
    print(f"å¹³å‡ç½®ä¿¡åº¦: {stats['avg_confidence']:.2f}")


if __name__ == "__main__":
    asyncio.run(main())