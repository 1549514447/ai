# core/processors/current_data_processor.py
"""
ğŸ“Š å½“å‰æ•°æ®å¤„ç†å™¨
ä¸“é—¨å¤„ç†å®æ—¶çŠ¶æ€æŸ¥è¯¢ï¼Œå¦‚"ä»Šå¤©ä½™é¢å¤šå°‘"ã€"å½“å‰ç”¨æˆ·æ•°"ç­‰ç®€å•æŸ¥è¯¢

æ ¸å¿ƒç‰¹ç‚¹:
- å¿«é€Ÿå“åº”å½“å‰çŠ¶æ€æŸ¥è¯¢
- åŸºäº /api/sta/system çš„å®æ—¶æ•°æ®
- æ™ºèƒ½æ•°æ®å¢å¼ºå’Œæ ¼å¼åŒ–
- ç®€å•æ˜“æ‡‚çš„è¾“å‡ºæ ¼å¼
- æ”¯æŒå¸¸è§çš„å®æ—¶æŒ‡æ ‡æŸ¥è¯¢
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
import asyncio
from dataclasses import dataclass
from enum import Enum
import json
from functools import lru_cache
import hashlib

# å¯¼å…¥å·²å®Œæˆçš„ç»„ä»¶
from core.analyzers.query_parser import SmartQueryParser, create_smart_query_parser
from core.analyzers.financial_data_analyzer import FinancialDataAnalyzer, create_financial_data_analyzer
from core.analyzers.insight_generator import InsightGenerator, create_insight_generator
from core.data_orchestration.smart_data_fetcher import SmartDataFetcher, create_smart_data_fetcher

logger = logging.getLogger(__name__)


class CurrentDataQueryType(Enum):
    """å½“å‰æ•°æ®æŸ¥è¯¢ç±»å‹"""
    SYSTEM_OVERVIEW = "system_overview"  # ç³»ç»Ÿæ¦‚è§ˆ "æ€»ä½“æƒ…å†µ"
    BALANCE_CHECK = "balance_check"  # ä½™é¢æŸ¥è¯¢ "ä½™é¢å¤šå°‘"
    USER_STATUS = "user_status"  # ç”¨æˆ·çŠ¶æ€ "ç”¨æˆ·æ•°é‡"
    TODAY_EXPIRY = "today_expiry"  # ä»Šæ—¥åˆ°æœŸ "ä»Šå¤©åˆ°æœŸå¤šå°‘"
    CASH_FLOW = "cash_flow"  # èµ„é‡‘æµåŠ¨ "å…¥é‡‘å‡ºé‡‘æƒ…å†µ"
    PRODUCT_STATUS = "product_status"  # äº§å“çŠ¶æ€ "äº§å“æƒ…å†µ"
    QUICK_METRICS = "quick_metrics"  # å¿«é€ŸæŒ‡æ ‡ "å…³é”®æŒ‡æ ‡"


class ResponseFormat(Enum):
    """å“åº”æ ¼å¼ç±»å‹"""
    SIMPLE_TEXT = "simple_text"  # ç®€å•æ–‡å­—
    DETAILED_SUMMARY = "detailed_summary"  # è¯¦ç»†æ‘˜è¦
    METRICS_FOCUSED = "metrics_focused"  # æŒ‡æ ‡èšç„¦
    BUSINESS_ORIENTED = "business_oriented"  # ä¸šåŠ¡å¯¼å‘


@dataclass
class CurrentDataResponse:
    """å½“å‰æ•°æ®å“åº”ç»“æœ"""
    query_type: CurrentDataQueryType  # æŸ¥è¯¢ç±»å‹
    response_format: ResponseFormat  # å“åº”æ ¼å¼

    # æ ¸å¿ƒå“åº”å†…å®¹
    main_answer: str  # ä¸»è¦å›ç­”
    key_metrics: Dict[str, Any]  # å…³é”®æŒ‡æ ‡
    formatted_data: Dict[str, str]  # æ ¼å¼åŒ–æ•°æ®

    # å¢å¼ºä¿¡æ¯
    business_context: str  # ä¸šåŠ¡ä¸Šä¸‹æ–‡
    quick_insights: List[str]  # å¿«é€Ÿæ´å¯Ÿ
    related_metrics: Dict[str, Any]  # ç›¸å…³æŒ‡æ ‡

    # å…ƒæ•°æ®
    data_timestamp: str  # æ•°æ®æ—¶é—´æˆ³
    response_confidence: float  # å“åº”ç½®ä¿¡åº¦
    data_sources: List[str]  # æ•°æ®æ¥æº
    processing_time: float  # å¤„ç†æ—¶é—´


class CurrentDataProcessor:
    """
    ğŸ“Š å½“å‰æ•°æ®å¤„ç†å™¨

    ä¸“æ³¨äºå¿«é€Ÿå¤„ç†å®æ—¶çŠ¶æ€æŸ¥è¯¢ï¼Œæä¾›å³æ—¶ã€å‡†ç¡®çš„å½“å‰çŠ¶æ€ä¿¡æ¯
    """

    def __init__(self, claude_client=None, gpt_client=None):
        """
        åˆå§‹åŒ–å½“å‰æ•°æ®å¤„ç†å™¨

        Args:
            claude_client: Claudeå®¢æˆ·ç«¯ï¼Œç”¨äºä¸šåŠ¡ç†è§£å’Œæ´å¯Ÿ
            gpt_client: GPTå®¢æˆ·ç«¯ï¼Œç”¨äºæ•°æ®æ ¼å¼åŒ–å’Œè®¡ç®—
        """
        self.claude_client = claude_client
        self.gpt_client = gpt_client

        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.query_parser = create_smart_query_parser(claude_client, gpt_client)
        self.data_fetcher = create_smart_data_fetcher(claude_client, gpt_client)
        self.data_analyzer = create_financial_data_analyzer(claude_client, gpt_client)
        self.insight_generator = create_insight_generator(claude_client, gpt_client)

        # å½“å‰æ•°æ®å¤„ç†é…ç½®
        self.processing_config = self._load_processing_config()

        # å¸¸ç”¨æŸ¥è¯¢æ¨¡å¼åŒ¹é…
        self.query_patterns = self._load_current_data_patterns()

        # å¤„ç†ç»Ÿè®¡
        self.processing_stats = {
            'total_queries': 0,
            'queries_by_type': {},
            'avg_response_time': 0.0,
            'avg_confidence': 0.0,
            'cache_hit_rate': 0.0,
            'cache_hits': 0,
            'cache_misses': 0
        }

        logger.info("CurrentDataProcessor initialized for real-time queries")

    def _get_query_hash(self, query: str) -> str:
        """ç”ŸæˆæŸ¥è¯¢å“ˆå¸Œå€¼ç”¨äºç¼“å­˜"""
        return hashlib.md5(query.encode('utf-8')).hexdigest()

    @lru_cache(maxsize=100)
    async def _cached_ai_analysis(self, query_hash: str, prompt: str) -> Dict[str, Any]:
        """ç¼“å­˜AIåˆ†æç»“æœ"""
        # æ›´æ–°ç¼“å­˜ç»Ÿè®¡
        self.processing_stats['cache_misses'] += 1
        
        # å¥å£®çš„Claudeå®¢æˆ·ç«¯è°ƒç”¨é€»è¾‘
        try:
            if not self.claude_client:
                logger.error("Claudeå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                return {"response": "AIåˆ†ææœåŠ¡ä¸å¯ç”¨"}
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªå®šä¹‰çš„ClaudeClientç±»
            if hasattr(self.claude_client, 'analyze_complex_query') and callable(getattr(self.claude_client, 'analyze_complex_query')):
                logger.info("ä½¿ç”¨è‡ªå®šä¹‰ClaudeClientçš„analyze_complex_queryæ–¹æ³•")
                return await self.claude_client.analyze_complex_query(prompt, {})
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥ç›´æ¥ä½¿ç”¨messages API (æ–°ç‰ˆSDK)
            if hasattr(self.claude_client, 'messages') and callable(getattr(self.claude_client.messages, 'create', None)):
                logger.info("ä½¿ç”¨messages APIè°ƒç”¨Claude")
                response = await asyncio.to_thread(
                    self.claude_client.messages.create,
                    model="claude-3-opus-20240229",
                    max_tokens=1000,
                    messages=[{"role": "user", "content": prompt}]
                )
                if hasattr(response, 'content') and response.content:
                    content_text = ""
                    for content_item in response.content:
                        if hasattr(content_item, 'text'):
                            content_text += content_item.text
                        elif isinstance(content_item, dict) and 'text' in content_item:
                            content_text += content_item['text']
                    return {"response": content_text}
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨completion API (æ—§ç‰ˆSDK)
            if hasattr(self.claude_client, 'completions') and callable(getattr(self.claude_client.completions, 'create', None)):
                logger.info("ä½¿ç”¨completions APIè°ƒç”¨Claude")
                response = await asyncio.to_thread(
                    self.claude_client.completions.create,
                    model="claude-3-opus-20240229",
                    prompt=f"\n\nHuman: {prompt}\n\nAssistant:",
                    max_tokens_to_sample=1000
                )
                if hasattr(response, 'completion'):
                    return {"response": response.completion}
                
            # å°è¯•ç›´æ¥è°ƒç”¨clientçš„completionæ–¹æ³• (æœ€æ—§ç‰ˆæœ¬)
            if hasattr(self.claude_client, 'completion') and callable(self.claude_client.completion):
                logger.info("ä½¿ç”¨æ—§ç‰ˆcompletionæ–¹æ³•è°ƒç”¨Claude")
                response = await asyncio.to_thread(
                    self.claude_client.completion,
                    prompt=f"\n\nHuman: {prompt}\n\nAssistant:",
                    max_tokens_to_sample=1000
                )
                if hasattr(response, 'completion'):
                    return {"response": response.completion}
            
            # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            logger.error("æ— æ³•æ‰¾åˆ°å¯ç”¨çš„Claude APIè°ƒç”¨æ–¹æ³•")
            return {"response": "AIåˆ†ææœåŠ¡è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥Claudeå®¢æˆ·ç«¯é…ç½®"}
            
        except Exception as e:
            logger.error(f"AIåˆ†æè°ƒç”¨å¤±è´¥: {str(e)}")
            return {"response": f"AIåˆ†æå‡ºé”™: {str(e)}"}

    async def _identify_current_data_query_type(self, user_query: str) -> CurrentDataQueryType:
        """AIé©±åŠ¨çš„æŸ¥è¯¢ç±»å‹è¯†åˆ«"""
        try:
            if not self.claude_client:
                # å¦‚æœæ²¡æœ‰AIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨é»˜è®¤ç±»å‹
                logger.warning("æ²¡æœ‰å¯ç”¨çš„AIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨é»˜è®¤æŸ¥è¯¢ç±»å‹")
                return CurrentDataQueryType.SYSTEM_OVERVIEW
                
            prompt = f"""
            åˆ†æä»¥ä¸‹é‡‘èä¸šåŠ¡æŸ¥è¯¢ï¼Œè¯†åˆ«æŸ¥è¯¢ç±»å‹ï¼š

            ç”¨æˆ·æŸ¥è¯¢: "{user_query}"

            è¯·ä»ä»¥ä¸‹ç±»å‹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ä¸€ä¸ª:
            - system_overview: ç³»ç»Ÿæ¦‚è§ˆæŸ¥è¯¢ï¼Œå¦‚"æ€»ä½“æƒ…å†µ"ã€"ç³»ç»ŸçŠ¶æ€"
            - balance_check: ä½™é¢æŸ¥è¯¢ï¼Œå¦‚"ä½™é¢å¤šå°‘"ã€"æ€»èµ„é‡‘"
            - user_status: ç”¨æˆ·çŠ¶æ€æŸ¥è¯¢ï¼Œå¦‚"ç”¨æˆ·æ•°é‡"ã€"æ´»è·ƒç”¨æˆ·"
            - today_expiry: ä»Šæ—¥åˆ°æœŸæŸ¥è¯¢ï¼Œå¦‚"ä»Šå¤©åˆ°æœŸå¤šå°‘"
            - cash_flow: èµ„é‡‘æµåŠ¨æŸ¥è¯¢ï¼Œå¦‚"å…¥é‡‘å‡ºé‡‘æƒ…å†µ"
            - product_status: äº§å“çŠ¶æ€æŸ¥è¯¢ï¼Œå¦‚"äº§å“æƒ…å†µ"
            - quick_metrics: å¿«é€ŸæŒ‡æ ‡æŸ¥è¯¢ï¼Œå¦‚"å…³é”®æŒ‡æ ‡"

            åªè¿”å›ç±»å‹ID (å¦‚ "balance_check")ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚
            """

            # ä½¿ç”¨ç¼“å­˜
            query_hash = self._get_query_hash(user_query)
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜ç»“æœ
            if query_hash in self._cached_ai_analysis.cache_info().currsize:
                self.processing_stats['cache_hits'] += 1
                # æ›´æ–°ç¼“å­˜å‘½ä¸­ç‡
                total_cache_requests = self.processing_stats['cache_hits'] + self.processing_stats['cache_misses']
                if total_cache_requests > 0:
                    self.processing_stats['cache_hit_rate'] = self.processing_stats['cache_hits'] / total_cache_requests
                logger.info(f"ç¼“å­˜å‘½ä¸­: {user_query}")
                
            result = await self._cached_ai_analysis(query_hash, prompt)
        
            # æå–ç±»å‹ID
            if isinstance(result, dict) and 'response' in result:
                type_id = result['response'].strip().lower()
            else:
                type_id = str(result).strip().lower()
                
            # ç§»é™¤å¯èƒ½çš„å¼•å·
            type_id = type_id.replace('"', '').replace("'", "")
            
            # è½¬æ¢ä¸ºæšä¸¾
            try:
                return CurrentDataQueryType(type_id)
            except ValueError:
                logger.warning(f"æ— æ³•è¯†åˆ«çš„æŸ¥è¯¢ç±»å‹: {type_id}ï¼Œä½¿ç”¨é»˜è®¤ç±»å‹")
                return CurrentDataQueryType.SYSTEM_OVERVIEW
            
        except Exception as e:
            logger.warning(f"AIæŸ¥è¯¢ç±»å‹è¯†åˆ«å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤ç±»å‹")
            return CurrentDataQueryType.SYSTEM_OVERVIEW

    async def _process_by_query_type(self, query_type: CurrentDataQueryType, 
                                   user_query: str, current_data: Dict[str, Any], 
                                   additional_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        AIé©±åŠ¨çš„æŸ¥è¯¢å¤„ç†ï¼Œæ ¹æ®æŸ¥è¯¢ç±»å‹å¤„ç†æ•°æ®
        
        Args:
            query_type: æŸ¥è¯¢ç±»å‹
            user_query: ç”¨æˆ·æŸ¥è¯¢
            current_data: å½“å‰ç³»ç»Ÿæ•°æ®
            additional_context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Returns:
            å¤„ç†ç»“æœï¼ŒåŒ…å«å…³é”®æŒ‡æ ‡å’Œæ ¼å¼åŒ–æ•°æ®
        """
        try:
            logger.info(f"å¤„ç†æŸ¥è¯¢ç±»å‹: {query_type.value}")
            
            # å‡†å¤‡AIå¤„ç†æç¤º
            prompt = f"""
            å¤„ç†ä»¥ä¸‹é‡‘èæŸ¥è¯¢ï¼Œæå–å…³é”®æŒ‡æ ‡å¹¶è®¡ç®—å¿…è¦çš„æ•°æ®:
            
            æŸ¥è¯¢ç±»å‹: {query_type.value}
            ç”¨æˆ·æŸ¥è¯¢: "{user_query}"

            ç³»ç»Ÿæ•°æ®:
            ```
            {json.dumps(current_data, ensure_ascii=False, indent=2)}
            ```
            
            è¯·æå–ä¸æŸ¥è¯¢ç›¸å…³çš„å…³é”®æŒ‡æ ‡ï¼Œå¹¶è¿›è¡Œå¿…è¦çš„è®¡ç®—ã€‚è¿”å›JSONæ ¼å¼:
            {{
                "key_metrics": {{
                    "metric1": value1,
                    "metric2": value2,
                    ...
                }},
                "related_metrics": {{
                    "related1": value1,
                    ...
                }},
                "response_format": "simple_text/detailed_summary/metrics_focused/business_oriented",
                "confidence": 0.95
            }}
            """
            
            # ä½¿ç”¨ç¼“å­˜
            query_hash = self._get_query_hash(f"{query_type.value}_{user_query}")
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜ç»“æœ
            if query_hash in self._cached_ai_analysis.cache_info().currsize:
                self.processing_stats['cache_hits'] += 1
                # æ›´æ–°ç¼“å­˜å‘½ä¸­ç‡
                total_cache_requests = self.processing_stats['cache_hits'] + self.processing_stats['cache_misses']
                if total_cache_requests > 0:
                    self.processing_stats['cache_hit_rate'] = self.processing_stats['cache_hits'] / total_cache_requests
                logger.info(f"å¤„ç†ç¼“å­˜å‘½ä¸­: {query_type.value}")
                
            # ä½¿ç”¨GPTå¤„ç†æ•°æ®å’Œè®¡ç®—
            result = await self._cached_ai_analysis(query_hash, prompt)
            
            # è§£æç»“æœ
            processed_result = {}
            if isinstance(result, dict) and 'response' in result:
                try:
                    processed_result = json.loads(result['response'])
                except:
                    logger.warning("æ— æ³•è§£æAIå¤„ç†ç»“æœï¼Œä½¿ç”¨åŸå§‹å“åº”")
                    processed_result = {
                        "key_metrics": {"raw_response": result['response']},
                        "response_format": "simple_text",
                        "confidence": 0.5
                    }
            else:
                logger.warning("AIå¤„ç†è¿”å›æ„å¤–æ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤ç»“æ„")
                processed_result = {
                    "key_metrics": {"raw_response": str(result)},
                    "response_format": "simple_text",
                    "confidence": 0.5
                }
                
            # ç¡®ä¿ç»“æœåŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ
            if "key_metrics" not in processed_result:
                processed_result["key_metrics"] = {}
            if "related_metrics" not in processed_result:
                processed_result["related_metrics"] = {}
            if "response_format" not in processed_result:
                processed_result["response_format"] = "simple_text"
            if "confidence" not in processed_result:
                processed_result["confidence"] = 0.8
                
            return processed_result
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")
            return {
                "key_metrics": {"error": str(e)},
                "related_metrics": {},
                "response_format": "simple_text",
                "confidence": 0.5
            }
            
    async def _generate_quick_insights(self, query_type: CurrentDataQueryType,
                                     key_metrics: Dict[str, Any],
                                     current_data: Dict[str, Any]) -> List[str]:
        """
        AIé©±åŠ¨çš„ä¸šåŠ¡æ´å¯Ÿç”Ÿæˆ
        
        Args:
            query_type: æŸ¥è¯¢ç±»å‹
            key_metrics: å…³é”®æŒ‡æ ‡
            current_data: å½“å‰ç³»ç»Ÿæ•°æ®
            
        Returns:
            ä¸šåŠ¡æ´å¯Ÿåˆ—è¡¨
        """
        try:
            if not self.claude_client:
                logger.warning("æ²¡æœ‰å¯ç”¨çš„Claudeå®¢æˆ·ç«¯ï¼Œè·³è¿‡æ´å¯Ÿç”Ÿæˆ")
                return []
                
            # å‡†å¤‡AIå¤„ç†æç¤º
            prompt = f"""
            åŸºäºä»¥ä¸‹é‡‘èæ•°æ®ï¼Œç”Ÿæˆ3-5æ¡ç®€æ´çš„ä¸šåŠ¡æ´å¯Ÿ:
            
            æŸ¥è¯¢ç±»å‹: {query_type.value}
            
            å…³é”®æŒ‡æ ‡:
            ```
            {json.dumps(key_metrics, ensure_ascii=False, indent=2)}
            ```
            
            ç³»ç»Ÿæ•°æ®:
            ```
            {json.dumps(current_data, ensure_ascii=False, indent=2)}
            ```
            
            è¯·ç”Ÿæˆ3-5æ¡ç®€æ´ã€æœ‰ä»·å€¼çš„ä¸šåŠ¡æ´å¯Ÿï¼Œæ¯æ¡ä¸è¶…è¿‡50ä¸ªå­—ã€‚
            è¿”å›JSONæ•°ç»„æ ¼å¼ï¼Œä¾‹å¦‚:
            ["æ´å¯Ÿ1", "æ´å¯Ÿ2", "æ´å¯Ÿ3"]
            """
            
            # ä½¿ç”¨ç¼“å­˜
            metrics_str = "_".join([f"{k}:{v}" for k, v in sorted(key_metrics.items())[:3]])
            query_hash = self._get_query_hash(f"{query_type.value}_{metrics_str}")
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜ç»“æœ
            if query_hash in self._cached_ai_analysis.cache_info().currsize:
                self.processing_stats['cache_hits'] += 1
                # æ›´æ–°ç¼“å­˜å‘½ä¸­ç‡
                total_cache_requests = self.processing_stats['cache_hits'] + self.processing_stats['cache_misses']
                if total_cache_requests > 0:
                    self.processing_stats['cache_hit_rate'] = self.processing_stats['cache_hits'] / total_cache_requests
                logger.info("æ´å¯Ÿç¼“å­˜å‘½ä¸­")
                
            # ä½¿ç”¨Claudeç”Ÿæˆæ´å¯Ÿ
            result = await self._cached_ai_analysis(query_hash, prompt)
            
            # è§£æç»“æœ
            insights = []
            if isinstance(result, dict) and 'response' in result:
                try:
                    insights = json.loads(result['response'])
                except:
                    logger.warning("æ— æ³•è§£æAIæ´å¯Ÿç»“æœï¼Œä½¿ç”¨åŸå§‹å“åº”")
                    insights = [result['response']]
            else:
                logger.warning("AIæ´å¯Ÿè¿”å›æ„å¤–æ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤ç»“æ„")
                insights = [str(result)]
                
            # ç¡®ä¿ç»“æœæ˜¯åˆ—è¡¨ç±»å‹
            if not isinstance(insights, list):
                insights = [str(insights)]
                
            # é™åˆ¶æ´å¯Ÿæ•°é‡
            return insights[:5]
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ´å¯Ÿå¤±è´¥: {str(e)}")
            return []
            
    async def _format_current_data_response(self, query_type: CurrentDataQueryType,
                                          user_query: str,
                                          processed_result: Dict[str, Any],
                                          quick_insights: List[str]) -> Dict[str, Any]:
        """
        AIé©±åŠ¨çš„å“åº”æ ¼å¼åŒ–
        
        Args:
            query_type: æŸ¥è¯¢ç±»å‹
            user_query: ç”¨æˆ·æŸ¥è¯¢
            processed_result: å¤„ç†ç»“æœ
            quick_insights: ä¸šåŠ¡æ´å¯Ÿ
            
        Returns:
            æ ¼å¼åŒ–çš„å“åº”
        """
        try:
            if not self.gpt_client:
                logger.warning("æ²¡æœ‰å¯ç”¨çš„GPTå®¢æˆ·ç«¯ï¼Œä½¿ç”¨ç®€å•æ ¼å¼åŒ–")
                return {
                    "main_answer": f"æŸ¥è¯¢ç±»å‹: {query_type.value}\nå…³é”®æŒ‡æ ‡: {json.dumps(processed_result.get('key_metrics', {}), ensure_ascii=False)}",
                    "formatted_data": {"raw": json.dumps(processed_result, ensure_ascii=False)},
                    "business_context": ""
                }
                
            # å‡†å¤‡AIå¤„ç†æç¤º
            response_format = processed_result.get('response_format', 'simple_text')
            
            prompt = f"""
            åŸºäºä»¥ä¸‹é‡‘èæ•°æ®ï¼Œç”Ÿæˆç”¨æˆ·å‹å¥½çš„å“åº”:
            
            æŸ¥è¯¢ç±»å‹: {query_type.value}
            ç”¨æˆ·æŸ¥è¯¢: "{user_query}"
            
            å…³é”®æŒ‡æ ‡:
            ```
            {json.dumps(processed_result.get('key_metrics', {}), ensure_ascii=False, indent=2)}
            ```
            
            ä¸šåŠ¡æ´å¯Ÿ:
            ```
            {json.dumps(quick_insights, ensure_ascii=False, indent=2)}
            ```
            
            å“åº”æ ¼å¼: {response_format}
            
            è¯·ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„å“åº”ï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†:
            1. main_answer: ä¸»è¦å›ç­”ï¼Œç®€æ´æ˜äº†
            2. formatted_data: æ ¼å¼åŒ–çš„æ•°æ®å±•ç¤º
            3. business_context: ä¸šåŠ¡ä¸Šä¸‹æ–‡è¯´æ˜
            
            è¿”å›JSONæ ¼å¼:
            {{
                "main_answer": "...",
                "formatted_data": {{
                    "key1": "value1",
                    ...
                }},
                "business_context": "..."
            }}
            """
            
            # ä½¿ç”¨ç¼“å­˜
            metrics_str = "_".join([f"{k}" for k in sorted(processed_result.get('key_metrics', {}).keys())[:3]])
            insights_str = "_".join(quick_insights[:2]) if quick_insights else ""
            query_hash = self._get_query_hash(f"{query_type.value}_{metrics_str}_{insights_str}")
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜ç»“æœ
            if query_hash in self._cached_ai_analysis.cache_info().currsize:
                self.processing_stats['cache_hits'] += 1
                # æ›´æ–°ç¼“å­˜å‘½ä¸­ç‡
                total_cache_requests = self.processing_stats['cache_hits'] + self.processing_stats['cache_misses']
                if total_cache_requests > 0:
                    self.processing_stats['cache_hit_rate'] = self.processing_stats['cache_hits'] / total_cache_requests
                logger.info("æ ¼å¼åŒ–ç¼“å­˜å‘½ä¸­")
                
            # ä½¿ç”¨GPTæ ¼å¼åŒ–å“åº”
            result = await self._cached_ai_analysis(query_hash, prompt)
            
            # è§£æç»“æœ
            formatted_response = {}
            if isinstance(result, dict) and 'response' in result:
                try:
                    formatted_response = json.loads(result['response'])
                except:
                    logger.warning("æ— æ³•è§£æAIæ ¼å¼åŒ–ç»“æœï¼Œä½¿ç”¨åŸå§‹å“åº”")
                    formatted_response = {
                        "main_answer": result['response'],
                        "formatted_data": {"raw": json.dumps(processed_result.get('key_metrics', {}), ensure_ascii=False)},
                        "business_context": ""
                    }
            else:
                logger.warning("AIæ ¼å¼åŒ–è¿”å›æ„å¤–æ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤ç»“æ„")
                formatted_response = {
                    "main_answer": str(result),
                    "formatted_data": {"raw": json.dumps(processed_result.get('key_metrics', {}), ensure_ascii=False)},
                    "business_context": ""
                }
                
            # ç¡®ä¿ç»“æœåŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ
            if "main_answer" not in formatted_response:
                formatted_response["main_answer"] = f"æŸ¥è¯¢ç±»å‹: {query_type.value}"
            if "formatted_data" not in formatted_response:
                formatted_response["formatted_data"] = {"raw": json.dumps(processed_result.get('key_metrics', {}), ensure_ascii=False)}
            if "business_context" not in formatted_response:
                formatted_response["business_context"] = ""
                
            return formatted_response
            
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–å“åº”å¤±è´¥: {str(e)}")
            return {
                "main_answer": f"æŸ¥è¯¢ç±»å‹: {query_type.value}\nå…³é”®æŒ‡æ ‡: {json.dumps(processed_result.get('key_metrics', {}), ensure_ascii=False)}",
                "formatted_data": {"raw": json.dumps(processed_result, ensure_ascii=False)},
                "business_context": f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
            }

    async def process_multiple_queries(self, queries: List[str]) -> List[CurrentDataResponse]:
        """æ‰¹é‡å¤„ç†å¤šä¸ªæŸ¥è¯¢ï¼Œå‡å°‘AIè°ƒç”¨æ¬¡æ•°"""
        
        # å¦‚æœæŸ¥è¯¢æ•°é‡å°‘ï¼Œç›´æ¥é€ä¸ªå¤„ç†
        if len(queries) <= 2:
            return [await self.process_current_data_query(q) for q in queries]
        
        try:
            # æ‰¹é‡è¯†åˆ«æŸ¥è¯¢ç±»å‹
            combined_prompt = f"""
            æ‰¹é‡åˆ†æä»¥ä¸‹{len(queries)}ä¸ªé‡‘èæŸ¥è¯¢çš„ç±»å‹ï¼š

            {chr(10).join([f"{i+1}. {q}" for i, q in enumerate(queries)])}

            å¯¹æ¯ä¸ªæŸ¥è¯¢ï¼Œåªè¿”å›å…¶ç±»å‹IDï¼š
            - system_overview
            - balance_check
            - user_status
            - today_expiry
            - cash_flow
            - product_status
            - quick_metrics

            è¿”å›JSONæ•°ç»„æ ¼å¼ï¼Œä¾‹å¦‚ï¼š
            ["balance_check", "user_status", "system_overview"]
            """
            
            # ä¸€æ¬¡AIè°ƒç”¨å¤„ç†å¤šä¸ªæŸ¥è¯¢ç±»å‹
            result = await self.claude_client.analyze_complex_query(combined_prompt, {})
            
            # è§£æç»“æœ
            query_types = []
            if isinstance(result, dict) and 'response' in result:
                try:
                    query_types = json.loads(result['response'])
                except:
                    # é™çº§åˆ°å•ç‹¬å¤„ç†
                    return [await self.process_current_data_query(q) for q in queries]
            
            # ç¡®ä¿ç±»å‹æ•°é‡åŒ¹é…
            if len(query_types) != len(queries):
                # é™çº§åˆ°å•ç‹¬å¤„ç†
                return [await self.process_current_data_query(q) for q in queries]
                
            # è·å–ç³»ç»Ÿæ•°æ®ï¼ˆåªéœ€è·å–ä¸€æ¬¡ï¼‰
            current_data = await self._fetch_current_system_data()
            
            # å¤„ç†æ¯ä¸ªæŸ¥è¯¢
            responses = []
            for i, query in enumerate(queries):
                try:
                    query_type = CurrentDataQueryType(query_types[i])
                    # ä½¿ç”¨å·²è·å–çš„ç³»ç»Ÿæ•°æ®å¤„ç†æŸ¥è¯¢
                    response = await self._process_query_with_data(query, query_type, current_data)
                    responses.append(response)
                except Exception as e:
                    logger.error(f"å¤„ç†æŸ¥è¯¢ '{query}' å¤±è´¥: {str(e)}")
                    # å•ä¸ªæŸ¥è¯¢å¤±è´¥æ—¶ï¼Œé™çº§å¤„ç†è¯¥æŸ¥è¯¢
                    responses.append(await self.process_current_data_query(query))
                    
            return responses
            
        except Exception as e:
            logger.error(f"æ‰¹é‡æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")
            # é™çº§åˆ°å•ç‹¬å¤„ç†
            return [await self.process_current_data_query(q) for q in queries]
            
    async def _process_query_with_data(self, user_query: str, query_type: CurrentDataQueryType, 
                                current_data: Dict[str, Any]) -> CurrentDataResponse:
        """ä½¿ç”¨å·²è·å–çš„æ•°æ®å¤„ç†å•ä¸ªæŸ¥è¯¢"""
        try:
            logger.info(f"ğŸ“Š ä½¿ç”¨å·²è·å–æ•°æ®å¤„ç†æŸ¥è¯¢: {user_query}")

            start_time = datetime.now()
            self.processing_stats['total_queries'] += 1

            # Step 3: GPT-4oå¤„ç†æ•°æ®å’Œè®¡ç®—
            processed_result = await self._process_by_query_type(
                query_type, user_query, current_data, None
            )
            logger.info(f"æ•°æ®å¤„ç†å®Œæˆï¼Œå…³é”®æŒ‡æ ‡: {list(processed_result.get('key_metrics', {}).keys())}")

            # Step 4: Claudeç”Ÿæˆä¸šåŠ¡æ´å¯Ÿ
            quick_insights = await self._generate_quick_insights(
                query_type, processed_result['key_metrics'], current_data
            )
            logger.info(f"ç”Ÿæˆæ´å¯Ÿ: {len(quick_insights)}æ¡")

            # Step 5: GPT-4oæ ¼å¼åŒ–å“åº”
            formatted_response = await self._format_current_data_response(
                query_type, user_query, processed_result, quick_insights
            )
            logger.info("å“åº”æ ¼å¼åŒ–å®Œæˆ")

            # Step 6: æ„å»ºæœ€ç»ˆå“åº”
            processing_time = (datetime.now() - start_time).total_seconds()

            response = CurrentDataResponse(
                query_type=query_type,
                response_format=processed_result.get('response_format', ResponseFormat.SIMPLE_TEXT),

                main_answer=formatted_response['main_answer'],
                key_metrics=processed_result['key_metrics'],
                formatted_data=formatted_response['formatted_data'],

                business_context=formatted_response.get('business_context', ''),
                quick_insights=quick_insights,
                related_metrics=processed_result.get('related_metrics', {}),

                data_timestamp=current_data.get('timestamp', datetime.now().isoformat()),
                response_confidence=processed_result.get('confidence', 0.8),
                data_sources=['/api/sta/system'],
                processing_time=processing_time
            )

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_processing_stats(query_type, processing_time, response.response_confidence)

            logger.info(f"âœ… æ‰¹é‡æŸ¥è¯¢å¤„ç†å®Œæˆï¼Œè€—æ—¶{processing_time:.2f}ç§’")

            return response

        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")
            return self._create_error_response(user_query, str(e))

    async def process_current_data_query(self, user_query: str) -> CurrentDataResponse:
        """å¤„ç†å½“å‰æ•°æ®æŸ¥è¯¢"""
        try:
            logger.info(f"ğŸ“Š å¤„ç†å½“å‰æ•°æ®æŸ¥è¯¢: {user_query}")
            
            start_time = datetime.now()
            self.processing_stats['total_queries'] += 1
            
            # Step 1: è¯†åˆ«æŸ¥è¯¢ç±»å‹
            query_type = await self._identify_current_data_query_type(user_query)
            logger.info(f"è¯†åˆ«æŸ¥è¯¢ç±»å‹: {query_type.value}")
            
            # Step 2: è·å–å½“å‰ç³»ç»Ÿæ•°æ®
            current_data = await self._fetch_current_system_data()
            logger.info(f"è·å–ç³»ç»Ÿæ•°æ®: {len(current_data)} ä¸ªå­—æ®µ")
            
            # Step 3: GPT-4oå¤„ç†æ•°æ®å’Œè®¡ç®—
            processed_result = await self._process_by_query_type(
                query_type, user_query, current_data, None
            )
            logger.info(f"æ•°æ®å¤„ç†å®Œæˆï¼Œå…³é”®æŒ‡æ ‡: {list(processed_result.get('key_metrics', {}).keys())}")
            
            # Step 4: Claudeç”Ÿæˆä¸šåŠ¡æ´å¯Ÿ
            quick_insights = await self._generate_quick_insights(
                query_type, processed_result['key_metrics'], current_data
            )
            logger.info(f"ç”Ÿæˆæ´å¯Ÿ: {len(quick_insights)}æ¡")
            
            # Step 5: GPT-4oæ ¼å¼åŒ–å“åº”
            formatted_response = await self._format_current_data_response(
                query_type, user_query, processed_result, quick_insights
            )
            logger.info("å“åº”æ ¼å¼åŒ–å®Œæˆ")
            
            # Step 6: æ„å»ºæœ€ç»ˆå“åº”
            processing_time = (datetime.now() - start_time).total_seconds()

            response = CurrentDataResponse(
                query_type=query_type,
                response_format=ResponseFormat(processed_result.get('response_format', 'simple_text')),
                
                main_answer=formatted_response['main_answer'],
                key_metrics=processed_result['key_metrics'],
                formatted_data=formatted_response['formatted_data'],
                
                business_context=formatted_response.get('business_context', ''),
                quick_insights=quick_insights,
                related_metrics=processed_result.get('related_metrics', {}),
                
                data_timestamp=current_data.get('timestamp', datetime.now().isoformat()),
                response_confidence=processed_result.get('confidence', 0.8),
                data_sources=['/api/sta/system'],
                processing_time=processing_time
            )

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_processing_stats(query_type, processing_time, response.response_confidence)

            logger.info(f"âœ… æŸ¥è¯¢å¤„ç†å®Œæˆï¼Œè€—æ—¶{processing_time:.2f}ç§’")
            
            return response
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")
            return self._create_error_response(user_query, str(e))

    async def _fetch_current_system_data(self) -> Dict[str, Any]:
        """è·å–å½“å‰ç³»ç»Ÿæ•°æ®"""
        try:
            logger.info("è·å–å½“å‰ç³»ç»ŸçœŸå®æ•°æ®")
            
            # ä½¿ç”¨APIè¿æ¥å™¨è·å–çœŸå®æ•°æ®
            if not hasattr(self, 'api_connector') or self.api_connector is None:
                # å¦‚æœæ²¡æœ‰åˆå§‹åŒ–APIè¿æ¥å™¨ï¼Œåˆ™åˆ›å»ºä¸€ä¸ª
                from data.connectors.api_connector import create_enhanced_api_connector
                self.api_connector = create_enhanced_api_connector(
                    None, self.claude_client, self.gpt_client
                )
                logger.info("åˆå§‹åŒ–APIè¿æ¥å™¨")
            
            # è·å–ç³»ç»Ÿæ¦‚è§ˆæ•°æ®
            system_data = await self.api_connector._make_request('/api/sta/system')
            
            if not system_data or not system_data.get('success', False):
                logger.error(f"è·å–ç³»ç»Ÿæ•°æ®å¤±è´¥: {system_data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                # é™çº§åˆ°è·å–æ¯æ—¥æ•°æ®
                daily_data = await self.api_connector._make_request('/api/sta/daily')
                if daily_data and daily_data.get('success', False):
                    system_data = daily_data
                    logger.info("ä½¿ç”¨æ¯æ—¥æ•°æ®ä½œä¸ºé™çº§æ–¹æ¡ˆ")
                else:
                    # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºæœ€åçš„é™çº§æ–¹æ¡ˆ
                    logger.warning("APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºé™çº§æ–¹æ¡ˆ")
                    return await self._get_mock_system_data()
            
            # å¢å¼ºç³»ç»Ÿæ•°æ®
            if system_data.get('data'):
                # æ·»åŠ æ—¶é—´æˆ³
                now = datetime.now()
                system_data['data']['timestamp'] = now.isoformat()
                
                # å¦‚æœéœ€è¦é¢å¤–æ•°æ®ï¼Œè·å–ç”¨æˆ·æ•°æ®å’Œäº§å“æ•°æ®
                try:
                    user_data = await self.api_connector._make_request('/api/sta/user')
                    if user_data and user_data.get('success', False) and user_data.get('data'):
                        system_data['data']['user_details'] = user_data['data']
                        
                    product_data = await self.api_connector._make_request('/api/sta/product')
                    if product_data and product_data.get('success', False) and product_data.get('data'):
                        system_data['data']['product_details'] = product_data['data']
                        
                    # è·å–ä»Šæ—¥åˆ°æœŸæ•°æ®
                    today_str = now.strftime('%Y%m%d')
                    expiry_data = await self.api_connector._make_request('/api/sta/product/end', {'date': today_str})
                    if expiry_data and expiry_data.get('success', False) and expiry_data.get('data'):
                        system_data['data']['today_expiry_details'] = expiry_data['data']
                except Exception as e:
                    logger.warning(f"è·å–é¢å¤–æ•°æ®å¤±è´¥: {str(e)}")
                
                return system_data['data']
            else:
                logger.error("ç³»ç»Ÿæ•°æ®å“åº”ä¸­æ²¡æœ‰dataå­—æ®µ")
                return await self._get_mock_system_data()
            
        except Exception as e:
            logger.error(f"è·å–ç³»ç»Ÿæ•°æ®å¤±è´¥: {str(e)}")
            # è¿”å›æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºé™çº§æ–¹æ¡ˆ
            return await self._get_mock_system_data()
            
    async def _get_mock_system_data(self) -> Dict[str, Any]:
        """è·å–æ¨¡æ‹Ÿç³»ç»Ÿæ•°æ®ï¼ˆä½œä¸ºé™çº§æ–¹æ¡ˆï¼‰"""
        logger.warning("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        
        # è·å–å½“å‰æ—¶é—´
        now = datetime.now()
        
        # æ¨¡æ‹Ÿç³»ç»Ÿæ•°æ®
        system_data = {
            "timestamp": now.isoformat(),
            "system_status": "normal",
            "total_balance": 12567890.45,
            "available_balance": 10234567.89,
            "frozen_balance": 2333322.56,
            "total_users": 5678,
            "active_users_today": 1234,
            "new_users_today": 56,
            "today_expiry_amount": 1500000.00,
            "today_expiry_count": 12,
            "cash_in_today": 2345678.90,
            "cash_out_today": 1234567.80,
            "net_cash_flow": 1111111.10,
            "products": {
                "total_count": 45,
                "active_count": 38,
                "top_performing": ["äº§å“A", "äº§å“B", "äº§å“C"],
                "underperforming": ["äº§å“X", "äº§å“Y"]
            },
            "quick_metrics": {
                "roi_7d": 0.0234,
                "roi_30d": 0.0567,
                "user_growth_30d": 0.0789,
                "transaction_volume_7d": 45678901.23
            }
        }
        
        return system_data

    def _update_processing_stats(self, query_type: CurrentDataQueryType, 
                               processing_time: float, confidence: float) -> None:
        """æ›´æ–°å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # æ›´æ–°æŸ¥è¯¢ç±»å‹ç»Ÿè®¡
            type_value = query_type.value
            if type_value not in self.processing_stats['queries_by_type']:
                self.processing_stats['queries_by_type'][type_value] = 0
            self.processing_stats['queries_by_type'][type_value] += 1
            
            # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
            total_queries = self.processing_stats['total_queries']
            current_avg_time = self.processing_stats['avg_response_time']
            self.processing_stats['avg_response_time'] = (current_avg_time * (total_queries - 1) + processing_time) / total_queries
            
            # æ›´æ–°å¹³å‡ç½®ä¿¡åº¦
            current_avg_confidence = self.processing_stats['avg_confidence']
            self.processing_stats['avg_confidence'] = (current_avg_confidence * (total_queries - 1) + confidence) / total_queries
            
            # æ›´æ–°ç¼“å­˜å‘½ä¸­ç‡
            total_cache_requests = self.processing_stats['cache_hits'] + self.processing_stats['cache_misses']
            if total_cache_requests > 0:
                self.processing_stats['cache_hit_rate'] = self.processing_stats['cache_hits'] / total_cache_requests
                
        except Exception as e:
            logger.error(f"æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")

    def _create_error_response(self, user_query: str, error_message: str) -> CurrentDataResponse:
        """åˆ›å»ºé”™è¯¯å“åº”"""
        return CurrentDataResponse(
            query_type=CurrentDataQueryType.SYSTEM_OVERVIEW,
            response_format=ResponseFormat.SIMPLE_TEXT,
            
            main_answer=f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {error_message}",
            key_metrics={"error": error_message},
            formatted_data={"error_details": error_message},
            
            business_context="",
            quick_insights=[],
            related_metrics={},
            
            data_timestamp=datetime.now().isoformat(),
            response_confidence=0.0,
            data_sources=[],
            processing_time=0.0
        )

    def _load_processing_config(self) -> Dict[str, Any]:
        """åŠ è½½å¤„ç†é…ç½®"""
        return {
            "max_response_time_ms": 2000,
            "data_freshness_threshold_sec": 60,
            "enable_insights": True,
            "max_insights_count": 5,
            "cache_ttl_sec": 300
        }

    def _load_current_data_patterns(self) -> Dict[str, List[str]]:
        """åŠ è½½å½“å‰æ•°æ®æŸ¥è¯¢æ¨¡å¼"""
        return {
            "system_overview": ["æ€»ä½“æƒ…å†µ", "ç³»ç»ŸçŠ¶æ€", "æ•´ä½“çŠ¶å†µ"],
            "balance_check": ["ä½™é¢", "èµ„é‡‘", "é’±", "è´¦æˆ·"],
            "user_status": ["ç”¨æˆ·", "å®¢æˆ·", "ä¼šå‘˜"],
            "today_expiry": ["åˆ°æœŸ", "è¿‡æœŸ", "ä»Šå¤©åˆ°æœŸ"],
            "cash_flow": ["å…¥é‡‘", "å‡ºé‡‘", "æµå…¥", "æµå‡º"],
            "product_status": ["äº§å“", "ç†è´¢", "æŠ•èµ„"],
            "quick_metrics": ["æŒ‡æ ‡", "æ•°æ®", "ç»Ÿè®¡"]
        }