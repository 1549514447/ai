import anthropic
from typing import Dict, Any, Optional, List
import json
import asyncio
import logging
from datetime import datetime
import httpx
import os
from dotenv import load_dotenv

logger = logging.getLogger(__name__)

# è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
class CustomJSONEncoder(json.JSONEncoder):
    def default(self, obj):
        # æ£€æŸ¥å¯¹è±¡æ˜¯å¦æœ‰__dict__å±æ€§ï¼ˆå¤§å¤šæ•°è‡ªå®šä¹‰ç±»éƒ½æœ‰ï¼‰
        if hasattr(obj, '__dict__'):
            return obj.__dict__
        # æ£€æŸ¥å¯¹è±¡æ˜¯å¦æœ‰to_dictæ–¹æ³•
        elif hasattr(obj, 'to_dict') and callable(getattr(obj, 'to_dict')):
            return obj.to_dict()
        # æ£€æŸ¥å¯¹è±¡æ˜¯å¦æœ‰__str__æ–¹æ³•
        elif hasattr(obj, '__str__'):
            return str(obj)
        # å…¶ä»–ç±»å‹çš„å¯¹è±¡ï¼Œè¿”å›å…¶ç±»å
        return f"<{obj.__class__.__name__}>"

# å®‰å…¨çš„JSONè½¬æ¢å‡½æ•°
def safe_json_dumps(obj, **kwargs):
    try:
        return json.dumps(obj, ensure_ascii=False, cls=CustomJSONEncoder, **kwargs)
    except Exception as e:
        logger.warning(f"JSONåºåˆ—åŒ–å¤±è´¥ï¼Œä½¿ç”¨å®‰å…¨æ¨¡å¼: {e}")
        # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if isinstance(obj, dict):
            safe_dict = {}
            for k, v in obj.items():
                try:
                    # é€’å½’å¤„ç†åµŒå¥—å­—å…¸
                    if isinstance(v, dict):
                        safe_dict[k] = safe_json_dumps(v)
                    else:
                        safe_dict[k] = str(v)
                except:
                    safe_dict[k] = "<ä¸å¯åºåˆ—åŒ–å¯¹è±¡>"
            return json.dumps(safe_dict, ensure_ascii=False, **kwargs)
        else:
            return json.dumps({"data": str(obj)}, ensure_ascii=False, **kwargs)


class ClaudeClient:
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–Claude Sonnet 4å®¢æˆ·ç«¯

        Args:
            api_key: APIå¯†é’¥ï¼Œå¦‚æœä¸ä¼ å…¥åˆ™ä»ç¯å¢ƒå˜é‡CLAUDE_API_KEYè·å–
        """
        # å¦‚æœæ²¡æœ‰ä¼ å…¥api_keyï¼Œä»ç¯å¢ƒå˜é‡è·å–
        if api_key is None:
            load_dotenv()
            api_key = os.getenv('CLAUDE_API_KEY')
            if not api_key:
                raise ValueError("CLAUDE_API_KEY not found in environment variables or .env file")

        # åˆ›å»ºä¸€ä¸ªä¸ä½¿ç”¨ä»£ç†çš„è‡ªå®šä¹‰ httpx å®¢æˆ·ç«¯
        custom_http_client = httpx.Client(
            timeout=httpx.Timeout(180.0),  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°180ç§’
            follow_redirects=True
        )

        # æ£€æŸ¥anthropicç‰ˆæœ¬
        self.anthropic_version = getattr(anthropic, "__version__", "0.0.0")
        logger.info(f"Detected Anthropic SDK version: {self.anthropic_version}")
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯ - å°è¯•å¤šç§å¯èƒ½çš„åˆå§‹åŒ–æ–¹å¼
        try:
            # å°è¯•æ–¹æ³•1: ç›´æ¥åˆå§‹åŒ–Anthropic
            self.client = anthropic.Anthropic(api_key=api_key, http_client=custom_http_client)
            logger.info("Initialized with anthropic.Anthropic")
        except Exception as e1:
            logger.warning(f"Failed to initialize with anthropic.Anthropic: {e1}")
            try:
                # å°è¯•æ–¹æ³•2: ä½¿ç”¨Clientç±»
                self.client = anthropic.Client(api_key=api_key, http_client=custom_http_client)
                logger.info("Initialized with anthropic.Client")
            except Exception as e2:
                logger.warning(f"Failed to initialize with anthropic.Client: {e2}")
                try:
                    # å°è¯•æ–¹æ³•3: ä¸å¸¦http_clientå‚æ•°
                    self.client = anthropic.Anthropic(api_key=api_key)
                    logger.info("Initialized with anthropic.Anthropic without http_client")
                except Exception as e3:
                    logger.error(f"All initialization methods failed: {e3}")
                    raise ValueError("Failed to initialize Anthropic client with any method")

        # æ£€æµ‹å¯ç”¨çš„APIæ–¹æ³•
        self.has_messages_api = hasattr(self.client, 'messages') and hasattr(getattr(self.client, 'messages', None), 'create')
        self.has_completion_api = hasattr(self.client, 'completion')
        
        logger.info(f"API capabilities: messages_api={self.has_messages_api}, completion_api={self.has_completion_api}")
        
        if not (self.has_messages_api or self.has_completion_api):
            logger.warning("No known API methods detected. Client may not work properly.")

        # è®¾ç½®æ¨¡å‹å’Œå‚æ•°
        self.model = "claude-sonnet-4-20250514"  # ä½¿ç”¨æœ€æ–°çš„Claude 4æ¨¡å‹
        self.max_tokens = 8000
        self.max_retries = 1  # æœ€å¤§é‡è¯•æ¬¡æ•°
        self.retry_delay = 2  # åˆå§‹é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
        
        logger.info(f"ClaudeClient initialized successfully")
        logger.info(f"Using model: {self.model}")

    # 1. ä¿®å¤ core/models/claude_client.py çš„ analyze_complex_query æ–¹æ³•

    async def analyze_complex_query(self, query: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        å¤æ‚æŸ¥è¯¢æ·±åº¦åˆ†æ - Claudeçš„æ ¸å¿ƒä¼˜åŠ¿
        """
        try:
            # ç®€åŒ–æç¤ºä»¥å‡å°‘å¤„ç†æ—¶é—´
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ•°æ®åˆ†æå¸ˆå’Œæ™ºèƒ½ä¸šåŠ¡é¡¾é—®ã€‚
    æä¾›ç®€æ´ã€ä¸“ä¸šçš„åˆ†æï¼ŒåŒ…æ‹¬ä¸šåŠ¡æ´å¯Ÿã€é£é™©è¯„ä¼°å’Œå†³ç­–å»ºè®®ã€‚"""

            # ğŸ”¥ ä¿®å¤ï¼šé™åˆ¶contextå¤§å°ï¼Œé¿å…è¯·æ±‚è¿‡å¤§
            user_content = f"""
    ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

    å¯ç”¨æ•°æ®ä¸Šä¸‹æ–‡ï¼š
    {safe_json_dumps(context, indent=2) if context else "æš‚æ— å…·ä½“æ•°æ®"}

    è¯·è¿›è¡Œåˆ†æå¹¶æä¾›ä¸“ä¸šå»ºè®®ã€‚
    """

            # ğŸ”¥ æ–°å¢ï¼šæ™ºèƒ½æˆªæ–­è¿‡å¤§çš„context
            MAX_CONTEXT_SIZE = 8000  # è®¾ç½®æœ€å¤§contextå¤§å°
            if context and len(safe_json_dumps(context)) > MAX_CONTEXT_SIZE:
                logger.warning("Contextè¿‡å¤§ï¼Œæ­£åœ¨æ™ºèƒ½æˆªæ–­...")

                # ä¿ç•™æœ€é‡è¦çš„æ•°æ®
                simplified_context = {}
                if 'system_data' in context:
                    simplified_context['system_data'] = context['system_data']
                if 'query_metadata' in context:
                    simplified_context['query_metadata'] = {
                        'query': context['query_metadata'].get('query', ''),
                        'data_sources_used': context['query_metadata'].get('data_sources_used', [])
                    }

                user_content = f"""
    ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

    å¯ç”¨æ•°æ®ä¸Šä¸‹æ–‡ï¼š(å·²ä¼˜åŒ–æ˜¾ç¤ºå…³é”®ä¿¡æ¯)
    {safe_json_dumps(simplified_context, indent=2)}

    è¯·è¿›è¡Œåˆ†æå¹¶æä¾›ä¸“ä¸šå»ºè®®ã€‚
    """

            # å°è¯•ä¸åŒçš„APIè°ƒç”¨æ–¹å¼
            analysis = None
            last_error = None

            # å®ç°è‡ªå®šä¹‰é‡è¯•é€»è¾‘
            for attempt in range(self.max_retries):
                try:
                    # å°è¯•ä½¿ç”¨messages API
                    if self.has_messages_api:
                        try:
                            logger.info(f"Attempting to use messages API (attempt {attempt + 1}/{self.max_retries})")
                            message = await asyncio.to_thread(
                                self.client.messages.create,
                                model=self.model,
                                max_tokens=self.max_tokens,
                                system=system_prompt,
                                messages=[{"role": "user", "content": user_content}]
                            )

                            # å¤„ç†è¿”å›å†…å®¹
                            if hasattr(message, 'content'):
                                content_list = message.content
                                if isinstance(content_list, list) and len(content_list) > 0:
                                    analysis = ""
                                    for content_item in content_list:
                                        if hasattr(content_item, 'text'):
                                            analysis += content_item.text
                                        elif isinstance(content_item, dict) and 'text' in content_item:
                                            analysis += content_item['text']

                                    if analysis:
                                        logger.info("Successfully retrieved analysis from messages API")
                                        break

                            # å¤„ç†stop_reason
                            if hasattr(message, 'stop_reason') and message.stop_reason == "refusal":
                                logger.warning("Claude refused to generate content for safety reasons")
                                return {
                                    "success": False,
                                    "error": "Content generation refused for safety reasons",
                                    "claude_failed": True,
                                    "should_fallback_to_gpt": True,
                                    "model_used": self.model,
                                    "query_type": "complex_analysis",
                                    "timestamp": datetime.now().isoformat()
                                }

                        except Exception as e:
                            last_error = e
                            logger.error(f"Messages API call failed (attempt {attempt + 1}): {e}")

                            # ğŸ”¥ æ–°å¢ï¼šç‰¹æ®Šå¤„ç†ä½™é¢ä¸è¶³é”™è¯¯
                            if "credit balance is too low" in str(e):
                                logger.error("Claude APIä½™é¢ä¸è¶³ï¼Œå°†ç«‹å³é™çº§åˆ°GPT-4o")
                                return {
                                    "success": False,
                                    "error": "Claude APIä½™é¢ä¸è¶³",
                                    "claude_failed": True,
                                    "should_fallback_to_gpt": True,
                                    "fallback_reason": "insufficient_credits",
                                    "user_message": "ğŸ”„ Claude APIæš‚æ—¶ä¸å¯ç”¨ï¼ˆä½™é¢ä¸è¶³ï¼‰ï¼Œç³»ç»Ÿå·²è‡ªåŠ¨åˆ‡æ¢åˆ°GPT-4oä¸ºæ‚¨æä¾›æœåŠ¡",
                                    "model_used": self.model,
                                    "query_type": "complex_analysis",
                                    "timestamp": datetime.now().isoformat()
                                }

                    # å¦‚æœå°è¯•å¤±è´¥ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
                    if analysis is None and attempt < self.max_retries - 1:
                        retry_delay = self.retry_delay * (2 ** attempt)
                        logger.info(f"Retrying in {retry_delay} seconds...")
                        await asyncio.sleep(retry_delay)

                except Exception as e:
                    last_error = e
                    logger.error(f"API call attempt {attempt + 1} failed with error: {e}")
                    if attempt < self.max_retries - 1:
                        retry_delay = self.retry_delay * (2 ** attempt)
                        logger.info(f"Retrying in {retry_delay} seconds...")
                        await asyncio.sleep(retry_delay)

            # å¦‚æœæ‰€æœ‰APIè°ƒç”¨éƒ½å¤±è´¥äº†
            if analysis is None:
                error_msg = str(last_error) if last_error else "All API call methods failed"
                logger.error(f"Claudeåˆ†æå¤±è´¥: {error_msg}")

                # ğŸ”¥ æ˜ç¡®çš„é™çº§ä¿¡æ¯
                return {
                    "success": False,
                    "error": error_msg,
                    "claude_failed": True,
                    "should_fallback_to_gpt": True,
                    "fallback_reason": "api_failure",
                    "user_message": "ğŸ”„ ClaudeæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œç³»ç»Ÿå·²è‡ªåŠ¨åˆ‡æ¢åˆ°GPT-4oä¸ºæ‚¨æä¾›æœåŠ¡",
                    "model_used": self.model,
                    "query_type": "complex_analysis",
                    "timestamp": datetime.now().isoformat()
                }

            return {
                "success": True,
                "analysis": analysis,
                "model_used": self.model,
                "query_type": "complex_analysis",
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"Claudeåˆ†æå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "claude_failed": True,
                "should_fallback_to_gpt": True,
                "fallback_reason": "exception",
                "user_message": f"ğŸ”„ ClaudeæœåŠ¡å¼‚å¸¸ï¼Œç³»ç»Ÿå·²è‡ªåŠ¨åˆ‡æ¢åˆ°GPT-4oä¸ºæ‚¨æä¾›æœåŠ¡",
                "model_used": self.model,
                "query_type": "complex_analysis",
                "timestamp": datetime.now().isoformat()
            }

    async def decompose_query(self, query: str) -> Dict[str, Any]:
        """
        æŸ¥è¯¢åˆ†è§£ - å°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„æ­¥éª¤
        """
        try:
            decomposition_prompt = f"""
åˆ†æä»¥ä¸‹æŸ¥è¯¢ï¼Œå°†å…¶åˆ†è§£ä¸ºå…·ä½“çš„æ‰§è¡Œæ­¥éª¤å’Œæ•°æ®éœ€æ±‚ï¼š

æŸ¥è¯¢ï¼š"{query}"

å¤æ‚åº¦å®šä¹‰ï¼š
- simple: å•ä¸€ç›´æ¥æŸ¥è¯¢ï¼Œ1ä¸ªæ˜ç¡®ç›®æ ‡ï¼Œæ— éœ€å¤æ‚è®¡ç®—
- medium: 2-3ä¸ªæ­¥éª¤ï¼Œæ¶‰åŠåŸºç¡€è®¡ç®—ã€ç®€å•é¢„æµ‹æˆ–å¯¹æ¯”åˆ†æ
- complex: 3+ä¸ªæ­¥éª¤ï¼Œå¤šç»´åˆ†æï¼Œå†å²è¶‹åŠ¿ï¼Œå¤æ‚æ¨ç†ï¼Œå¤šæƒ…æ™¯é¢„æµ‹

è¿”å›JSONæ ¼å¼ï¼š
{{
    "complexity": "simple/medium/complex",
    "confidence": 0.0-1.0,
    "reasoning": "åˆ¤æ–­ç†ç”±",
    "key_indicators": [
        {{
            "indicator": "æŒ‡æ ‡åç§°",
            "value": "æŒ‡æ ‡å€¼",
            "weight": "æƒé‡"
        }}
    ],
    "processing_requirements": {{
        "estimated_steps": æ­¥éª¤æ•°é‡,
        "data_complexity": "low/medium/high",
        "calculation_intensity": "low/medium/high",
        "analysis_depth": "surface/moderate/deep"
    }},
    "recommended_approach": "direct_query/analysis_with_calculation/multi_model_collaboration"
}}
"""

            message = await asyncio.to_thread(
                self.client.messages.create,
                model=self.model,
                max_tokens=3500,
                messages=[{"role": "user", "content": decomposition_prompt}]
            )
            result_text = message.content[0].text

            # è§£æJSONç»“æœ
            decomposition_result = json.loads(result_text)

            return {
                "success": True,
                "decomposition": decomposition_result,
                "model_used": self.model,
                "timestamp": datetime.now().isoformat()
            }

        except json.JSONDecodeError as e:
            logger.error(f"æŸ¥è¯¢åˆ†è§£JSONè§£æå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": f"JSONè§£æå¤±è´¥: {str(e)}",
                "raw_response": result_text if 'result_text' in locals() else None
            }
        except Exception as e:
            logger.error(f"æŸ¥è¯¢åˆ†è§£å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "model_used": self.model
            }

    async def generate_business_insights(self, analysis_data: Dict[str, Any], query: str) -> Dict[str, Any]:
        """
        ä¸šåŠ¡æ´å¯Ÿç”Ÿæˆ - Claudeçš„æ ¸å¿ƒä»·å€¼
        """
        try:
            insight_prompt = f"""
åŸºäºä»¥ä¸‹åˆ†ææ•°æ®ï¼Œä¸ºç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆæ·±åº¦çš„ä¸šåŠ¡æ´å¯Ÿå’Œå»ºè®®ï¼š

åŸå§‹æŸ¥è¯¢ï¼š{query}

åˆ†ææ•°æ®ï¼š
{safe_json_dumps(analysis_data, indent=2)}

è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹å†…å®¹çš„ä¸šåŠ¡æ´å¯Ÿï¼š

1. æ ¸å¿ƒå‘ç° (Key Findings)
2. é£é™©é¢„è­¦ (Risk Warnings) 
3. æœºä¼šè¯†åˆ« (Opportunities)
4. å…·ä½“å»ºè®® (Actionable Recommendations)
5. åç»­å…³æ³¨ç‚¹ (Follow-up Points)

è¿”å›JSONæ ¼å¼ï¼š
{{
    "executive_summary": "æ‰§è¡Œæ‘˜è¦",
    "key_findings": [
        {{
            "finding": "å‘ç°å†…å®¹",
            "impact": "å½±å“ç¨‹åº¦",
            "supporting_data": "æ”¯æ’‘æ•°æ®"
        }}
    ],
    "risk_warnings": [
        {{
            "risk": "é£é™©æè¿°", 
            "probability": "å‘ç”Ÿæ¦‚ç‡",
            "impact": "å½±å“ç¨‹åº¦",
            "mitigation": "ç¼“è§£æªæ–½"
        }}
    ],
    "opportunities": [
        {{
            "opportunity": "æœºä¼šæè¿°",
            "potential_value": "æ½œåœ¨ä»·å€¼",
            "implementation": "å®æ–½å»ºè®®"
        }}
    ],
    "recommendations": [
        {{
            "priority": "é«˜/ä¸­/ä½",
            "action": "å…·ä½“è¡ŒåŠ¨",
            "timeline": "æ—¶é—´æ¡†æ¶",
            "expected_outcome": "é¢„æœŸç»“æœ"
        }}
    ],
    "follow_up_questions": ["å»¶å±•é—®é¢˜1", "å»¶å±•é—®é¢˜2"]
}}
"""

            message = await asyncio.to_thread(
                self.client.messages.create,
                model=self.model,
                max_tokens=3000,
                messages=[{"role": "user", "content": insight_prompt}]
            )
            insights_text = message.content[0].text

            insights = json.loads(insights_text)

            return {
                "success": True,
                "insights": insights,
                "model_used": self.model,
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"ä¸šåŠ¡æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "model_used": self.model
            }

    async def assess_query_complexity(self, query: str) -> Dict[str, Any]:
        """
        æŸ¥è¯¢å¤æ‚åº¦è¯„ä¼° - æ™ºèƒ½è·¯ç”±çš„åŸºç¡€
        """
        try:
            complexity_prompt = f"""
è¯„ä¼°ä»¥ä¸‹æŸ¥è¯¢çš„å¤æ‚åº¦å’Œå¤„ç†è¦æ±‚ï¼š

æŸ¥è¯¢ï¼š"{query}"

å¤æ‚åº¦å®šä¹‰ï¼š
- simple: å•ä¸€ç›´æ¥æŸ¥è¯¢ï¼Œ1ä¸ªæ˜ç¡®ç›®æ ‡ï¼Œæ— éœ€å¤æ‚è®¡ç®—
- medium: 2-3ä¸ªæ­¥éª¤ï¼Œæ¶‰åŠåŸºç¡€è®¡ç®—ã€ç®€å•é¢„æµ‹æˆ–å¯¹æ¯”åˆ†æ
- complex: 3+ä¸ªæ­¥éª¤ï¼Œå¤šç»´åˆ†æï¼Œå†å²è¶‹åŠ¿ï¼Œå¤æ‚æ¨ç†ï¼Œå¤šæƒ…æ™¯é¢„æµ‹

è¿”å›JSONæ ¼å¼ï¼š
{{
    "complexity": "simple/medium/complex",
    "confidence": 0.0-1.0,
    "reasoning": "åˆ¤æ–­ç†ç”±",
    "key_indicators": [
        {{
            "indicator": "æŒ‡æ ‡åç§°",
            "value": "æŒ‡æ ‡å€¼",
            "weight": "æƒé‡"
        }}
    ],
    "processing_requirements": {{
        "estimated_steps": æ­¥éª¤æ•°é‡,
        "data_complexity": "low/medium/high",
        "calculation_intensity": "low/medium/high",
        "analysis_depth": "surface/moderate/deep"
    }},
    "recommended_approach": "direct_query/analysis_with_calculation/multi_model_collaboration"
}}
"""

            message = await asyncio.to_thread(
                self.client.messages.create,
                model=self.model,
                max_tokens=3500,
                messages=[{"role": "user", "content": complexity_prompt}]
            )
            complexity_result_text = message.content[0].text

            complexity_result = json.loads(complexity_result_text)

            return {
                "success": True,
                "complexity_analysis": complexity_result,
                "model_used": self.model,
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"å¤æ‚åº¦è¯„ä¼°å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "fallback_complexity": "medium"  # å¤±è´¥æ—¶çš„é»˜è®¤å¤æ‚åº¦
            }

    async def decompose_complex_query(self, query: str) -> Dict[str, Any]:
        """
        å¤æ‚æŸ¥è¯¢åˆ†è§£ - ä¸º intelligent_router.py æä¾›çš„æ–¹æ³•åˆ«å
        """
        return await self.decompose_query(query)

    async def analyze_query_complexity(self, query: str) -> Dict[str, Any]:
        """
        æŸ¥è¯¢å¤æ‚åº¦åˆ†æ - ä¸º intelligent_router.py æä¾›çš„æ–¹æ³•åˆ«å
        """
        return await self.assess_query_complexity(query)

    async def analyze_financial_complexity(self, text: str) -> Dict[str, float]:
        """
        åˆ†ææ–‡æœ¬çš„é‡‘èå¤æ‚åº¦
        """
        try:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ–‡æœ¬åˆ†æä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯è¯„ä¼°ç”¨æˆ·æŸ¥è¯¢çš„é‡‘èå¤æ‚åº¦ï¼Œå¹¶ç»™å‡º0-1ä¹‹é—´çš„è¯„åˆ†ã€‚

è¯„åˆ†æ ‡å‡†ï¼š
- é‡‘èä¸“ä¸šåº¦ï¼šæ–‡æœ¬åŒ…å«çš„é‡‘èä¸“ä¸šæœ¯è¯­å’Œæ¦‚å¿µçš„å¤æ‚ç¨‹åº¦
- åˆ†æå¤æ‚åº¦ï¼šéœ€è¦çš„åˆ†ææ­¥éª¤å’Œé€»è¾‘æ¨ç†çš„å¤æ‚ç¨‹åº¦
- æ•°æ®éœ€æ±‚ï¼šåˆ†ææ‰€éœ€çš„æ•°æ®é‡å’Œæ•°æ®å¤„ç†å¤æ‚åº¦
- é£é™©è¯„ä¼°éš¾åº¦ï¼šæ¶‰åŠçš„é£é™©è¯„ä¼°çš„å¤æ‚ç¨‹åº¦
- å†³ç­–å»ºè®®éš¾åº¦ï¼šç”Ÿæˆå†³ç­–å»ºè®®çš„éš¾åº¦

ä½ éœ€è¦ä»¥JSONæ ¼å¼è¿”å›è¯„åˆ†ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{
  "financial_expertise": 0.7,  // é‡‘èä¸“ä¸šåº¦è¯„åˆ†
  "analysis_complexity": 0.8,  // åˆ†æå¤æ‚åº¦è¯„åˆ†
  "data_requirements": 0.5,    // æ•°æ®éœ€æ±‚è¯„åˆ†
  "risk_assessment": 0.6,      // é£é™©è¯„ä¼°éš¾åº¦è¯„åˆ†
  "decision_making": 0.7,      // å†³ç­–å»ºè®®éš¾åº¦è¯„åˆ†
  "overall_complexity": 0.66   // ç»¼åˆå¤æ‚åº¦è¯„åˆ†ï¼ˆä»¥ä¸Šå„é¡¹çš„å¹³å‡å€¼ï¼‰
}

åªè¿”å›JSONæ ¼å¼çš„è¯„åˆ†ç»“æœï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–è§£é‡Šæˆ–æ–‡å­—ã€‚"""

            user_content = f"""
è¯·è¯„ä¼°ä»¥ä¸‹æŸ¥è¯¢çš„é‡‘èå¤æ‚åº¦ï¼š

{text}
"""

            message = await asyncio.to_thread(
                self.client.messages.create,
                model=self.model,
                max_tokens=1000,
                system=system_prompt,
                messages=[{"role": "user", "content": user_content}]
            )
            result_text = message.content[0].text

            # è§£æJSONç»“æœ
            result = json.loads(result_text)
            return result

        except Exception as e:
            logger.error(f"é‡‘èå¤æ‚åº¦åˆ†æå¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤å€¼
            return {
                "financial_expertise": 0.5,
                "analysis_complexity": 0.5,
                "data_requirements": 0.5,
                "risk_assessment": 0.5,
                "decision_making": 0.5,
                "overall_complexity": 0.5
            }

    async def detect_date_ranges(self, text: str) -> Dict[str, Any]:
        """
        æ£€æµ‹æ–‡æœ¬ä¸­çš„æ—¥æœŸèŒƒå›´
        """
        try:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬åˆ†æä¸“å®¶ï¼Œä¸“æ³¨äºä»æ–‡æœ¬ä¸­æå–æ—¶é—´å’Œæ—¥æœŸä¿¡æ¯ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä»ç”¨æˆ·æŸ¥è¯¢ä¸­è¯†åˆ«å‡ºæ‰€æœ‰æåŠçš„æ—¥æœŸã€æ—¶é—´æ®µå’Œæ—¶é—´èŒƒå›´ã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{
  "date_ranges": [
    {
      "start_date": "2023-01-01",  // ISOæ ¼å¼çš„å¼€å§‹æ—¥æœŸï¼Œå¦‚æœæ²¡æœ‰æ˜ç¡®æåŠåˆ™ä¸ºnull
      "end_date": "2023-03-31",    // ISOæ ¼å¼çš„ç»“æŸæ—¥æœŸï¼Œå¦‚æœæ²¡æœ‰æ˜ç¡®æåŠåˆ™ä¸ºnull
      "period_type": "quarter",    // æ—¶é—´æ®µç±»å‹ï¼šday, week, month, quarter, year, custom
      "description": "2023å¹´ç¬¬ä¸€å­£åº¦"  // å¯¹è¯¥æ—¶é—´æ®µçš„æè¿°
    }
  ],
  "specific_dates": [
    {
      "date": "2023-05-01",        // ISOæ ¼å¼çš„å…·ä½“æ—¥æœŸ
      "description": "åŠ³åŠ¨èŠ‚"       // å¯¹è¯¥æ—¥æœŸçš„æè¿°
    }
  ],
  "relative_periods": [
    {
      "period_type": "last_month",  // ç›¸å¯¹æ—¶é—´ç±»å‹ï¼šyesterday, last_week, last_month, last_quarter, last_yearç­‰
      "description": "ä¸Šä¸ªæœˆ"        // å¯¹è¯¥ç›¸å¯¹æ—¶é—´çš„æè¿°
    }
  ],
  "has_time_info": true             // æ˜¯å¦åŒ…å«æ—¶é—´ä¿¡æ¯
}

åªè¿”å›JSONæ ¼å¼çš„ç»“æœï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–è§£é‡Šæˆ–æ–‡å­—ã€‚å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•æ—¥æœŸæˆ–æ—¶é—´ä¿¡æ¯ï¼Œåˆ™è¿”å›ç©ºæ•°ç»„å¹¶å°†has_time_infoè®¾ä¸ºfalseã€‚"""

            user_content = f"""
è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–æ‰€æœ‰æ—¥æœŸå’Œæ—¶é—´èŒƒå›´ä¿¡æ¯ï¼š

{text}
"""

            message = await asyncio.to_thread(
                self.client.messages.create,
                model=self.model,
                max_tokens=1000,
                system=system_prompt,
                messages=[{"role": "user", "content": user_content}]
            )
            result_text = message.content[0].text

            # è§£æJSONç»“æœ
            result = json.loads(result_text)
            return result

        except Exception as e:
            logger.error(f"æ—¥æœŸèŒƒå›´æ£€æµ‹å¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤å€¼
            return {
                "date_ranges": [],
                "specific_dates": [],
                "relative_periods": [],
                "has_time_info": False
            }

    async def extract_query_features(self, query: str) -> Dict[str, Any]:
        """
        æå–æŸ¥è¯¢ç‰¹å¾ï¼Œç”¨äºæ™ºèƒ½è·¯ç”±
        """
        try:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŸ¥è¯¢åˆ†æä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·æŸ¥è¯¢çš„ç‰¹å¾ï¼Œç”¨äºåç»­çš„æ™ºèƒ½è·¯ç”±ã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{
  "query_type": "analysis",  // æŸ¥è¯¢ç±»å‹ï¼šsimple, analysis, prediction, recommendation, comparison
  "domain": "finance",       // é¢†åŸŸï¼šfinance, business, marketing, operations, general
  "complexity": 0.7,         // å¤æ‚åº¦è¯„åˆ†(0-1)
  "time_sensitivity": 0.5,   // æ—¶é—´æ•æ„Ÿåº¦(0-1)
  "requires_calculation": true,  // æ˜¯å¦éœ€è¦è®¡ç®—
  "requires_visualization": false,  // æ˜¯å¦éœ€è¦å¯è§†åŒ–
  "key_entities": ["revenue", "profit margin"],  // å…³é”®å®ä½“
  "key_metrics": ["growth rate", "ROI"]  // å…³é”®æŒ‡æ ‡
}

åªè¿”å›JSONæ ¼å¼çš„ç»“æœï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–è§£é‡Šæˆ–æ–‡å­—ã€‚"""

            user_content = f"""
è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢çš„ç‰¹å¾ï¼š

{query}
"""

            message = await asyncio.to_thread(
                self.client.messages.create,
                model=self.model,
                max_tokens=1000,
                system=system_prompt,
                messages=[{"role": "user", "content": user_content}]
            )
            result_text = message.content[0].text

            # è§£æJSONç»“æœ
            result = json.loads(result_text)
            return result

        except Exception as e:
            logger.error(f"æŸ¥è¯¢ç‰¹å¾æå–å¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤å€¼
            return {
                "query_type": "analysis",
                "domain": "general",
                "complexity": 0.5,
                "time_sensitivity": 0.5,
                "requires_calculation": False,
                "requires_visualization": False,
                "key_entities": [],
                "key_metrics": []
            }

    async def generate_text(self, prompt: str, max_tokens: int = 1500, system_prompt: str = None) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ–‡æœ¬å“åº” - ä¸ºIntelligentQAOrchestratoræä¾›çš„é€šç”¨æ–‡æœ¬ç”Ÿæˆæ–¹æ³•
        æ ¹æ®å¯ç”¨çš„APIæ–¹æ³•ï¼ˆmessages APIæˆ–completion APIï¼‰åŠ¨æ€é€‰æ‹©è°ƒç”¨æ–¹å¼
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            system_prompt: å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯
            
        Returns:
            åŒ…å«ç”Ÿæˆæ–‡æœ¬çš„å­—å…¸ï¼Œæ ¼å¼ä¸º {"success": bool, "text": str, ...}
        """
        logger.info(f"ä½¿ç”¨Claudeç”Ÿæˆæ–‡æœ¬å“åº”ï¼Œæ¨¡å‹: {self.model}, æœ€å¤§tokens: {max_tokens}")
        
        try:
            # å°è¯•ä½¿ç”¨messages APIï¼ˆä¼˜å…ˆï¼‰
            if self.has_messages_api:
                logger.debug("ä½¿ç”¨messages APIç”Ÿæˆæ–‡æœ¬")
                messages = [{"role": "user", "content": prompt}]
                
                # å¦‚æœæä¾›äº†ç³»ç»Ÿæç¤ºè¯
                message_kwargs = {
                    "model": self.model,
                    "max_tokens": max_tokens,
                    "messages": messages
                }
                
                if system_prompt:
                    message_kwargs["system"] = system_prompt
                
                # messages.createæ˜¯åŒæ­¥çš„ï¼Œä½¿ç”¨asyncio.to_threadè¿è¡Œ
                response = await asyncio.to_thread(
                    self.client.messages.create,
                    **message_kwargs
                )
                
                # æå–æ–‡æœ¬å†…å®¹
                content_text = ""
                if hasattr(response, 'content') and response.content:
                    for content_item in response.content:
                        if hasattr(content_item, 'text'):
                            content_text += content_item.text
                
                return {
                    "success": True,
                    "text": content_text,
                    "model_used": self.model,
                    "api_method": "messages"
                }
            
            # å°è¯•ä½¿ç”¨completion APIï¼ˆå¤‡é€‰ï¼‰
            elif self.has_completion_api:
                logger.debug("ä½¿ç”¨completion APIç”Ÿæˆæ–‡æœ¬")
                # æ„å»ºæç¤ºè¯
                if system_prompt:
                    full_prompt = f"{system_prompt}\n\n{prompt}"
                else:
                    full_prompt = prompt
                
                # completionæ˜¯åŒæ­¥çš„ï¼Œä½¿ç”¨asyncio.to_threadè¿è¡Œ
                response = await asyncio.to_thread(
                    self.client.completion,
                    prompt=full_prompt,
                    model=self.model,
                    max_tokens_to_sample=max_tokens
                )
                
                # æå–æ–‡æœ¬å†…å®¹
                completion_text = response.completion if hasattr(response, 'completion') else str(response)
                
                return {
                    "success": True,
                    "text": completion_text,
                    "model_used": self.model,
                    "api_method": "completion"
                }
            
            # ä¸¤ç§APIæ–¹æ³•éƒ½ä¸å¯ç”¨
            else:
                error_msg = "Claudeå®¢æˆ·ç«¯æ²¡æœ‰å¯ç”¨çš„APIæ–¹æ³•ï¼ˆmessagesæˆ–completionï¼‰"
                logger.error(error_msg)
                return {
                    "success": False,
                    "error": error_msg,
                    "text": "AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚",
                    "model_used": self.model
                }
                
        except Exception as e:
            error_msg = f"Claudeç”Ÿæˆæ–‡æœ¬æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            logger.error(f"{error_msg}\n{traceback.format_exc()}")
            return {
                "success": False,
                "error": error_msg,
                "text": f"AIå¤„ç†é‡åˆ°é—®é¢˜: {str(e)}",
                "model_used": self.model
            }