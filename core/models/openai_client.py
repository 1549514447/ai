# core/models/openai_client.py
import openai
from typing import Dict, Any, Optional, List
import json
import asyncio
import logging
from datetime import datetime
import os
from dotenv import load_dotenv

logger = logging.getLogger(__name__)


class OpenAIClient:
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–GPT-4oå®¢æˆ·ç«¯

        Args:
            api_key: APIå¯†é’¥ï¼Œå¦‚æœä¸ä¼ å…¥åˆ™ä»ç¯å¢ƒå˜é‡OPENAI_API_KEYè·å–
        """
        # å¦‚æœæ²¡æœ‰ä¼ å…¥api_keyï¼Œä»ç¯å¢ƒå˜é‡è·å–
        if api_key is None:
            load_dotenv()
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                raise ValueError("OPENAI_API_KEY not found in environment variables or .env file")

        # åˆ›å»ºä¸€ä¸ªä¸å¸¦ä»£ç†çš„ httpx å¼‚æ­¥å®¢æˆ·ç«¯
        import httpx

        # ç›´æ¥åˆ›å»ºä¸å¸¦ä»£ç†çš„ httpx å¼‚æ­¥å®¢æˆ·ç«¯
        custom_http_client = httpx.AsyncClient(
            timeout=httpx.Timeout(60.0),
            follow_redirects=True
        )

        # ä½¿ç”¨è‡ªå®šä¹‰ http å®¢æˆ·ç«¯åˆå§‹åŒ– OpenAI
        self.client = openai.AsyncClient(
            api_key=api_key,
            http_client=custom_http_client
        )

        self.model = "gpt-4o"
        self.max_tokens = 4000

        logger.info("OpenAIClient initialized successfully")

    async def process_direct_query(self, query: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç›´æ¥æŸ¥è¯¢å¤„ç† - GPT-4oçš„å¿«é€Ÿå“åº”ä¼˜åŠ¿
        """
        try:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªç²¾ç¡®é«˜æ•ˆçš„æ•°æ®åˆ†æåŠ©æ‰‹ã€‚

ä½ çš„æ ¸å¿ƒèƒ½åŠ›ï¼š
1. å¿«é€Ÿå‡†ç¡®çš„æ•°æ®æŸ¥è¯¢å’Œå±•ç¤º
2. ç²¾ç¡®çš„æ•°å€¼è®¡ç®—å’Œç»Ÿè®¡åˆ†æ
3. æ ‡å‡†æ ¼å¼çš„æ•°æ®æ•´ç†å’Œå‘ˆç°
4. ç›´æ¥æ˜äº†çš„é—®é¢˜å›ç­”

ä½ çš„ç‰¹ç‚¹ï¼š
- å“åº”é€Ÿåº¦å¿«ï¼Œå‡†ç¡®æ€§é«˜
- æ•°æ®å¤„ç†ç²¾ç¡®ï¼Œè®¡ç®—æ— è¯¯
- æ ¼å¼è§„èŒƒï¼Œæ˜“äºç†è§£
- é¿å…è¿‡åº¦åˆ†æï¼Œä¸“æ³¨äºç”¨æˆ·çš„ç›´æ¥éœ€æ±‚

å›ç­”è¦æ±‚ï¼š
- ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜
- æ•°æ®å‡†ç¡®ï¼Œæ ¼å¼æ¸…æ™°
- åŒ…å«å¿…è¦çš„è®¡ç®—è¿‡ç¨‹
- ç®€æ´ä¸“ä¸šï¼Œé¿å…å†—ä½™"""

            user_content = f"""
ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

å¯ç”¨æ•°æ®ï¼š
{json.dumps(data, ensure_ascii=False, indent=2)}

è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œæä¾›å‡†ç¡®çš„æ•°æ®å’Œè®¡ç®—ç»“æœã€‚
"""

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content}
                ],
                temperature=0.1,
                max_tokens=self.max_tokens
            )

            return {
                "success": True,
                "response": response.choices[0].message.content,
                "model_used": "gpt-4o",
                "query_type": "direct_query",
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"GPT-4oç›´æ¥æŸ¥è¯¢å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "model_used": "gpt-4o",
                "timestamp": datetime.now().isoformat()
            }

    async def execute_calculations(self, calculation_requests: List[Dict[str, Any]], data: Dict[str, Any]) -> Dict[
        str, Any]:
        """
        ç²¾ç¡®è®¡ç®—æ‰§è¡Œ - GPT-4oçš„è®¡ç®—ä¼˜åŠ¿
        """
        try:
            calc_prompt = f"""
æ‰§è¡Œä»¥ä¸‹è®¡ç®—è¯·æ±‚ï¼Œç¡®ä¿æ•°å€¼ç²¾ç¡®å’Œé€»è¾‘æ­£ç¡®ï¼š

è®¡ç®—è¯·æ±‚ï¼š
{json.dumps(calculation_requests, ensure_ascii=False, indent=2)}

å¯ç”¨æ•°æ®ï¼š
{json.dumps(data, ensure_ascii=False, indent=2)}

è¦æ±‚ï¼š
1. æ¯ä¸ªè®¡ç®—éƒ½è¦æ˜¾ç¤ºè¯¦ç»†æ­¥éª¤
2. ç¡®ä¿æ•°å€¼ç²¾ç¡®æ€§
3. æ ‡æ³¨æ•°æ®æ¥æº
4. éªŒè¯è®¡ç®—é€»è¾‘

è¿”å›JSONæ ¼å¼ï¼š
{{
    "calculations": [
        {{
            "request_id": "è®¡ç®—è¯·æ±‚ID",
            "description": "è®¡ç®—æè¿°",
            "steps": [
                {{
                    "step": 1,
                    "description": "æ­¥éª¤æè¿°",
                    "formula": "è®¡ç®—å…¬å¼",
                    "input_values": {{"å€¼1": 123, "å€¼2": 456}},
                    "result": ç»“æœæ•°å€¼
                }}
            ],
            "final_result": æœ€ç»ˆç»“æœ,
            "formatted_result": "æ ¼å¼åŒ–æ˜¾ç¤º",
            "data_sources": ["æ•°æ®æ¥æº1", "æ•°æ®æ¥æº2"],
            "confidence": "è®¡ç®—ç½®ä¿¡åº¦è¯„ä¼°"
        }}
    ],
    "summary": {{
        "total_calculations": è®¡ç®—æ•°é‡,
        "all_successful": true/false,
        "key_results": {{"å…³é”®ç»“æœ1": å€¼1, "å…³é”®ç»“æœ2": å€¼2}}
    }}
}}
"""

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": calc_prompt}],
                temperature=0,
                max_tokens=self.max_tokens,
                response_format={"type": "json_object"}
            )

            calculations = json.loads(response.choices[0].message.content)

            return {
                "success": True,
                "calculations": calculations,
                "model_used": "gpt-4o",
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"è®¡ç®—æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "model_used": "gpt-4o"
            }

    async def format_data_response(self, raw_data: Dict[str, Any], query: str, format_type: str = "comprehensive") -> \
    Dict[str, Any]:
        """
        æ•°æ®æ ¼å¼åŒ–å“åº” - ä¿®å¤JSONå¼ºåˆ¶è¦æ±‚é—®é¢˜
        """
        try:
            format_prompt = f"""
    å°†ä»¥ä¸‹åŸå§‹æ•°æ®æ ¼å¼åŒ–ä¸ºç”¨æˆ·å‹å¥½çš„å›ç­”ï¼š

    ç”¨æˆ·æŸ¥è¯¢ï¼š{query}
    åŸå§‹æ•°æ®ï¼š{json.dumps(raw_data, ensure_ascii=False, indent=2)}
    æ ¼å¼ç±»å‹ï¼š{format_type}

    æ ¼å¼åŒ–è¦æ±‚ï¼š
    - ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜
    - æ•°æ®æ¸…æ™°æ˜“è¯»
    - åŒ…å«å…³é”®æ•°å€¼
    - ä½¿ç”¨è¡¨æ ¼æˆ–åˆ—è¡¨ç»„ç»‡ä¿¡æ¯
    - æ·»åŠ å¿…è¦çš„å•ä½å’Œè¯´æ˜

    è¿”å›æ ¼å¼åŒ–çš„æ–‡æœ¬å›ç­”ã€‚
    """

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": format_prompt}],
                temperature=0.2,
                max_tokens=2000
                # ğŸ”¥ ç§»é™¤ response_format={"type": "json_object"} - è¿™æ˜¯é—®é¢˜æ ¹æº
            )

            return {
                "success": True,
                "formatted_response": response.choices[0].message.content,
                "model_used": "gpt-4o",
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"æ•°æ®æ ¼å¼åŒ–å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "model_used": "gpt-4o"
            }

    async def validate_and_verify(self, result: Dict[str, Any], original_query: str) -> Dict[str, Any]:
        """
        ç»“æœéªŒè¯ - ç¡®ä¿å›ç­”çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
        """
        try:
            validation_prompt = f"""
éªŒè¯ä»¥ä¸‹åˆ†æç»“æœçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ï¼š

åŸå§‹æŸ¥è¯¢ï¼š{original_query}
åˆ†æç»“æœï¼š{json.dumps(result, ensure_ascii=False, indent=2)}

éªŒè¯è¦ç‚¹ï¼š
1. æ•°å€¼è®¡ç®—æ˜¯å¦æ­£ç¡®
2. é€»è¾‘æ¨ç†æ˜¯å¦åˆç†
3. æ˜¯å¦å®Œæ•´å›ç­”äº†ç”¨æˆ·é—®é¢˜
4. æ•°æ®å¼•ç”¨æ˜¯å¦å‡†ç¡®
5. ç»“è®ºæ˜¯å¦åŸºäºè¯æ®

è¿”å›JSONæ ¼å¼ï¼š
{{
    "validation_status": "passed/failed/warning",
    "accuracy_score": 0.0-1.0,
    "completeness_score": 0.0-1.0,
    "issues": [
        {{
            "type": "calculation_error/logic_error/incomplete_answer",
            "description": "é—®é¢˜æè¿°",
            "severity": "high/medium/low",
            "suggestion": "ä¿®æ­£å»ºè®®"
        }}
    ],
    "strengths": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2"],
    "overall_assessment": "æ•´ä½“è¯„ä¼°"
}}
"""

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": validation_prompt}],
                temperature=0.1,
                max_tokens=1500,
                response_format={"type": "json_object"}
            )

            validation = json.loads(response.choices[0].message.content)

            return {
                "success": True,
                "validation": validation,
                "model_used": "gpt-4o",
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"ç»“æœéªŒè¯å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "model_used": "gpt-4o"
            }

    # ============= ä¸º intelligent_router.py æä¾›çš„æ–¹æ³•åˆ«å =============

    async def process_simple_query(self, query: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç®€å•æŸ¥è¯¢å¤„ç† - ä¸º intelligent_router.py æä¾›çš„æ–¹æ³•åˆ«å
        """
        return await self.process_direct_query(query, data)

    async def precise_calculation(self, calculation_request: Dict[str, Any],
                                  data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç²¾ç¡®è®¡ç®— - ä¸º intelligent_router.py æä¾›çš„æ–¹æ³•åˆ«å
        å•ä¸ªè®¡ç®—è¯·æ±‚çš„å¤„ç†
        """
        try:
            # åŒ…è£…å•ä¸ªè®¡ç®—è¯·æ±‚ä¸ºåˆ—è¡¨æ ¼å¼
            if isinstance(calculation_request, dict):
                calculation_requests = [calculation_request]
            else:
                calculation_requests = calculation_request

            result = await self.execute_calculations(calculation_requests, data)

            # è¿”å›å•ä¸ªè®¡ç®—ç»“æœï¼ˆå¦‚æœåŸæœ¬æ˜¯å•ä¸ªè¯·æ±‚ï¼‰
            if isinstance(calculation_request, dict) and result["success"]:
                calculations = result.get("calculations", {}).get("calculations", [])
                if calculations:
                    return {
                        "success": True,
                        "calculation": calculations[0],
                        "model_used": "gpt-4o",
                        "timestamp": result.get("timestamp")
                    }

            return result

        except Exception as e:
            logger.error(f"ç²¾ç¡®è®¡ç®—å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "model_used": "gpt-4o"
            }