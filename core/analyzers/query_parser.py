# core/analyzers/query_parser.py
"""
ğŸ§  AIé©±åŠ¨çš„æ™ºèƒ½æŸ¥è¯¢è§£æå™¨
é‡‘èAIåˆ†æç³»ç»Ÿçš„æ ¸å¿ƒ"å¤§è„‘"ï¼Œè´Ÿè´£ç†è§£å’Œåˆ†è§£å¤æ‚çš„é‡‘èä¸šåŠ¡æŸ¥è¯¢

æ ¸å¿ƒç‰¹ç‚¹:
- åŒAIåä½œçš„æŸ¥è¯¢ç†è§£ (Claude + GPT-4o)
- æ™ºèƒ½å¤æ‚åº¦è¯„ä¼°å’Œåˆ†çº§å¤„ç†
- åŠ¨æ€æ‰§è¡Œè®¡åˆ’ç”Ÿæˆ
- ä¸šåŠ¡åœºæ™¯è‡ªåŠ¨è¯†åˆ«
- ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åˆ†æç­–ç•¥
"""

import logging
from typing import Dict, Any, List, Optional, Tuple, Union
from datetime import datetime, timedelta
import json
import asyncio
from dataclasses import dataclass
from enum import Enum
import re

# å¯¼å…¥æˆ‘ä»¬çš„å·¥å…·ç±»
from utils.helpers.date_utils import DateUtils, create_date_utils, DateParseResult
from utils.helpers.validation_utils import ValidationUtils, create_validation_utils

logger = logging.getLogger(__name__)


class QueryComplexity(Enum):
    """æŸ¥è¯¢å¤æ‚åº¦ç­‰çº§"""
    SIMPLE = "simple"  # ç®€å•æŸ¥è¯¢ (å•ä¸€æ•°æ®è·å–)
    MEDIUM = "medium"  # ä¸­ç­‰å¤æ‚ (åŸºç¡€åˆ†æè®¡ç®—)
    COMPLEX = "complex"  # å¤æ‚æŸ¥è¯¢ (å¤šæ­¥éª¤åˆ†æ)
    EXPERT = "expert"  # ä¸“å®¶çº§ (æ·±åº¦é¢„æµ‹åˆ†æ)


class QueryType(Enum):
    """æŸ¥è¯¢ç±»å‹åˆ†ç±»"""
    DATA_RETRIEVAL = "data_retrieval"  # æ•°æ®æŸ¥è¯¢
    TREND_ANALYSIS = "trend_analysis"  # è¶‹åŠ¿åˆ†æ
    PREDICTION = "prediction"  # é¢„æµ‹åˆ†æ
    COMPARISON = "comparison"  # å¯¹æ¯”åˆ†æ
    CALCULATION = "calculation"  # è®¡ç®—åœºæ™¯
    RISK_ASSESSMENT = "risk_assessment"  # é£é™©è¯„ä¼°
    SCENARIO_SIMULATION = "scenario_simulation"  # åœºæ™¯æ¨¡æ‹Ÿ


class BusinessScenario(Enum):
    """ä¸šåŠ¡åœºæ™¯ç±»å‹"""
    DAILY_OPERATIONS = "daily_operations"  # æ—¥å¸¸è¿è¥
    FINANCIAL_PLANNING = "financial_planning"  # è´¢åŠ¡è§„åˆ’
    RISK_MANAGEMENT = "risk_management"  # é£é™©ç®¡ç†
    GROWTH_ANALYSIS = "growth_analysis"  # å¢é•¿åˆ†æ
    USER_BEHAVIOR = "user_behavior"  # ç”¨æˆ·è¡Œä¸º
    PRODUCT_PERFORMANCE = "product_performance"  # äº§å“è¡¨ç°
    COMPLIANCE_CHECK = "compliance_check"  # åˆè§„æ£€æŸ¥


@dataclass
class ExecutionStep:
    """æ‰§è¡Œæ­¥éª¤æ•°æ®ç±»"""
    step_id: str  # æ­¥éª¤ID
    step_type: str  # æ­¥éª¤ç±»å‹
    description: str  # æ­¥éª¤æè¿°
    required_data: List[str]  # éœ€è¦çš„æ•°æ®
    processing_method: str  # å¤„ç†æ–¹æ³•
    dependencies: List[str]  # ä¾èµ–çš„æ­¥éª¤
    estimated_time: float  # ä¼°è®¡è€—æ—¶(ç§’)
    ai_model_preference: str  # æ¨èçš„AIæ¨¡å‹


@dataclass
class QueryAnalysisResult:
    """æŸ¥è¯¢åˆ†æç»“æœ"""
    original_query: str  # åŸå§‹æŸ¥è¯¢
    complexity: QueryComplexity  # å¤æ‚åº¦ç­‰çº§
    query_type: QueryType  # æŸ¥è¯¢ç±»å‹
    business_scenario: BusinessScenario  # ä¸šåŠ¡åœºæ™¯
    confidence_score: float  # åˆ†æç½®ä¿¡åº¦

    # æ—¶é—´ç›¸å…³
    time_requirements: Dict[str, Any]  # æ—¶é—´éœ€æ±‚
    date_parse_result: DateParseResult  # æ—¥æœŸè§£æç»“æœ

    # æ•°æ®éœ€æ±‚
    data_requirements: Dict[str, Any]  # æ•°æ®éœ€æ±‚
    required_apis: List[str]  # éœ€è¦çš„API

    # ä¸šåŠ¡å‚æ•°
    business_parameters: Dict[str, Any]  # ä¸šåŠ¡å‚æ•°
    calculation_requirements: Dict[str, Any]  # è®¡ç®—éœ€æ±‚

    # æ‰§è¡Œè®¡åˆ’
    execution_plan: List[ExecutionStep]  # æ‰§è¡Œæ­¥éª¤
    processing_strategy: str  # å¤„ç†ç­–ç•¥

    # AIåä½œç­–ç•¥
    ai_collaboration_plan: Dict[str, Any]  # AIåä½œè®¡åˆ’

    # å…ƒæ•°æ®
    analysis_timestamp: str  # åˆ†ææ—¶é—´æˆ³
    estimated_total_time: float  # é¢„ä¼°æ€»è€—æ—¶
    processing_metadata: Dict[str, Any]  # å¤„ç†å…ƒæ•°æ®


class SmartQueryParser:
    """
    ğŸ§  AIé©±åŠ¨çš„æ™ºèƒ½æŸ¥è¯¢è§£æå™¨

    åŠŸèƒ½æ¶æ„:
    1. åŒAIåä½œçš„æŸ¥è¯¢ç†è§£
    2. æ™ºèƒ½å¤æ‚åº¦è¯„ä¼°
    3. åŠ¨æ€æ‰§è¡Œè®¡åˆ’ç”Ÿæˆ
    4. è‡ªé€‚åº”å¤„ç†ç­–ç•¥
    """

    def __init__(self, claude_client=None, gpt_client=None):
        """
        åˆå§‹åŒ–æ™ºèƒ½æŸ¥è¯¢è§£æå™¨

        Args:
            claude_client: Claudeå®¢æˆ·ç«¯ï¼Œè´Ÿè´£ä¸šåŠ¡é€»è¾‘ç†è§£
            gpt_client: GPTå®¢æˆ·ç«¯ï¼Œè´Ÿè´£æ•°æ®éœ€æ±‚åˆ†æ
        """
        self.claude_client = claude_client
        self.gpt_client = gpt_client
        self.date_utils = create_date_utils(claude_client)
        self.validator = create_validation_utils(claude_client, gpt_client)

        # æŸ¥è¯¢æ¨¡å¼è¯†åˆ«
        self.query_patterns = self._load_query_patterns()

        # å¤„ç†ç»Ÿè®¡
        self.processing_stats = {
            'total_queries': 0,
            'complexity_distribution': {
                'simple': 0,
                'medium': 0,
                'complex': 0,
                'expert': 0
            },
            'query_type_distribution': {},
            'ai_collaboration_usage': 0,
            'average_confidence': 0.0
        }

        logger.info("SmartQueryParser initialized with dual-AI capabilities")

    def _load_query_patterns(self) -> Dict[str, Any]:
        """åŠ è½½æŸ¥è¯¢æ¨¡å¼åº“"""
        return {
            # ç®€å•æ•°æ®æŸ¥è¯¢æ¨¡å¼
            "simple_data_patterns": [
                r"ä»Šå¤©|ä»Šæ—¥|å½“å¤©.*?(ä½™é¢|æ•°æ®|æƒ…å†µ)",
                r"(å¤šå°‘|ä»€ä¹ˆ).*?(ç”¨æˆ·|ä½™é¢|é‡‘é¢)",
                r"æ˜¾ç¤º|ç»™æˆ‘.*?(ç³»ç»Ÿ|æ¦‚è§ˆ|çŠ¶æ€)",
                r"æŸ¥çœ‹|çœ‹çœ‹.*?(äº§å“|æ•°æ®)"
            ],

            # å†å²è¶‹åŠ¿åˆ†ææ¨¡å¼
            "trend_analysis_patterns": [
                r"(è¿‡å»|æœ€è¿‘).*?(\d+)(å¤©|å‘¨|æœˆ).*?(è¶‹åŠ¿|å˜åŒ–|å¢é•¿)",
                r"å¯¹æ¯”.*?(ä¸Šæœˆ|ä¸Šå‘¨|å»å¹´)",
                r".*?å¢é•¿.*?(å¦‚ä½•|æ€ä¹ˆæ ·)",
                r"(å¹³å‡|æ¯æ—¥).*?(å¢é•¿|å˜åŒ–)"
            ],

            # é¢„æµ‹åˆ†ææ¨¡å¼
            "prediction_patterns": [
                r"é¢„æµ‹|é¢„è®¡|é¢„æœŸ.*?(æœªæ¥|æ˜å¤©|ä¸‹æœˆ|ä¸‹å‘¨)",
                r"(å¦‚æœ|å‡è®¾).*?(ä¼š|å°†).*?(å¤šå°‘|æ€æ ·)",
                r".*?æœˆ.*?ä¼š.*?(ä½™é¢|èµ„é‡‘)",
                r"åŸºäº.*?é¢„æµ‹"
            ],

            # è®¡ç®—åœºæ™¯æ¨¡å¼
            "calculation_patterns": [
                r"(å¤æŠ•|æç°).*?(\d+%|ç™¾åˆ†ä¹‹)",
                r"è®¡ç®—.*?(å¦‚æœ|æŒ‰ç…§).*?æ¯”ä¾‹",
                r"(\d+%|\d+åˆ†ä¹‹\d+).*?(å¤æŠ•|æç°)",
                r"ä¸åŒ.*?ç‡.*?å½±å“"
            ],

            # é£é™©è¯„ä¼°æ¨¡å¼
            "risk_assessment_patterns": [
                r"(æ²¡æœ‰|æ— ).*?å…¥é‡‘.*?(è¿è¡Œ|æŒç»­).*?(å¤šä¹…|æ—¶é—´)",
                r"é£é™©|å±é™©|å®‰å…¨.*?è¯„ä¼°",
                r"å¯æŒç»­.*?åˆ†æ",
                r"èµ„é‡‘.*?è€—å°½"
            ],

            # åœºæ™¯æ¨¡æ‹Ÿæ¨¡å¼
            "scenario_simulation_patterns": [
                r"(å‡è®¾|å¦‚æœ|å‡å®š).*?æƒ…å†µä¸‹",
                r"ä¸åŒ.*?åœºæ™¯.*?å¯¹æ¯”",
                r"æ¨¡æ‹Ÿ.*?(æƒ…å†µ|åœºæ™¯)",
                r".*?æƒ…å†µ.*?å½±å“"
            ]
        }

    # ============= æ ¸å¿ƒæŸ¥è¯¢åˆ†ææ–¹æ³• =============

    async def parse_complex_query(self, query: str, context: Dict[str, Any] = None) -> QueryAnalysisResult:
        """
        ğŸ¯ è§£æå¤æ‚æŸ¥è¯¢ - æ ¸å¿ƒå…¥å£æ–¹æ³•

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
            context: æŸ¥è¯¢ä¸Šä¸‹æ–‡ (ç”¨æˆ·ä¿¡æ¯ã€å†å²æŸ¥è¯¢ç­‰)

        Returns:
            QueryAnalysisResult: å®Œæ•´çš„æŸ¥è¯¢åˆ†æç»“æœ
        """
        try:
            logger.info(f"ğŸ§  å¼€å§‹è§£æå¤æ‚æŸ¥è¯¢: {query}")
            self.processing_stats['total_queries'] += 1

            # ç¬¬1æ­¥: åŸºç¡€æŸ¥è¯¢é¢„å¤„ç†
            preprocessed_query = await self._preprocess_query(query)

            # ç¬¬2æ­¥: Claudeæ·±åº¦ç†è§£æŸ¥è¯¢æ„å›¾å’Œä¸šåŠ¡é€»è¾‘
            claude_analysis = await self._claude_understand_query(preprocessed_query, context)

            # ç¬¬3æ­¥: GPTåˆ†ææ•°æ®éœ€æ±‚å’Œè®¡ç®—è¦æ±‚
            gpt_analysis = await self._gpt_analyze_data_requirements(preprocessed_query, claude_analysis)

            # ç¬¬4æ­¥: ç»¼åˆåˆ†æï¼Œç¡®å®šå¤æ‚åº¦å’Œç±»å‹
            complexity_analysis = await self._analyze_query_complexity(
                preprocessed_query, claude_analysis, gpt_analysis
            )

            # ç¬¬5æ­¥: è§£ææ—¶é—´å’Œæ—¥æœŸè¦æ±‚
            time_analysis = await self._analyze_time_requirements(preprocessed_query, claude_analysis)

            # ç¬¬6æ­¥: ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
            execution_plan = await self._generate_execution_plan(
                preprocessed_query, claude_analysis, gpt_analysis, complexity_analysis
            )

            # ç¬¬7æ­¥: è®¾è®¡AIåä½œç­–ç•¥
            ai_collaboration_plan = self._design_ai_collaboration(
                complexity_analysis, execution_plan
            )

            # ç¬¬8æ­¥: æ„å»ºæœ€ç»ˆåˆ†æç»“æœ
            analysis_result = self._build_analysis_result(
                query, preprocessed_query, claude_analysis, gpt_analysis,
                complexity_analysis, time_analysis, execution_plan, ai_collaboration_plan
            )

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_processing_stats(analysis_result)

            logger.info(
                f"âœ… æŸ¥è¯¢è§£æå®Œæˆ: å¤æ‚åº¦={analysis_result.complexity.value}, ç±»å‹={analysis_result.query_type.value}")

            return analysis_result

        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢è§£æå¤±è´¥: {str(e)}")
            return self._create_error_analysis_result(query, str(e))

    # ============= Claudeä¸šåŠ¡ç†è§£å±‚ =============

    async def _claude_understand_query(self, query: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Claudeæ·±åº¦ç†è§£æŸ¥è¯¢çš„ä¸šåŠ¡é€»è¾‘å’Œæ„å›¾"""

        if not self.claude_client:
            logger.warning("Claudeå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€è§£æ")
            return await self._fallback_query_understanding(query)

        try:
            current_date = datetime.now().strftime("%Y-%m-%d")

            understanding_prompt = f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é‡‘èä¸šåŠ¡åˆ†æä¸“å®¶ã€‚è¯·æ·±åº¦åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢çš„ä¸šåŠ¡æ„å›¾å’Œé€»è¾‘éœ€æ±‚ã€‚

ç”¨æˆ·æŸ¥è¯¢: "{query}"
å½“å‰æ—¥æœŸ: {current_date}
æŸ¥è¯¢ä¸Šä¸‹æ–‡: {json.dumps(context or {}, ensure_ascii=False)}

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œä¸“ä¸šåˆ†æï¼š

1. **æ ¸å¿ƒä¸šåŠ¡æ„å›¾**: ç”¨æˆ·çœŸæ­£æƒ³äº†è§£ä»€ä¹ˆä¸šåŠ¡é—®é¢˜ï¼Ÿ
2. **ä¸šåŠ¡åœºæ™¯åˆ†ç±»**: è¿™å±äºå“ªç§ä¸šåŠ¡åœºæ™¯ï¼Ÿ(æ—¥å¸¸è¿è¥/è´¢åŠ¡è§„åˆ’/é£é™©ç®¡ç†/å¢é•¿åˆ†æ/ç”¨æˆ·è¡Œä¸º/äº§å“è¡¨ç°)
3. **åˆ†ææ·±åº¦è¦æ±‚**: éœ€è¦ä»€ä¹ˆç¨‹åº¦çš„åˆ†æï¼Ÿ(æ¦‚è§ˆ/è¶‹åŠ¿/é¢„æµ‹/æ·±åº¦å»ºæ¨¡)
4. **ä¸šåŠ¡é€»è¾‘å¤æ‚åº¦**: æ¶‰åŠå¤šå°‘å±‚ä¸šåŠ¡é€»è¾‘ï¼Ÿ
5. **æ—¶é—´ç»´åº¦åˆ†æ**: æ¶‰åŠä»€ä¹ˆæ—¶é—´èŒƒå›´å’Œæ—¶é—´æ¦‚å¿µï¼Ÿ
6. **å…³é”®ä¸šåŠ¡å‚æ•°**: æ¶‰åŠå“ªäº›é‡è¦çš„ä¸šåŠ¡å‚æ•°ï¼Ÿ(å¤æŠ•ç‡ã€å¢é•¿ç‡ã€é£é™©ç³»æ•°ç­‰)
7. **é¢„æœŸè¾“å‡º**: ç”¨æˆ·æœŸæœ›å¾—åˆ°ä»€ä¹ˆæ ·çš„ç­”æ¡ˆæ ¼å¼ï¼Ÿ

è¯·è¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœï¼š
{{
    "business_intent": {{
        "primary_goal": "ä¸»è¦ç›®æ ‡",
        "secondary_goals": ["æ¬¡è¦ç›®æ ‡1", "æ¬¡è¦ç›®æ ‡2"],
        "business_impact": "ä¸šåŠ¡å½±å“è¯„ä¼°",
        "urgency_level": "high/medium/low"
    }},
    "business_scenario": {{
        "primary_scenario": "ä¸»è¦ä¸šåŠ¡åœºæ™¯",
        "scenario_confidence": 0.0-1.0,
        "related_scenarios": ["ç›¸å…³åœºæ™¯1", "ç›¸å…³åœºæ™¯2"]
    }},
    "analysis_requirements": {{
        "depth_level": "overview/trend/prediction/deep_modeling",
        "analysis_type": "descriptive/diagnostic/predictive/prescriptive",
        "requires_forecasting": true/false,
        "requires_scenario_analysis": true/false
    }},
    "business_logic_complexity": {{
        "complexity_level": "simple/moderate/complex/expert",
        "reasoning_steps": ä¼°è®¡æ¨ç†æ­¥éª¤æ•°,
        "involves_multiple_factors": true/false,
        "requires_business_assumptions": true/false
    }},
    "key_business_parameters": {{
        "financial_metrics": ["å…³é”®è´¢åŠ¡æŒ‡æ ‡"],
        "operational_metrics": ["å…³é”®è¿è¥æŒ‡æ ‡"], 
        "risk_factors": ["é£é™©å› å­"],
        "external_factors": ["å¤–éƒ¨å› ç´ "]
    }},
    "expected_output_format": {{
        "format_type": "summary/detailed_analysis/dashboard/report",
        "visualization_needs": ["å›¾è¡¨ç±»å‹"],
        "actionable_insights_required": true/false
    }},
    "confidence_assessment": {{
        "understanding_confidence": 0.0-1.0,
        "clarity_score": 0.0-1.0,
        "potential_ambiguities": ["æ¨¡ç³Šç‚¹1", "æ¨¡ç³Šç‚¹2"]
    }}
}}

é‡ç‚¹å…³æ³¨ä¸šåŠ¡é€»è¾‘çš„åˆç†æ€§å’Œå®ç”¨æ€§ï¼Œç¡®ä¿åˆ†æç»“æœèƒ½å¤ŸæŒ‡å¯¼åç»­çš„æ•°æ®è·å–å’Œè®¡ç®—ç­–ç•¥ã€‚
"""

            result = await self.claude_client.analyze_complex_query(understanding_prompt, {
                "query": query,
                "context": context,
                "current_date": current_date
            })

            if result.get("success"):
                claude_analysis = result["analysis"]
                logger.info("âœ… Claudeä¸šåŠ¡ç†è§£å®Œæˆ")
                return {
                    "success": True,
                    "claude_understanding": claude_analysis,
                    "processing_method": "claude_analysis"
                }
            else:
                logger.warning(f"Claudeåˆ†æå¤±è´¥: {result.get('error', 'Unknown error')}")
                return await self._fallback_query_understanding(query)

        except Exception as e:
            logger.error(f"Claudeä¸šåŠ¡ç†è§£å¼‚å¸¸: {str(e)}")
            return await self._fallback_query_understanding(query)

    # ============= GPTæ•°æ®éœ€æ±‚åˆ†æå±‚ =============

    async def _gpt_analyze_data_requirements(self, query: str, claude_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """GPTåˆ†ææ•°æ®éœ€æ±‚å’Œè®¡ç®—è¦æ±‚"""

        if not self.gpt_client:
            logger.warning("GPTå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
            return self._fallback_data_requirements_analysis(query, claude_analysis)

        try:
            claude_understanding = claude_analysis.get("claude_understanding", {})

            data_analysis_prompt = f"""
åŸºäºä¸šåŠ¡åˆ†æç»“æœï¼Œè¯·ç²¾ç¡®åˆ†ææŸ¥è¯¢çš„æ•°æ®éœ€æ±‚å’Œè®¡ç®—è¦æ±‚ï¼š

åŸå§‹æŸ¥è¯¢: "{query}"
ä¸šåŠ¡ç†è§£ç»“æœ: {json.dumps(claude_understanding, ensure_ascii=False)}

å¯ç”¨çš„APIæ•°æ®æº:
1. /api/sta/system - ç³»ç»Ÿæ¦‚è§ˆ (æ€»ä½™é¢ã€ç”¨æˆ·ç»Ÿè®¡ã€ä»Šæ—¥åˆ°æœŸç­‰)
2. /api/sta/day - æ¯æ—¥æ•°æ® (æ³¨å†Œã€æŒä»“ã€å…¥é‡‘ã€å‡ºé‡‘)
3. /api/sta/product - äº§å“æ•°æ® (äº§å“åˆ—è¡¨ã€æŒæœ‰æƒ…å†µã€åˆ°æœŸé¢„æµ‹)
4. /api/sta/user_daily - ç”¨æˆ·æ¯æ—¥æ•°æ® (VIPåˆ†å¸ƒã€æ–°å¢ç”¨æˆ·)
5. /api/sta/user - ç”¨æˆ·è¯¦æƒ… (æŠ•èµ„é¢ã€å¥–åŠ±ã€æŠ•æŠ¥æ¯”)
6. /api/sta/product_end - å•æ—¥åˆ°æœŸæ•°æ®
7. /api/sta/product_end_interval - åŒºé—´åˆ°æœŸæ•°æ®

è¯·åˆ†æå¹¶è¿”å›JSONæ ¼å¼ç»“æœï¼š
{{
    "required_data_sources": {{
        "primary_apis": ["å¿…éœ€çš„ä¸»è¦API"],
        "secondary_apis": ["å¯é€‰çš„è¾…åŠ©API"],
        "data_freshness_requirements": "realtime/daily/weekly"
    }},
    "time_range_requirements": {{
        "historical_data_needed": true/false,
        "prediction_horizon_needed": true/false,
        "minimum_historical_days": å¤©æ•°,
        "optimal_historical_days": å¤©æ•°
    }},
    "calculation_requirements": {{
        "basic_calculations": ["åŸºç¡€è®¡ç®—ç±»å‹"],
        "advanced_calculations": ["é«˜çº§è®¡ç®—ç±»å‹"],
        "requires_financial_modeling": true/false,
        "requires_statistical_analysis": true/false,
        "calculation_complexity": "simple/moderate/complex"
    }},
    "data_processing_needs": {{
        "data_cleaning_required": true/false,
        "data_alignment_needed": true/false,
        "missing_data_handling": "ignore/interpolate/estimate",
        "outlier_detection_needed": true/false
    }},
    "performance_considerations": {{
        "estimated_data_volume": "small/medium/large",
        "processing_intensity": "low/medium/high",
        "real_time_requirements": true/false,
        "caching_beneficial": true/false
    }},
    "validation_requirements": {{
        "data_quality_checks": ["æ£€æŸ¥ç±»å‹"],
        "business_logic_validation": true/false,
        "result_verification_needed": true/false
    }}
}}

é‡ç‚¹å…³æ³¨æ•°æ®è·å–çš„æ•ˆç‡å’Œè®¡ç®—çš„å‡†ç¡®æ€§ã€‚
"""

            result = await self.gpt_client.process_direct_query(data_analysis_prompt, {
                "query": query,
                "claude_analysis": claude_understanding
            })

            if result.get("success"):
                # è§£æGPTçš„æ–‡æœ¬å“åº”
                gpt_response = result["response"]

                try:
                    # å°è¯•ä»å“åº”ä¸­æå–JSON
                    import re
                    json_match = re.search(r'\{.*\}', gpt_response, re.DOTALL)
                    if json_match:
                        gpt_analysis = json.loads(json_match.group())
                        logger.info("âœ… GPTæ•°æ®éœ€æ±‚åˆ†æå®Œæˆ")
                        return {
                            "success": True,
                            "gpt_analysis": gpt_analysis,
                            "processing_method": "gpt_analysis"
                        }
                    else:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œä½¿ç”¨æ–‡æœ¬è§£æ
                        return {
                            "success": True,
                            "gpt_analysis": {"raw_response": gpt_response},
                            "processing_method": "gpt_text_analysis"
                        }

                except json.JSONDecodeError:
                    logger.warning("GPTå“åº”JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨æ–‡æœ¬åˆ†æ")
                    return {
                        "success": True,
                        "gpt_analysis": {"raw_response": gpt_response},
                        "processing_method": "gpt_text_fallback"
                    }
            else:
                logger.warning(f"GPTåˆ†æå¤±è´¥: {result.get('error', 'Unknown error')}")
                return self._fallback_data_requirements_analysis(query, claude_analysis)

        except Exception as e:
            logger.error(f"GPTæ•°æ®éœ€æ±‚åˆ†æå¼‚å¸¸: {str(e)}")
            return self._fallback_data_requirements_analysis(query, claude_analysis)

    # ============= å¤æ‚åº¦åˆ†æå±‚ =============

    async def _analyze_query_complexity(self, query: str, claude_analysis: Dict[str, Any],
                                        gpt_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææŸ¥è¯¢å¤æ‚åº¦å¹¶ç¡®å®šå¤„ç†ç­–ç•¥"""

        try:
            logger.info("ğŸ” åˆ†ææŸ¥è¯¢å¤æ‚åº¦")

            # ä»Claudeåˆ†æä¸­æå–å¤æ‚åº¦æŒ‡æ ‡
            claude_data = claude_analysis.get("claude_understanding", {})
            business_logic = claude_data.get("business_logic_complexity", {})
            analysis_requirements = claude_data.get("analysis_requirements", {})

            # ä»GPTåˆ†æä¸­æå–è®¡ç®—å¤æ‚åº¦
            gpt_data = gpt_analysis.get("gpt_analysis", {})
            calculation_requirements = gpt_data.get("calculation_requirements", {})
            processing_needs = gpt_data.get("data_processing_needs", {})

            # ğŸ¯ å¤æ‚åº¦è¯„åˆ†è®¡ç®—
            complexity_score = 0
            complexity_factors = []

            # 1. ä¸šåŠ¡é€»è¾‘å¤æ‚åº¦ (0-3åˆ†)
            logic_level = business_logic.get("complexity_level", "simple")
            if logic_level == "expert":
                complexity_score += 3
                complexity_factors.append("expert_business_logic")
            elif logic_level == "complex":
                complexity_score += 2
                complexity_factors.append("complex_business_logic")
            elif logic_level == "moderate":
                complexity_score += 1
                complexity_factors.append("moderate_business_logic")

            # 2. åˆ†ææ·±åº¦è¦æ±‚ (0-2åˆ†)
            depth_level = analysis_requirements.get("depth_level", "overview")
            if depth_level == "deep_modeling":
                complexity_score += 2
                complexity_factors.append("deep_modeling_required")
            elif depth_level == "prediction":
                complexity_score += 1.5
                complexity_factors.append("prediction_analysis")
            elif depth_level == "trend":
                complexity_score += 1
                complexity_factors.append("trend_analysis")

            # 3. è®¡ç®—å¤æ‚åº¦ (0-2åˆ†)
            calc_complexity = calculation_requirements.get("calculation_complexity", "simple")
            if calc_complexity == "complex":
                complexity_score += 2
                complexity_factors.append("complex_calculations")
            elif calc_complexity == "moderate":
                complexity_score += 1
                complexity_factors.append("moderate_calculations")

            # 4. æ•°æ®å¤„ç†éœ€æ±‚ (0-2åˆ†)
            if processing_needs.get("data_alignment_needed"):
                complexity_score += 0.5
                complexity_factors.append("data_alignment")
            if processing_needs.get("outlier_detection_needed"):
                complexity_score += 0.5
                complexity_factors.append("outlier_detection")
            if gpt_data.get("time_range_requirements", {}).get("historical_data_needed"):
                complexity_score += 1
                complexity_factors.append("historical_analysis")

            # 5. ç‰¹æ®Šéœ€æ±‚ (0-1åˆ†)
            if analysis_requirements.get("requires_forecasting"):
                complexity_score += 1
                complexity_factors.append("forecasting_required")
            if analysis_requirements.get("requires_scenario_analysis"):
                complexity_score += 0.5
                complexity_factors.append("scenario_analysis")

            # ğŸ¯ ç¡®å®šæœ€ç»ˆå¤æ‚åº¦ç­‰çº§
            if complexity_score >= 6:
                final_complexity = QueryComplexity.EXPERT
            elif complexity_score >= 4:
                final_complexity = QueryComplexity.COMPLEX
            elif complexity_score >= 2:
                final_complexity = QueryComplexity.MEDIUM
            else:
                final_complexity = QueryComplexity.SIMPLE

            # ğŸ¯ ç¡®å®šæŸ¥è¯¢ç±»å‹
            query_type = self._determine_query_type(claude_data, gpt_data, query)

            # ğŸ¯ ç¡®å®šä¸šåŠ¡åœºæ™¯
            business_scenario = self._determine_business_scenario(claude_data)

            # è®¡ç®—ç½®ä¿¡åº¦
            claude_confidence = claude_data.get("confidence_assessment", {}).get("understanding_confidence", 0.8)
            gpt_success = gpt_analysis.get("success", False)
            confidence_score = claude_confidence * (0.9 if gpt_success else 0.7)

            return {
                "complexity": final_complexity,
                "complexity_score": complexity_score,
                "complexity_factors": complexity_factors,
                "query_type": query_type,
                "business_scenario": business_scenario,
                "confidence_score": confidence_score,
                "analysis_metadata": {
                    "claude_logic_complexity": logic_level,
                    "gpt_calc_complexity": calc_complexity,
                    "depth_requirement": depth_level,
                    "total_complexity_indicators": len(complexity_factors)
                }
            }

        except Exception as e:
            logger.error(f"å¤æ‚åº¦åˆ†æå¤±è´¥: {str(e)}")
            # é™çº§åˆ°åŸºç¡€åˆ†æ
            return {
                "complexity": QueryComplexity.MEDIUM,
                "complexity_score": 2.0,
                "complexity_factors": ["fallback_analysis"],
                "query_type": QueryType.DATA_RETRIEVAL,
                "business_scenario": BusinessScenario.DAILY_OPERATIONS,
                "confidence_score": 0.5,
                "analysis_metadata": {"fallback_reason": str(e)}
            }

    def _determine_query_type(self, claude_data: Dict[str, Any],
                              gpt_data: Dict[str, Any], query: str) -> QueryType:
        """ç¡®å®šæŸ¥è¯¢ç±»å‹"""

        # ä»Claudeåˆ†æä¸­è·å–åˆ†æç±»å‹
        analysis_type = claude_data.get("analysis_requirements", {}).get("analysis_type", "descriptive")
        depth_level = claude_data.get("analysis_requirements", {}).get("depth_level", "overview")

        # ä»GPTåˆ†æä¸­è·å–è®¡ç®—éœ€æ±‚
        requires_forecasting = claude_data.get("analysis_requirements", {}).get("requires_forecasting", False)
        requires_scenario = claude_data.get("analysis_requirements", {}).get("requires_scenario_analysis", False)

        # åŸºäºæ¨¡å¼åŒ¹é…
        query_lower = query.lower()

        # ä¼˜å…ˆçº§åˆ¤æ–­
        if requires_forecasting or "é¢„æµ‹" in query or "é¢„è®¡" in query:
            return QueryType.PREDICTION
        elif requires_scenario or "å‡è®¾" in query or "å¦‚æœ" in query:
            return QueryType.SCENARIO_SIMULATION
        elif "å¯¹æ¯”" in query or "æ¯”è¾ƒ" in query or analysis_type == "comparative":
            return QueryType.COMPARISON
        elif "è®¡ç®—" in query or "å¤æŠ•" in query or "æç°" in query:
            return QueryType.CALCULATION
        elif "é£é™©" in query or "å®‰å…¨" in query or "å¯æŒç»­" in query:
            return QueryType.RISK_ASSESSMENT
        elif "è¶‹åŠ¿" in query or "å¢é•¿" in query or depth_level == "trend":
            return QueryType.TREND_ANALYSIS
        else:
            return QueryType.DATA_RETRIEVAL

    def _determine_business_scenario(self, claude_data: Dict[str, Any]) -> BusinessScenario:
        """ç¡®å®šä¸šåŠ¡åœºæ™¯"""

        primary_scenario = claude_data.get("business_scenario", {}).get("primary_scenario", "")

        scenario_mapping = {
            "daily_operations": BusinessScenario.DAILY_OPERATIONS,
            "financial_planning": BusinessScenario.FINANCIAL_PLANNING,
            "risk_management": BusinessScenario.RISK_MANAGEMENT,
            "growth_analysis": BusinessScenario.GROWTH_ANALYSIS,
            "user_behavior": BusinessScenario.USER_BEHAVIOR,
            "product_performance": BusinessScenario.PRODUCT_PERFORMANCE,
            "compliance_check": BusinessScenario.COMPLIANCE_CHECK
        }

        return scenario_mapping.get(primary_scenario, BusinessScenario.DAILY_OPERATIONS)

    # ============= æ—¶é—´éœ€æ±‚åˆ†æ =============

    async def _analyze_time_requirements(self, query: str, claude_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ—¶é—´å’Œæ—¥æœŸéœ€æ±‚"""

        try:
            logger.info("ğŸ“… åˆ†ææ—¶é—´éœ€æ±‚")

            # ä½¿ç”¨date_utilsè¿›è¡ŒAIæ—¥æœŸè§£æ
            date_parse_result = await self.date_utils.parse_dates_from_query(query)

            # ä»Claudeåˆ†æä¸­è·å–æ—¶é—´ç›¸å…³ä¿¡æ¯
            claude_data = claude_analysis.get("claude_understanding", {})
            analysis_requirements = claude_data.get("analysis_requirements", {})

            # ç¡®å®šæ—¶é—´èŒƒå›´éœ€æ±‚
            if date_parse_result.has_time_info:
                # æŸ¥è¯¢ä¸­æ˜ç¡®åŒ…å«æ—¶é—´ä¿¡æ¯
                time_requirements = {
                    "has_explicit_time": True,
                    "parsed_dates": date_parse_result.dates,
                    "parsed_ranges": [
                        {
                            "start_date": r.start_date,
                            "end_date": r.end_date,
                            "description": r.description
                        }
                        for r in date_parse_result.ranges
                    ],
                    "relative_terms": date_parse_result.relative_terms
                }
            else:
                # æ²¡æœ‰æ˜ç¡®æ—¶é—´ä¿¡æ¯ï¼Œéœ€è¦æ¨æ–­
                inferred_range = await self.date_utils.infer_optimal_time_range(query, "analysis")
                time_requirements = {
                    "has_explicit_time": False,
                    "inferred_range": {
                        "start_date": inferred_range.start_date,
                        "end_date": inferred_range.end_date,
                        "description": inferred_range.description
                    }
                }

            # åˆ†ææ—¶é—´å¤æ‚åº¦
            requires_historical = analysis_requirements.get("requires_forecasting", False)
            depth_level = analysis_requirements.get("depth_level", "overview")

            if depth_level in ["prediction", "deep_modeling"] or requires_historical:
                time_requirements["complexity"] = "high"
                time_requirements["min_historical_days"] = 90
                time_requirements["optimal_historical_days"] = 180
            elif depth_level == "trend":
                time_requirements["complexity"] = "medium"
                time_requirements["min_historical_days"] = 30
                time_requirements["optimal_historical_days"] = 60
            else:
                time_requirements["complexity"] = "low"
                time_requirements["min_historical_days"] = 7
                time_requirements["optimal_historical_days"] = 30

            return {
                "success": True,
                "time_requirements": time_requirements,
                "date_parse_result": date_parse_result
            }

        except Exception as e:
            logger.error(f"æ—¶é—´éœ€æ±‚åˆ†æå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "fallback_time_requirements": {
                    "has_explicit_time": False,
                    "complexity": "medium",
                    "min_historical_days": 30
                }
            }

    # ============= æ‰§è¡Œè®¡åˆ’ç”Ÿæˆ =============

    async def _generate_execution_plan(self, query: str, claude_analysis: Dict[str, Any],
                                       gpt_analysis: Dict[str, Any],
                                       complexity_analysis: Dict[str, Any]) -> List[ExecutionStep]:
        """ç”Ÿæˆè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’"""

        try:
            logger.info("ğŸ“‹ ç”Ÿæˆæ‰§è¡Œè®¡åˆ’")

            complexity = complexity_analysis["complexity"]
            query_type = complexity_analysis["query_type"]

            execution_steps = []

            # ğŸ”¥ æ ¹æ®å¤æ‚åº¦å’Œç±»å‹ç”Ÿæˆä¸åŒçš„æ‰§è¡Œè®¡åˆ’
            if complexity == QueryComplexity.SIMPLE:
                execution_steps = self._generate_simple_execution_plan(query, claude_analysis, gpt_analysis)
            elif complexity == QueryComplexity.MEDIUM:
                execution_steps = self._generate_medium_execution_plan(query, claude_analysis, gpt_analysis)
            elif complexity == QueryComplexity.COMPLEX:
                execution_steps = self._generate_complex_execution_plan(query, claude_analysis, gpt_analysis)
            else:  # EXPERT
                execution_steps = self._generate_expert_execution_plan(query, claude_analysis, gpt_analysis)

            # ä¸ºæ¯ä¸ªæ­¥éª¤æ·»åŠ ä¾èµ–å…³ç³»å’Œæ—¶é—´ä¼°è®¡
            self._optimize_execution_plan(execution_steps)

            logger.info(f"âœ… ç”Ÿæˆ{len(execution_steps)}æ­¥æ‰§è¡Œè®¡åˆ’")
            return execution_steps

        except Exception as e:
            logger.error(f"æ‰§è¡Œè®¡åˆ’ç”Ÿæˆå¤±è´¥: {str(e)}")
            # è¿”å›åŸºç¡€æ‰§è¡Œè®¡åˆ’
            return [
                ExecutionStep(
                    step_id="fallback_step",
                    step_type="data_retrieval",
                    description="åŸºç¡€æ•°æ®è·å–",
                    required_data=["system_data"],
                    processing_method="direct_api_call",
                    dependencies=[],
                    estimated_time=3.0,
                    ai_model_preference="gpt"
                )
            ]

    def _generate_simple_execution_plan(self, query: str, claude_analysis: Dict[str, Any],
                                        gpt_analysis: Dict[str, Any]) -> List[ExecutionStep]:
        """ç”Ÿæˆç®€å•æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’"""
        return [
            ExecutionStep(
                step_id="simple_data_fetch",
                step_type="data_retrieval",
                description="è·å–å½“å‰æ•°æ®",
                required_data=["system_data"],
                processing_method="single_api_call",
                dependencies=[],
                estimated_time=2.0,
                ai_model_preference="gpt"
            ),
            ExecutionStep(
                step_id="simple_format",
                step_type="data_formatting",
                description="æ ¼å¼åŒ–è¾“å‡º",
                required_data=["system_data"],
                processing_method="ai_formatting",
                dependencies=["simple_data_fetch"],
                estimated_time=1.0,
                ai_model_preference="gpt"
            )
        ]

    def _generate_medium_execution_plan(self, query: str, claude_analysis: Dict[str, Any],
                                        gpt_analysis: Dict[str, Any]) -> List[ExecutionStep]:
        """ç”Ÿæˆä¸­ç­‰å¤æ‚åº¦æ‰§è¡Œè®¡åˆ’"""
        return [
            ExecutionStep(
                step_id="medium_data_collection",
                step_type="data_collection",
                description="æ”¶é›†ç›¸å…³æ•°æ®",
                required_data=["system_data", "historical_data"],
                processing_method="intelligent_data_fetch",
                dependencies=[],
                estimated_time=5.0,
                ai_model_preference="api_connector"
            ),
            ExecutionStep(
                step_id="medium_analysis",
                step_type="trend_analysis",
                description="è¶‹åŠ¿åˆ†æè®¡ç®—",
                required_data=["historical_data"],
                processing_method="time_series_analysis",
                dependencies=["medium_data_collection"],
                estimated_time=8.0,
                ai_model_preference="gpt"
            ),
            ExecutionStep(
                step_id="medium_insights",
                step_type="insight_generation",
                description="ç”Ÿæˆä¸šåŠ¡æ´å¯Ÿ",
                required_data=["analysis_results"],
                processing_method="ai_insight_generation",
                dependencies=["medium_analysis"],
                estimated_time=5.0,
                ai_model_preference="claude"
            )
        ]

    def _generate_complex_execution_plan(self, query: str, claude_analysis: Dict[str, Any],
                                         gpt_analysis: Dict[str, Any]) -> List[ExecutionStep]:
        """ç”Ÿæˆå¤æ‚æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’"""
        return [
            ExecutionStep(
                step_id="complex_planning",
                step_type="analysis_planning",
                description="åˆ†æç­–ç•¥è§„åˆ’",
                required_data=["query_analysis"],
                processing_method="ai_planning",
                dependencies=[],
                estimated_time=3.0,
                ai_model_preference="claude"
            ),
            ExecutionStep(
                step_id="complex_data_comprehensive",
                step_type="comprehensive_data_collection",
                description="ç»¼åˆæ•°æ®è·å–",
                required_data=["system_data", "historical_data", "product_data"],
                processing_method="comprehensive_data_package",
                dependencies=["complex_planning"],
                estimated_time=10.0,
                ai_model_preference="api_connector"
            ),
            ExecutionStep(
                step_id="complex_preprocessing",
                step_type="data_preprocessing",
                description="æ•°æ®é¢„å¤„ç†å’Œæ¸…æ´—",
                required_data=["raw_data"],
                processing_method="time_series_building",
                dependencies=["complex_data_comprehensive"],
                estimated_time=8.0,
                ai_model_preference="time_series_builder"
            ),
            ExecutionStep(
                step_id="complex_analysis",
                step_type="multi_dimensional_analysis",
                description="å¤šç»´åº¦åˆ†æ",
                required_data=["processed_data"],
                processing_method="dual_ai_analysis",
                dependencies=["complex_preprocessing"],
                estimated_time=15.0,
                ai_model_preference="claude_gpt_collaboration"
            ),
            ExecutionStep(
                step_id="complex_insights",
                step_type="comprehensive_insight_generation",
                description="ç»¼åˆæ´å¯Ÿç”Ÿæˆ",
                required_data=["analysis_results"],
                processing_method="expert_insight_generation",
                dependencies=["complex_analysis"],
                estimated_time=10.0,
                ai_model_preference="claude"
            )
        ]

    def _generate_expert_execution_plan(self, query: str, claude_analysis: Dict[str, Any],
                                        gpt_analysis: Dict[str, Any]) -> List[ExecutionStep]:
        """ç”Ÿæˆä¸“å®¶çº§æ‰§è¡Œè®¡åˆ’"""
        return [
            ExecutionStep(
                step_id="expert_strategy_design",
                step_type="strategic_planning",
                description="ä¸“å®¶çº§ç­–ç•¥è®¾è®¡",
                required_data=["query_analysis", "business_context"],
                processing_method="ai_strategic_planning",
                dependencies=[],
                estimated_time=5.0,
                ai_model_preference="claude"
            ),
            ExecutionStep(
                step_id="expert_data_ecosystem",
                step_type="data_ecosystem_building",
                description="æ„å»ºæ•°æ®ç”Ÿæ€ç³»ç»Ÿ",
                required_data=["all_available_data"],
                processing_method="comprehensive_data_ecosystem",
                dependencies=["expert_strategy_design"],
                estimated_time=15.0,
                ai_model_preference="api_connector"
            ),
            ExecutionStep(
                step_id="expert_time_series",
                step_type="advanced_time_series_analysis",
                description="é«˜çº§æ—¶é—´åºåˆ—åˆ†æ",
                required_data=["historical_data"],
                processing_method="multi_metric_time_series",
                dependencies=["expert_data_ecosystem"],
                estimated_time=12.0,
                ai_model_preference="time_series_builder"
            ),
            ExecutionStep(
                step_id="expert_modeling",
                step_type="predictive_modeling",
                description="é¢„æµ‹å»ºæ¨¡åˆ†æ",
                required_data=["time_series_data"],
                processing_method="advanced_financial_modeling",
                dependencies=["expert_time_series"],
                estimated_time=20.0,
                ai_model_preference="gpt"
            ),
            ExecutionStep(
                step_id="expert_scenario_analysis",
                step_type="scenario_simulation",
                description="åœºæ™¯æ¨¡æ‹Ÿåˆ†æ",
                required_data=["model_results"],
                processing_method="scenario_simulation",
                dependencies=["expert_modeling"],
                estimated_time=15.0,
                ai_model_preference="financial_calculator"
            ),
            ExecutionStep(
                step_id="expert_validation",
                step_type="result_validation",
                description="ç»“æœéªŒè¯å’Œè´¨é‡æ£€æŸ¥",
                required_data=["all_results"],
                processing_method="ai_validation",
                dependencies=["expert_scenario_analysis"],
                estimated_time=8.0,
                ai_model_preference="claude_gpt_collaboration"
            ),
            ExecutionStep(
                step_id="expert_insights",
                step_type="expert_insight_synthesis",
                description="ä¸“å®¶çº§æ´å¯Ÿç»¼åˆ",
                required_data=["validated_results"],
                processing_method="expert_insight_synthesis",
                dependencies=["expert_validation"],
                estimated_time=12.0,
                ai_model_preference="claude"
            )
        ]

    def _optimize_execution_plan(self, execution_steps: List[ExecutionStep]):
        """ä¼˜åŒ–æ‰§è¡Œè®¡åˆ’"""

        # æ£€æŸ¥å¹¶è¡Œæ‰§è¡Œå¯èƒ½æ€§
        for i, step in enumerate(execution_steps):
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥ä¸å‰é¢çš„æ­¥éª¤å¹¶è¡Œ
            if i > 0:
                previous_step = execution_steps[i - 1]
                if (step.step_type != previous_step.step_type and
                        len(set(step.required_data) & set(previous_step.required_data)) == 0):
                    # å¯èƒ½å¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼Œæ ‡è®°ä¸ºå¯ä¼˜åŒ–
                    if step.step_id not in previous_step.dependencies:
                        step.estimated_time *= 0.8  # å¹¶è¡Œæ‰§è¡Œæ—¶é—´ä¼˜åŒ–

    # ============= AIåä½œç­–ç•¥è®¾è®¡ =============

    def _design_ai_collaboration(self, complexity_analysis: Dict[str, Any],
                                 execution_plan: List[ExecutionStep]) -> Dict[str, Any]:
        """è®¾è®¡AIåä½œç­–ç•¥"""

        complexity = complexity_analysis["complexity"]
        query_type = complexity_analysis["query_type"]

        # ğŸ¤– æ ¹æ®å¤æ‚åº¦å’Œç±»å‹è®¾è®¡åä½œç­–ç•¥
        if complexity == QueryComplexity.SIMPLE:
            collaboration_plan = {
                "strategy_type": "single_ai",
                "primary_ai": "gpt",
                "collaboration_level": "minimal",
                "handoff_points": [],
                "quality_gates": ["basic_validation"]
            }
        elif complexity == QueryComplexity.MEDIUM:
            collaboration_plan = {
                "strategy_type": "sequential_collaboration",
                "primary_ai": "gpt",
                "secondary_ai": "claude",
                "collaboration_level": "moderate",
                "handoff_points": ["after_calculation", "before_insight_generation"],
                "quality_gates": ["data_validation", "logic_validation"]
            }
        elif complexity == QueryComplexity.COMPLEX:
            collaboration_plan = {
                "strategy_type": "parallel_collaboration",
                "primary_ai": "claude",
                "secondary_ai": "gpt",
                "collaboration_level": "high",
                "handoff_points": ["strategy_planning", "data_analysis", "insight_synthesis"],
                "quality_gates": ["strategy_validation", "calculation_validation", "insight_validation"]
            }
        else:  # EXPERT
            collaboration_plan = {
                "strategy_type": "deep_collaboration",
                "primary_ai": "claude",
                "secondary_ai": "gpt",
                "collaboration_level": "expert",
                "handoff_points": ["strategic_planning", "data_modeling", "scenario_analysis", "result_validation",
                                   "insight_synthesis"],
                "quality_gates": ["strategy_gate", "modeling_gate", "scenario_gate", "validation_gate", "insight_gate"]
            }

        # æ·»åŠ å…·ä½“çš„AIä»»åŠ¡åˆ†é…
        collaboration_plan["ai_task_allocation"] = self._allocate_ai_tasks(execution_plan)

        return collaboration_plan

    def _allocate_ai_tasks(self, execution_plan: List[ExecutionStep]) -> Dict[str, List[str]]:
        """åˆ†é…AIä»»åŠ¡"""

        claude_tasks = []
        gpt_tasks = []

        for step in execution_plan:
            if step.ai_model_preference in ["claude", "claude_gpt_collaboration"]:
                claude_tasks.append(step.step_id)
            elif step.ai_model_preference == "gpt":
                gpt_tasks.append(step.step_id)

        return {
            "claude_tasks": claude_tasks,
            "gpt_tasks": gpt_tasks,
            "collaborative_tasks": [
                step.step_id for step in execution_plan
                if step.ai_model_preference == "claude_gpt_collaboration"
            ]
        }

    # ============= ç»“æœæ„å»ºå’Œè¾…åŠ©æ–¹æ³• =============

    def _build_analysis_result(self, original_query: str, preprocessed_query: str,
                               claude_analysis: Dict[str, Any], gpt_analysis: Dict[str, Any],
                               complexity_analysis: Dict[str, Any], time_analysis: Dict[str, Any],
                               execution_plan: List[ExecutionStep],
                               ai_collaboration_plan: Dict[str, Any]) -> QueryAnalysisResult:
        """æ„å»ºæœ€ç»ˆåˆ†æç»“æœ"""

        # è®¡ç®—æ€»é¢„ä¼°æ—¶é—´
        total_estimated_time = sum(step.estimated_time for step in execution_plan)

        # æå–æ•°æ®éœ€æ±‚
        gpt_data = gpt_analysis.get("gpt_analysis", {})
        data_requirements = gpt_data.get("required_data_sources", {})
        required_apis = data_requirements.get("primary_apis", []) + data_requirements.get("secondary_apis", [])

        # æå–ä¸šåŠ¡å‚æ•°
        claude_data = claude_analysis.get("claude_understanding", {})
        business_parameters = claude_data.get("key_business_parameters", {})
        calculation_requirements = gpt_data.get("calculation_requirements", {})

        # ç¡®å®šå¤„ç†ç­–ç•¥
        complexity = complexity_analysis["complexity"]
        if complexity == QueryComplexity.SIMPLE:
            processing_strategy = "direct_processing"
        elif complexity == QueryComplexity.MEDIUM:
            processing_strategy = "standard_analysis_pipeline"
        elif complexity == QueryComplexity.COMPLEX:
            processing_strategy = "comprehensive_analysis_pipeline"
        else:
            processing_strategy = "expert_analysis_pipeline"

        return QueryAnalysisResult(
            original_query=original_query,
            complexity=complexity_analysis["complexity"],
            query_type=complexity_analysis["query_type"],
            business_scenario=complexity_analysis["business_scenario"],
            confidence_score=complexity_analysis["confidence_score"],

            time_requirements=time_analysis.get("time_requirements", {}),
            date_parse_result=time_analysis.get("date_parse_result"),

            data_requirements=data_requirements,
            required_apis=required_apis,

            business_parameters=business_parameters,
            calculation_requirements=calculation_requirements,

            execution_plan=execution_plan,
            processing_strategy=processing_strategy,

            ai_collaboration_plan=ai_collaboration_plan,

            analysis_timestamp=datetime.now().isoformat(),
            estimated_total_time=total_estimated_time,
            processing_metadata={
                "claude_analysis_success": claude_analysis.get("success", False),
                "gpt_analysis_success": gpt_analysis.get("success", False),
                "complexity_factors": complexity_analysis.get("complexity_factors", []),
                "total_execution_steps": len(execution_plan),
                "ai_collaboration_level": ai_collaboration_plan.get("collaboration_level", "minimal")
            }
        )

    async def _preprocess_query(self, query: str) -> str:
        """é¢„å¤„ç†æŸ¥è¯¢æ–‡æœ¬"""

        # åŸºç¡€æ¸…ç†
        cleaned_query = query.strip()

        # ç§»é™¤å¤šä½™ç©ºæ ¼
        cleaned_query = re.sub(r'\s+', ' ', cleaned_query)

        # æ ‡å‡†åŒ–å¸¸è§æœ¯è¯­
        replacements = {
            'è¤‡æŠ•': 'å¤æŠ•',
            'ç¾é‡‘': 'ç°é‡‘',
            'è³‡é‡‘': 'èµ„é‡‘',
            'é æ¸¬': 'é¢„æµ‹',
            'é è¨ˆ': 'é¢„è®¡'
        }

        for old, new in replacements.items():
            cleaned_query = cleaned_query.replace(old, new)

        return cleaned_query

    async def _fallback_query_understanding(self, query: str) -> Dict[str, Any]:
        """é™çº§æŸ¥è¯¢ç†è§£"""

        # åŸºäºæ¨¡å¼åŒ¹é…çš„åŸºç¡€ç†è§£
        understanding = {
            "business_intent": {
                "primary_goal": "æ•°æ®æŸ¥è¯¢",
                "urgency_level": "medium"
            },
            "business_scenario": {
                "primary_scenario": "daily_operations",
                "scenario_confidence": 0.6
            },
            "analysis_requirements": {
                "depth_level": "overview",
                "analysis_type": "descriptive"
            },
            "business_logic_complexity": {
                "complexity_level": "simple",
                "reasoning_steps": 1
            },
            "confidence_assessment": {
                "understanding_confidence": 0.6,
                "clarity_score": 0.7
            }
        }

        return {
            "success": True,
            "claude_understanding": understanding,
            "processing_method": "fallback_pattern_matching"
        }

    def _fallback_data_requirements_analysis(self, query: str, claude_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """é™çº§æ•°æ®éœ€æ±‚åˆ†æ"""

        # åŸºç¡€æ•°æ®éœ€æ±‚æ¨æ–­
        analysis = {
            "required_data_sources": {
                "primary_apis": ["system"],
                "data_freshness_requirements": "daily"
            },
            "calculation_requirements": {
                "basic_calculations": ["basic_stats"],
                "calculation_complexity": "simple"
            },
            "data_processing_needs": {
                "data_cleaning_required": True,
                "missing_data_handling": "ignore"
            }
        }

        return {
            "success": True,
            "gpt_analysis": analysis,
            "processing_method": "fallback_basic_requirements"
        }

    def _create_error_analysis_result(self, query: str, error: str) -> QueryAnalysisResult:
        """åˆ›å»ºé”™è¯¯åˆ†æç»“æœ"""

        error_execution_plan = [
            ExecutionStep(
                step_id="error_handling",
                step_type="error_response",
                description=f"å¤„ç†è§£æé”™è¯¯: {error}",
                required_data=[],
                processing_method="error_handling",
                dependencies=[],
                estimated_time=1.0,
                ai_model_preference="system"
            )
        ]

        return QueryAnalysisResult(
            original_query=query,
            complexity=QueryComplexity.SIMPLE,
            query_type=QueryType.DATA_RETRIEVAL,
            business_scenario=BusinessScenario.DAILY_OPERATIONS,
            confidence_score=0.0,

            time_requirements={},
            date_parse_result=None,

            data_requirements={},
            required_apis=[],

            business_parameters={},
            calculation_requirements={},

            execution_plan=error_execution_plan,
            processing_strategy="error_handling",

            ai_collaboration_plan={"strategy_type": "error_handling"},

            analysis_timestamp=datetime.now().isoformat(),
            estimated_total_time=1.0,
            processing_metadata={"error": error}
        )

    def _update_processing_stats(self, result: QueryAnalysisResult):
        """æ›´æ–°å¤„ç†ç»Ÿè®¡"""

        self.processing_stats['complexity_distribution'][result.complexity.value] += 1

        query_type_key = result.query_type.value
        if query_type_key not in self.processing_stats['query_type_distribution']:
            self.processing_stats['query_type_distribution'][query_type_key] = 0
        self.processing_stats['query_type_distribution'][query_type_key] += 1

        if result.ai_collaboration_plan.get("collaboration_level") in ["high", "expert"]:
            self.processing_stats['ai_collaboration_usage'] += 1

        # æ›´æ–°å¹³å‡ç½®ä¿¡åº¦
        total = self.processing_stats['total_queries']
        current_avg = self.processing_stats['average_confidence']
        new_avg = (current_avg * (total - 1) + result.confidence_score) / total
        self.processing_stats['average_confidence'] = new_avg

    # ============= å·¥å…·æ–¹æ³• =============

    def get_processing_stats(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        return self.processing_stats.copy()

    async def validate_query(self, query: str) -> Dict[str, Any]:
        """éªŒè¯æŸ¥è¯¢æœ‰æ•ˆæ€§"""

        if not query or len(query.strip()) == 0:
            return {"valid": False, "error": "æŸ¥è¯¢ä¸ºç©º"}

        if len(query) > 1000:
            return {"valid": False, "error": "æŸ¥è¯¢è¿‡é•¿"}

        # ä½¿ç”¨validation_utilséªŒè¯
        if self.validator:
            validation_result = await self.validator.validate_data(
                {"query": query}, "query_data"
            )
            return {
                "valid": validation_result.is_valid,
                "validation_details": validation_result
            }

        return {"valid": True}


# ============= å·¥å‚å‡½æ•° =============

def create_smart_query_parser(claude_client=None, gpt_client=None) -> SmartQueryParser:
    """
    åˆ›å»ºæ™ºèƒ½æŸ¥è¯¢è§£æå™¨å®ä¾‹

    Args:
        claude_client: Claudeå®¢æˆ·ç«¯å®ä¾‹
        gpt_client: GPTå®¢æˆ·ç«¯å®ä¾‹

    Returns:
        SmartQueryParser: æ™ºèƒ½æŸ¥è¯¢è§£æå™¨å®ä¾‹
    """
    return SmartQueryParser(claude_client, gpt_client)


# ============= ä½¿ç”¨ç¤ºä¾‹ =============

async def main():
    """ä½¿ç”¨ç¤ºä¾‹"""

    # åˆ›å»ºæŸ¥è¯¢è§£æå™¨
    parser = create_smart_query_parser()

    print("=== æ™ºèƒ½æŸ¥è¯¢è§£æå™¨æµ‹è¯• ===")

    # æµ‹è¯•ä¸åŒå¤æ‚åº¦çš„æŸ¥è¯¢
    test_queries = [
        "ä»Šå¤©ç³»ç»Ÿæ€»ä½™é¢æ˜¯å¤šå°‘ï¼Ÿ",  # Simple
        "è¿‡å»30å¤©æ¯æ—¥å…¥é‡‘è¶‹åŠ¿å¦‚ä½•ï¼Ÿ",  # Medium
        "æ ¹æ®è¿‡å»3ä¸ªæœˆå¢é•¿é¢„æµ‹7æœˆä»½å¦‚æœ30%å¤æŠ•çš„èµ„é‡‘æƒ…å†µ",  # Expert
        "å‡è®¾æ— å…¥é‡‘æƒ…å†µä¸‹å…¬å¸è¿˜èƒ½è¿è¡Œå¤šä¹…ï¼Ÿ"  # Complex
    ]

    for i, query in enumerate(test_queries, 1):
        print(f"\n--- æµ‹è¯•æŸ¥è¯¢ {i} ---")
        print(f"æŸ¥è¯¢: {query}")

        # éªŒè¯æŸ¥è¯¢
        validation = await parser.validate_query(query)
        print(f"éªŒè¯: {'é€šè¿‡' if validation['valid'] else 'å¤±è´¥'}")

        if validation['valid']:
            # è§£ææŸ¥è¯¢
            result = await parser.parse_complex_query(query)
            print(f"å¤æ‚åº¦: {result.complexity.value}")
            print(f"ç±»å‹: {result.query_type.value}")
            print(f"åœºæ™¯: {result.business_scenario.value}")
            print(f"ç½®ä¿¡åº¦: {result.confidence_score:.2f}")
            print(f"æ‰§è¡Œæ­¥éª¤: {len(result.execution_plan)}æ­¥")
            print(f"é¢„ä¼°æ—¶é—´: {result.estimated_total_time:.1f}ç§’")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = parser.get_processing_stats()
    print(f"\n=== å¤„ç†ç»Ÿè®¡ ===")
    print(f"æ€»æŸ¥è¯¢æ•°: {stats['total_queries']}")
    print(f"å¹³å‡ç½®ä¿¡åº¦: {stats['average_confidence']:.2f}")


if __name__ == "__main__":
    asyncio.run(main())