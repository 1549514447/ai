# core/analyzers/insight_generator.py
"""
ğŸ’¡ AIé©±åŠ¨çš„ä¸šåŠ¡æ´å¯Ÿç”Ÿæˆå™¨
åŸºäºçœŸå®APIæ•°æ®ç”Ÿæˆå¯æ‰§è¡Œçš„ä¸šåŠ¡æ´å¯Ÿå’Œå»ºè®®

æ ¸å¿ƒç‰¹ç‚¹:
- åŸºäº8ä¸ªçœŸå®APIçš„æ•°æ®æ´å¯Ÿç”Ÿæˆ
- Claudeä¸“ç²¾ä¸šåŠ¡ç†è§£å’Œç­–ç•¥å»ºè®®
- GPT-4oä¸“ç²¾æ•°æ®è§£è¯»å’Œè®¡ç®—éªŒè¯
- é¢å‘å®é™…ä¸šåŠ¡åœºæ™¯çš„å¯æ‰§è¡Œå»ºè®®
- æ™ºèƒ½é£é™©é¢„è­¦å’Œæœºä¼šè¯†åˆ«
"""

import logging
from typing import Dict, Any, List, Optional, Tuple, Union
from datetime import datetime, timedelta
import asyncio
from dataclasses import dataclass
from enum import Enum
import json

from core.analyzers.query_parser import QueryAnalysisResult
from core.models.claude_client import CustomJSONEncoder

logger = logging.getLogger(__name__)


class InsightType(Enum):
    """æ´å¯Ÿç±»å‹"""
    FINANCIAL_HEALTH = "financial_health"  # è´¢åŠ¡å¥åº·çŠ¶å†µ
    CASH_FLOW_ANALYSIS = "cash_flow_analysis"  # èµ„é‡‘æµåŠ¨åˆ†æ
    USER_GROWTH_INSIGHT = "user_growth_insight"  # ç”¨æˆ·å¢é•¿æ´å¯Ÿ
    PRODUCT_PERFORMANCE = "product_performance"  # äº§å“è¡¨ç°æ´å¯Ÿ
    RISK_WARNING = "risk_warning"  # é£é™©é¢„è­¦
    OPPORTUNITY_IDENTIFICATION = "opportunity"  # æœºä¼šè¯†åˆ«
    OPERATIONAL_EFFICIENCY = "operational_efficiency"  # è¿è¥æ•ˆç‡
    EXPIRY_MANAGEMENT = "expiry_management"  # åˆ°æœŸç®¡ç†


class InsightPriority(Enum):
    """æ´å¯Ÿä¼˜å…ˆçº§"""
    CRITICAL = "critical"  # ç´§æ€¥ï¼Œéœ€è¦ç«‹å³è¡ŒåŠ¨
    HIGH = "high"  # é‡è¦ï¼Œéœ€è¦å°½å¿«å¤„ç†
    MEDIUM = "medium"  # ä¸­ç­‰ï¼Œå»ºè®®å…³æ³¨
    LOW = "low"  # ä¸€èˆ¬ï¼Œå¯ä»¥ç›‘æ§


class ActionType(Enum):
    """è¡ŒåŠ¨ç±»å‹"""
    IMMEDIATE_ACTION = "immediate"  # ç«‹å³è¡ŒåŠ¨
    SHORT_TERM_PLAN = "short_term"  # çŸ­æœŸè®¡åˆ’ (1-7å¤©)
    MEDIUM_TERM_PLAN = "medium_term"  # ä¸­æœŸè®¡åˆ’ (1-4å‘¨)
    LONG_TERM_STRATEGY = "long_term"  # é•¿æœŸæˆ˜ç•¥ (1ä¸ªæœˆ+)
    MONITORING = "monitoring"  # æŒç»­ç›‘æ§


@dataclass
class BusinessInsight:
    """ä¸šåŠ¡æ´å¯Ÿæ•°æ®ç±»"""
    insight_id: str  # æ´å¯ŸID
    insight_type: InsightType  # æ´å¯Ÿç±»å‹
    priority: InsightPriority  # ä¼˜å…ˆçº§

    # æ ¸å¿ƒå†…å®¹
    title: str  # æ´å¯Ÿæ ‡é¢˜
    summary: str  # æ´å¯Ÿæ‘˜è¦
    detailed_analysis: str  # è¯¦ç»†åˆ†æ

    # æ”¯æ’‘æ•°æ®
    key_metrics: Dict[str, Any]  # å…³é”®æŒ‡æ ‡
    supporting_data: Dict[str, Any]  # æ”¯æ’‘æ•°æ®
    confidence_score: float  # ç½®ä¿¡åº¦

    # è¡ŒåŠ¨å»ºè®®
    recommended_actions: List[Dict[str, Any]]  # æ¨èè¡ŒåŠ¨
    expected_impact: str  # é¢„æœŸå½±å“
    implementation_difficulty: str  # å®æ–½éš¾åº¦

    # å…ƒæ•°æ®
    data_sources: List[str]  # æ•°æ®æ¥æºAPI
    analysis_timestamp: str  # åˆ†ææ—¶é—´
    applicable_timeframe: str  # é€‚ç”¨æ—¶é—´æ¡†æ¶


@dataclass
class RecommendedAction:
    """æ¨èè¡ŒåŠ¨æ•°æ®ç±»"""
    action_id: str  # è¡ŒåŠ¨ID
    action_type: ActionType  # è¡ŒåŠ¨ç±»å‹
    title: str  # è¡ŒåŠ¨æ ‡é¢˜
    description: str  # è¡ŒåŠ¨æè¿°
    priority: InsightPriority  # ä¼˜å…ˆçº§

    # æ‰§è¡Œä¿¡æ¯
    timeline: str  # æ‰§è¡Œæ—¶é—´çº¿
    responsible_party: str  # è´Ÿè´£æ–¹
    required_resources: List[str]  # éœ€è¦çš„èµ„æº
    success_metrics: List[str]  # æˆåŠŸæŒ‡æ ‡

    # å½±å“è¯„ä¼°
    expected_outcome: str  # é¢„æœŸç»“æœ
    potential_risks: List[str]  # æ½œåœ¨é£é™©
    estimated_roi: Optional[float]  # é¢„ä¼°ROI


class InsightGenerator:
    """
    ğŸ’¡ AIé©±åŠ¨çš„ä¸šåŠ¡æ´å¯Ÿç”Ÿæˆå™¨

    ä¸“æ³¨äºå°†çœŸå®APIæ•°æ®è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„ä¸šåŠ¡æ´å¯Ÿ
    """

    def __init__(self, claude_client=None, gpt_client=None):
        """
        åˆå§‹åŒ–æ´å¯Ÿç”Ÿæˆå™¨

        Args:
            claude_client: Claudeå®¢æˆ·ç«¯ï¼Œè´Ÿè´£ä¸šåŠ¡æ´å¯Ÿç”Ÿæˆ
            gpt_client: GPTå®¢æˆ·ç«¯ï¼Œè´Ÿè´£æ•°æ®éªŒè¯å’Œè®¡ç®—
        """
        self.claude_client = claude_client
        self.gpt_client = gpt_client

        # ä¸šåŠ¡è§„åˆ™é…ç½® (åŸºäºå®é™…ä¸šåŠ¡åœºæ™¯)
        self.business_rules = self._load_business_rules()

        # æ´å¯Ÿç”Ÿæˆç»Ÿè®¡
        self.insight_stats = {
            'total_insights_generated': 0,
            'insights_by_type': {},
            'avg_confidence_score': 0.0,
            'actionable_insights': 0,
            'critical_insights': 0
        }

        logger.info("InsightGenerator initialized for real business scenarios")

    def _load_business_rules(self) -> Dict[str, Any]:
        """åŠ è½½åŸºäºå®é™…ä¸šåŠ¡çš„è§„åˆ™é…ç½®"""
        return {
            # åŸºäº /api/sta/system çš„è´¢åŠ¡å¥åº·è§„åˆ™
            'financial_health': {
                'healthy_growth_rate': 0.05,  # æœˆå¢é•¿ç‡5%ä»¥ä¸Šä¸ºå¥åº·
                'risk_outflow_ratio': 0.8,  # å‡ºé‡‘/å…¥é‡‘æ¯”ä¾‹è¶…è¿‡80%ä¸ºé£é™©
                'liquidity_warning_days': 30,  # èµ„é‡‘æ”¯æ’‘å¤©æ•°ä½äº30å¤©é¢„è­¦
                'balance_fluctuation_threshold': 0.15  # ä½™é¢æ³¢åŠ¨è¶…è¿‡15%éœ€å…³æ³¨
            },

            # åŸºäº /api/sta/day çš„ç”¨æˆ·å¢é•¿è§„åˆ™
            'user_growth': {
                'healthy_daily_growth': 50,  # æ—¥æ–°å¢ç”¨æˆ·50+ä¸ºå¥åº·
                'retention_warning_threshold': 0.6,  # æŒä»“äººæ•°/æ³¨å†Œäººæ•°ä½äº60%é¢„è­¦
                'activity_decline_threshold': 0.1,  # æ´»è·ƒåº¦ä¸‹é™10%éœ€å…³æ³¨
                'conversion_target': 0.8  # æ³¨å†Œè½¬åŒ–ç‡ç›®æ ‡80%
            },

            # åŸºäº /api/sta/product çš„äº§å“è¡¨ç°è§„åˆ™
            'product_performance': {
                'low_utilization_threshold': 0.3,  # æŒæœ‰ç‡ä½äº30%ä¸ºä½åˆ©ç”¨
                'popular_product_threshold': 100,  # è´­ä¹°æ¬¡æ•°100+ä¸ºçƒ­é—¨
                'expiry_concentration_risk': 0.4,  # å•æ—¥åˆ°æœŸè¶…è¿‡40%ä¸ºé›†ä¸­é£é™©
                'new_product_ramp_days': 7  # æ–°äº§å“çˆ¬å¡æœŸ7å¤©
            },

            # åŸºäºåˆ°æœŸç›¸å…³APIçš„ç°é‡‘æµè§„åˆ™
            'cash_flow_management': {
                'daily_expiry_limit': 5000000,  # æ—¥åˆ°æœŸé‡‘é¢500ä¸‡ä»¥ä¸Šéœ€é‡ç‚¹å…³æ³¨
                'expiry_preparation_days': 3,  # åˆ°æœŸå‰3å¤©å¼€å§‹å‡†å¤‡èµ„é‡‘
                'reinvestment_rate_target': 0.6,  # ç›®æ ‡å¤æŠ•ç‡60%
                'cash_reserve_ratio': 0.15  # ç°é‡‘å‚¨å¤‡æ¯”ä¾‹15%
            }
        }

    # ============= æ ¸å¿ƒæ´å¯Ÿç”Ÿæˆæ–¹æ³• =============

    async def generate_comprehensive_insights(self, analysis_results: List[Any],
                                              user_context: Optional[Dict[str, Any]] = None,
                                              focus_areas: List[str] = None) -> Tuple[
        List[BusinessInsight], Dict[str, Any]]:
        """
        ğŸ¯ ç”Ÿæˆç»¼åˆä¸šåŠ¡æ´å¯Ÿ

        Args:
            analysis_results: æ¥è‡ªfinancial_data_analyzerçš„åˆ†æç»“æœ
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯
            focus_areas: é‡ç‚¹å…³æ³¨é¢†åŸŸ

        Returns:
            Tuple[æ´å¯Ÿåˆ—è¡¨, å…ƒæ•°æ®]
        """
        try:
            logger.info("ğŸ’¡ å¼€å§‹ç”Ÿæˆç»¼åˆä¸šåŠ¡æ´å¯Ÿ")

            generation_start_time = datetime.now()

            # Step 1: æ•°æ®é¢„å¤„ç†å’ŒéªŒè¯
            processed_data = await self._preprocess_analysis_results(analysis_results)

            # Step 2: è¯†åˆ«å…³é”®ä¸šåŠ¡æ¨¡å¼
            business_patterns = await self._identify_business_patterns(processed_data)

            # Step 3: ç”Ÿæˆåˆ†ç±»æ´å¯Ÿ
            insights = []

            # è´¢åŠ¡å¥åº·æ´å¯Ÿ
            financial_insights = await self._generate_financial_health_insights(processed_data)
            insights.extend(financial_insights)

            # ç”¨æˆ·å¢é•¿æ´å¯Ÿ
            user_insights = await self._generate_user_growth_insights(processed_data)
            insights.extend(user_insights)

            # äº§å“è¡¨ç°æ´å¯Ÿ
            product_insights = await self._generate_product_performance_insights(processed_data)
            insights.extend(product_insights)

            # åˆ°æœŸç®¡ç†æ´å¯Ÿ
            expiry_insights = await self._generate_expiry_management_insights(processed_data)
            insights.extend(expiry_insights)

            # é£é™©é¢„è­¦æ´å¯Ÿ
            risk_insights = await self._generate_risk_warning_insights(processed_data)
            insights.extend(risk_insights)

            # Step 4: ä¼˜å…ˆçº§æ’åºå’Œå»é‡
            prioritized_insights = self._prioritize_and_deduplicate_insights(insights)

            # Step 5: ç”Ÿæˆå¯æ‰§è¡Œè¡ŒåŠ¨å»ºè®®
            for insight in prioritized_insights:
                insight.recommended_actions = await self._generate_actionable_recommendations(insight, processed_data)

            # Step 6: è´¨é‡éªŒè¯å’Œç½®ä¿¡åº¦è°ƒæ•´
            validated_insights = await self._validate_insights_quality(prioritized_insights)

            # ç”Ÿæˆå…ƒæ•°æ®
            generation_time = (datetime.now() - generation_start_time).total_seconds()
            metadata = {
                'generation_time': generation_time,
                'total_insights': len(validated_insights),
                'insights_by_priority': self._count_insights_by_priority(validated_insights),
                'data_sources_used': self._extract_data_sources(processed_data),
                'confidence_distribution': self._calculate_confidence_distribution(validated_insights),
                'actionable_insights_ratio': sum(1 for i in validated_insights if i.recommended_actions) / len(
                    validated_insights) if validated_insights else 0
            }

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_insight_stats(validated_insights)

            logger.info(f"âœ… ç”Ÿæˆ{len(validated_insights)}æ¡ä¸šåŠ¡æ´å¯Ÿï¼Œè€—æ—¶{generation_time:.2f}ç§’")

            return validated_insights, metadata

        except Exception as e:
            logger.error(f"âŒ ä¸šåŠ¡æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}")
            return [], {'error': str(e)}

    # ============= è´¢åŠ¡å¥åº·æ´å¯Ÿç”Ÿæˆ =============

    async def _generate_financial_health_insights(self, processed_data: Dict[str, Any]) -> List[BusinessInsight]:
        """ç”Ÿæˆè´¢åŠ¡å¥åº·æ´å¯Ÿ"""
        insights = []

        try:
            # ä»ç³»ç»Ÿæ•°æ®æå–è´¢åŠ¡æŒ‡æ ‡
            system_data = processed_data.get('system_data', {})
            daily_data = processed_data.get('daily_trends', {})

            total_balance = float(system_data.get('æ€»ä½™é¢', 0))
            total_inflow = float(system_data.get('æ€»å…¥é‡‘', 0))
            total_outflow = float(system_data.get('æ€»å‡ºé‡‘', 0))

            # è®¡ç®—å…³é”®è´¢åŠ¡æ¯”ç‡
            outflow_ratio = total_outflow / total_inflow if total_inflow > 0 else 0
            net_flow = total_inflow - total_outflow

            # åŸºäºä¸šåŠ¡è§„åˆ™ç”Ÿæˆæ´å¯Ÿ
            rules = self.business_rules['financial_health']

            # æ´å¯Ÿ1: èµ„é‡‘æµåŠ¨å¥åº·åº¦
            if outflow_ratio > rules['risk_outflow_ratio']:
                insight = await self._create_financial_risk_insight(outflow_ratio, net_flow, system_data)
                insights.append(insight)
            elif outflow_ratio < 0.5:
                insight = await self._create_financial_opportunity_insight(outflow_ratio, net_flow, system_data)
                insights.append(insight)

            # æ´å¯Ÿ2: ä½™é¢å¢é•¿è¶‹åŠ¿
            if daily_data.get('balance_growth_rate'):
                growth_rate = daily_data['balance_growth_rate']
                if growth_rate < rules['healthy_growth_rate']:
                    insight = await self._create_growth_concern_insight(growth_rate, daily_data)
                    insights.append(insight)

            # æ´å¯Ÿ3: æµåŠ¨æ€§é£é™©è¯„ä¼°
            daily_outflow_avg = daily_data.get('avg_daily_outflow', 0)
            if daily_outflow_avg > 0:
                sustainability_days = total_balance / daily_outflow_avg
                if sustainability_days < rules['liquidity_warning_days']:
                    insight = await self._create_liquidity_warning_insight(sustainability_days, total_balance,
                                                                           daily_outflow_avg)
                    insights.append(insight)

        except Exception as e:
            logger.error(f"è´¢åŠ¡å¥åº·æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}")

        return insights

    async def _create_financial_risk_insight(self, outflow_ratio: float, net_flow: float,
                                             system_data: Dict) -> BusinessInsight:
        """åˆ›å»ºè´¢åŠ¡é£é™©æ´å¯Ÿ"""

        # ä½¿ç”¨Claudeç”Ÿæˆä¸“ä¸šåˆ†æ
        if self.claude_client:
            analysis_prompt = f"""
            ä½œä¸ºé‡‘èé£é™©åˆ†æä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹è´¢åŠ¡çŠ¶å†µï¼š

            å…³é”®æŒ‡æ ‡ï¼š
            - å‡ºé‡‘/å…¥é‡‘æ¯”ä¾‹: {outflow_ratio:.2%}
            - å‡€ç°é‡‘æµ: Â¥{net_flow:,.0f}
            - æ€»ä½™é¢: Â¥{system_data.get('æ€»ä½™é¢', 0):,.0f}

            å‡ºé‡‘æ¯”ä¾‹è¶…è¿‡80%ï¼Œå­˜åœ¨ç°é‡‘æµé£é™©ã€‚è¯·æä¾›ï¼š
            1. é£é™©ç¨‹åº¦è¯„ä¼°
            2. å¯èƒ½çš„åŸå› åˆ†æ
            3. å…·ä½“çš„é£é™©æ§åˆ¶å»ºè®®

            è¦æ±‚ç®€æ´ä¸“ä¸šï¼Œé‡ç‚¹çªå‡ºå¯æ‰§è¡Œçš„å»ºè®®ã€‚
            """

            claude_result = await self.claude_client.analyze_complex_query(analysis_prompt, system_data)

            if claude_result.get('success'):
                analysis_text = claude_result.get('analysis', {}).get('detailed_analysis', '')
                recommendations = claude_result.get('analysis', {}).get('recommendations', [])
            else:
                analysis_text = f"å‡ºé‡‘æ¯”ä¾‹{outflow_ratio:.1%}è¶…è¿‡æ­£å¸¸æ°´å¹³ï¼Œéœ€è¦åŠ å¼ºç°é‡‘æµç®¡ç†ã€‚"
                recommendations = ["æ§åˆ¶å¤§é¢å‡ºé‡‘å®¡æ‰¹", "æé«˜å¤æŠ•æ¿€åŠ±", "åŠ å¼ºæµåŠ¨æ€§ç›‘æ§"]
        else:
            analysis_text = f"å½“å‰å‡ºé‡‘æ¯”ä¾‹ä¸º{outflow_ratio:.1%}ï¼Œè¶…è¿‡å¥åº·é˜ˆå€¼80%ï¼Œå­˜åœ¨ç°é‡‘æµå‹åŠ›ã€‚"
            recommendations = ["åŠ å¼ºå‡ºé‡‘å®¡æ ¸", "ä¼˜åŒ–å¤æŠ•ç­–ç•¥"]

        return BusinessInsight(
            insight_id=f"financial_risk_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            insight_type=InsightType.RISK_WARNING,
            priority=InsightPriority.HIGH if outflow_ratio > 0.9 else InsightPriority.MEDIUM,

            title="ç°é‡‘æµé£é™©é¢„è­¦",
            summary=f"å‡ºé‡‘æ¯”ä¾‹{outflow_ratio:.1%}åé«˜ï¼Œå­˜åœ¨æµåŠ¨æ€§é£é™©",
            detailed_analysis=analysis_text,

            key_metrics={
                'outflow_ratio': outflow_ratio,
                'net_cash_flow': net_flow,
                'total_balance': system_data.get('æ€»ä½™é¢', 0),
                'risk_level': 'high' if outflow_ratio > 0.9 else 'medium'
            },
            supporting_data=system_data,
            confidence_score=0.85,

            recommended_actions=[],  # å°†åœ¨åç»­æ­¥éª¤ä¸­ç”Ÿæˆ
            expected_impact="é™ä½ç°é‡‘æµé£é™©ï¼Œæå‡èµ„é‡‘å®‰å…¨æ€§",
            implementation_difficulty="ä¸­ç­‰",

            data_sources=['/api/sta/system'],
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="ç«‹å³æ‰§è¡Œï¼ŒæŒç»­ç›‘æ§"
        )

    # ============= ç”¨æˆ·å¢é•¿æ´å¯Ÿç”Ÿæˆ =============

    async def _generate_user_growth_insights(self, processed_data: Dict[str, Any]) -> List[BusinessInsight]:
        """ç”Ÿæˆç”¨æˆ·å¢é•¿æ´å¯Ÿ"""
        insights = []

        try:
            daily_data = processed_data.get('daily_trends', {})
            user_data = processed_data.get('user_statistics', {})

            # è·å–ç”¨æˆ·å¢é•¿æ•°æ®
            avg_daily_registrations = daily_data.get('avg_daily_registrations', 0)
            avg_active_users = daily_data.get('avg_active_users', 0)
            user_growth_rate = daily_data.get('user_growth_rate', 0)

            rules = self.business_rules['user_growth']

            # æ´å¯Ÿ1: ç”¨æˆ·å¢é•¿é€Ÿåº¦åˆ†æ
            if avg_daily_registrations < rules['healthy_daily_growth']:
                insight = await self._create_user_growth_concern_insight(avg_daily_registrations, user_growth_rate,
                                                                         daily_data)
                insights.append(insight)
            elif user_growth_rate > 0.2:  # 20%ä»¥ä¸Šä¸ºé«˜å¢é•¿
                insight = await self._create_user_growth_opportunity_insight(avg_daily_registrations, user_growth_rate,
                                                                             daily_data)
                insights.append(insight)

            # æ´å¯Ÿ2: ç”¨æˆ·æ´»è·ƒåº¦åˆ†æ
            if avg_active_users > 0 and avg_daily_registrations > 0:
                activation_rate = avg_active_users / avg_daily_registrations
                if activation_rate < rules['retention_warning_threshold']:
                    insight = await self._create_user_activation_insight(activation_rate, user_data)
                    insights.append(insight)

        except Exception as e:
            logger.error(f"ç”¨æˆ·å¢é•¿æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}")

        return insights

    async def _create_user_growth_concern_insight(self, avg_registrations: float, growth_rate: float,
                                                  daily_data: Dict) -> BusinessInsight:
        """åˆ›å»ºç”¨æˆ·å¢é•¿å…³æ³¨æ´å¯Ÿ"""

        analysis_text = f"æ—¥å‡æ–°å¢ç”¨æˆ·{avg_registrations:.0f}äººï¼Œä½äºå¥åº·æ°´å¹³50äººï¼Œå¢é•¿ç‡{growth_rate:.1%}éœ€è¦æå‡ã€‚"

        if self.claude_client:
            analysis_prompt = f"""
            åˆ†æç”¨æˆ·å¢é•¿ç°çŠ¶å¹¶æä¾›æ”¹è¿›å»ºè®®ï¼š

            å½“å‰æ•°æ®ï¼š
            - æ—¥å‡æ–°å¢ç”¨æˆ·: {avg_registrations:.0f}äºº
            - ç”¨æˆ·å¢é•¿ç‡: {growth_rate:.1%}
            - ç›®æ ‡å¢é•¿: 50äºº/å¤©

            è¯·æä¾›ï¼š
            1. å¢é•¿ç¼“æ…¢çš„å¯èƒ½åŸå› 
            2. å…·ä½“çš„è·å®¢ç­–ç•¥å»ºè®®
            3. çŸ­æœŸå¯æ‰§è¡Œçš„è¡ŒåŠ¨æ–¹æ¡ˆ
            """

            claude_result = await self.claude_client.analyze_complex_query(analysis_prompt, daily_data)
            if claude_result.get('success'):
                analysis_text = claude_result.get('analysis', {}).get('detailed_analysis', analysis_text)

        return BusinessInsight(
            insight_id=f"user_growth_concern_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            insight_type=InsightType.USER_GROWTH_INSIGHT,
            priority=InsightPriority.MEDIUM,

            title="ç”¨æˆ·å¢é•¿é€Ÿåº¦å¾…ä¼˜åŒ–",
            summary=f"æ—¥å‡æ–°å¢{avg_registrations:.0f}äººï¼Œå»ºè®®åŠ å¼ºè·å®¢æªæ–½",
            detailed_analysis=analysis_text,

            key_metrics={
                'avg_daily_registrations': avg_registrations,
                'growth_rate': growth_rate,
                'target_registrations': 50,
                'gap': 50 - avg_registrations
            },
            supporting_data=daily_data,
            confidence_score=0.8,

            recommended_actions=[],
            expected_impact="æå‡ç”¨æˆ·è·å–æ•ˆç‡ï¼Œæ‰©å¤§ç”¨æˆ·åŸºæ•°",
            implementation_difficulty="ä¸­ç­‰",

            data_sources=['/api/sta/day', '/api/sta/user_daily'],
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="1-2å‘¨å†…åˆ¶å®šå¹¶æ‰§è¡Œè·å®¢è®¡åˆ’"
        )

    # ============= äº§å“è¡¨ç°æ´å¯Ÿç”Ÿæˆ =============

    async def _generate_product_performance_insights(self, processed_data: Dict[str, Any]) -> List[BusinessInsight]:
        """ç”Ÿæˆäº§å“è¡¨ç°æ´å¯Ÿ"""
        insights = []

        try:
            product_data = processed_data.get('product_data', {})

            if not product_data:
                return insights

            product_list = product_data.get('äº§å“åˆ—è¡¨', [])

            # åˆ†æäº§å“åˆ©ç”¨ç‡
            low_utilization_products = []
            high_performance_products = []

            for product in product_list:
                purchase_count = product.get('æ€»è´­ä¹°æ¬¡æ•°', 0)
                current_holdings = product.get('å½“å‰æŒæœ‰æ•°', 0)

                # è®¡ç®—åˆ©ç”¨ç‡æŒ‡æ ‡
                if purchase_count > 0:
                    utilization_rate = current_holdings / purchase_count

                    if utilization_rate < self.business_rules['product_performance']['low_utilization_threshold']:
                        low_utilization_products.append(product)
                    elif purchase_count > self.business_rules['product_performance']['popular_product_threshold']:
                        high_performance_products.append(product)

            # ç”Ÿæˆä½åˆ©ç”¨ç‡äº§å“æ´å¯Ÿ
            if low_utilization_products:
                insight = await self._create_product_utilization_insight(low_utilization_products)
                insights.append(insight)

            # ç”Ÿæˆé«˜è¡¨ç°äº§å“æ´å¯Ÿ
            if high_performance_products:
                insight = await self._create_product_opportunity_insight(high_performance_products)
                insights.append(insight)

        except Exception as e:
            logger.error(f"äº§å“è¡¨ç°æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}")

        return insights

        # åœ¨ InsightGenerator ç±»ä¸­
    async def _create_product_opportunity_insight(self, high_performance_products: List[
        Dict[str, Any]]) -> BusinessInsight:
        """
        (ç§æœ‰) åˆ›å»ºé«˜è¡¨ç°äº§å“çš„æœºä¼šæ´å¯Ÿã€‚
        high_performance_products: è¡¨ç°ä¼˜å¼‚çš„äº§å“åˆ—è¡¨ï¼Œæ¯ä¸ªäº§å“æ˜¯åŒ…å«åç§°ã€è´­ä¹°æ¬¡æ•°ç­‰çš„å­—å…¸ã€‚
        """
        insight_id = f"prod_opportunity_{datetime.now().strftime('%Y%m%d%H%M%S%f')}"
        title = "æ˜æ˜Ÿäº§å“è¡¨ç°å¼ºåŠ²ï¼Œå­˜åœ¨å¢é•¿æ–°æœºä¼š"

        num_high_perf_products = len(high_performance_products)
        product_names_examples = [p.get('äº§å“åç§°', 'æœªçŸ¥äº§å“') for p in high_performance_products[:2]]  # åˆ—ä¸¾1-2ä¸ªä¾‹å­

        summary = f"å‘ç° {num_high_perf_products} æ¬¾äº§å“è¡¨ç°çªå‡ºï¼ˆä¾‹å¦‚ï¼š{', '.join(product_names_examples)}ï¼‰ï¼Œè´­ä¹°æ¬¡æ•°å¤šï¼Œç”¨æˆ·åé¦ˆç§¯æã€‚è¿™äº›æ˜æ˜Ÿäº§å“æ˜¯é‡è¦çš„å¢é•¿å¼•æ“ï¼Œå¹¶å¯èƒ½å¸¦æ¥æ–°çš„è¥é”€å’Œäº¤å‰é”€å”®æœºä¼šã€‚"
        detailed_analysis = f"{summary} å»ºè®®æ·±å…¥åˆ†æè¿™äº›äº§å“çš„æˆåŠŸå› ç´ ï¼Œå¹¶è€ƒè™‘å¦‚ä½•å¤åˆ¶æˆåŠŸç»éªŒåˆ°å…¶ä»–äº§å“çº¿ï¼Œæˆ–å›´ç»•è¿™äº›äº§å“è®¾è®¡æ–°çš„å¢å€¼æœåŠ¡ã€‚"
        key_metrics = {
            'é«˜è¡¨ç°äº§å“æ•°é‡': num_high_perf_products,
            'é«˜è¡¨ç°äº§å“ç¤ºä¾‹': product_names_examples,
            'å¹³å‡è´­ä¹°æ¬¡æ•°ï¼ˆé«˜è¡¨ç°äº§å“ï¼‰': sum(p.get('æ€»è´­ä¹°æ¬¡æ•°', 0) for p in
                                            high_performance_products) / num_high_perf_products if num_high_perf_products else 0
        }
        confidence = 0.85
        priority = InsightPriority.HIGH  # æœºä¼šé€šå¸¸æ˜¯é«˜ä¼˜å…ˆçº§

        if self.claude_client and high_performance_products:
            prompt = f"""
            é‡‘èäº§å“åˆ†ææ˜¾ç¤ºï¼Œä»¥ä¸‹äº§å“è¡¨ç°ä¼˜å¼‚ï¼Œç”¨æˆ·è´­ä¹°è¸Šè·ƒï¼š
            {json.dumps(high_performance_products[:3], ensure_ascii=False, indent=2, cls=CustomJSONEncoder)} # æœ€å¤š3ä¸ªäº§å“ç¤ºä¾‹ç»™AI

            è¯·ç”¨ä¸­æ–‡åˆ†æï¼š
            1. è¿™äº›â€œæ˜æ˜Ÿäº§å“â€çš„æˆåŠŸå¯èƒ½å½’å› äºå“ªäº›å› ç´ ï¼Ÿï¼ˆä¾‹å¦‚ï¼šæ”¶ç›Šç‡ã€æœŸé™ã€å¸‚åœºå®šä½ã€æ¨å¹¿ç­–ç•¥ç­‰ï¼‰
            2. å¦‚ä½•è¿›ä¸€æ­¥åˆ©ç”¨è¿™äº›äº§å“çš„æˆåŠŸæ¥å¸¦åŠ¨æ•´ä½“ä¸šåŠ¡å¢é•¿ï¼Ÿï¼ˆä¾‹å¦‚ï¼šåŠ å¤§æ¨å¹¿åŠ›åº¦ã€è®¾è®¡å…³è”äº§å“ã€é’ˆå¯¹é«˜ä»·å€¼ç”¨æˆ·è¿›è¡Œç²¾å‡†è¥é”€ã€æ‰“åŒ…é”€å”®ç­‰ï¼‰
            3. åŸºäºè¿™äº›äº§å“çš„ç‰¹æ€§ï¼Œæ˜¯å¦å­˜åœ¨æ–°çš„å¸‚åœºç»†åˆ†æˆ–ç”¨æˆ·ç¾¤å¯ä»¥æ‹“å±•ï¼Ÿ

            è¯·æä¾›ä¸€ä¸ªåŒ…å«ä»¥ä¸‹é”®çš„JSONå¯¹è±¡ï¼š
            "detailed_analysis_text": "å¯¹æ˜æ˜Ÿäº§å“æˆåŠŸå› ç´ å’Œæ½œåœ¨æœºä¼šçš„è¯¦ç»†ä¸­æ–‡åˆ†æã€‚",
            "growth_strategies_suggested": ["å…·ä½“çš„å¢é•¿ç­–ç•¥å»ºè®®1", "å»ºè®®2"],
            "target_actions": ["å›´ç»•è¿™äº›äº§å“çš„å…·ä½“è¡ŒåŠ¨ç‚¹1", "è¡ŒåŠ¨ç‚¹2"]
            """
            try:
                ai_response = await self.claude_client.analyze_complex_query(
                    query=prompt,
                    context={"high_performance_products_sample": high_performance_products[:3]}
                )
                if ai_response and ai_response.get('success'):
                    analysis_content = ai_response.get('analysis', {})
                    if isinstance(analysis_content, str):
                        try:
                            analysis_content = json.loads(analysis_content)
                        except:
                            pass

                    if isinstance(analysis_content, dict):
                        detailed_analysis = analysis_content.get('detailed_analysis_text', detailed_analysis)
                        confidence = analysis_content.get('confidence', confidence)
                else:
                    logger.warning(
                        f"AI call for product opportunity insight failed: {ai_response.get('error') if ai_response else 'N/A'}")
            except Exception as e:
                logger.error(f"Error during AI call for product opportunity insight: {e}")

        return BusinessInsight(
            insight_id=insight_id,
            insight_type=InsightType.OPPORTUNITY_IDENTIFICATION,
            priority=priority,
            title=title,
            summary=summary,
            detailed_analysis=detailed_analysis,
            key_metrics=key_metrics,
            supporting_data={"high_performance_products": high_performance_products},
            confidence_score=confidence,
            recommended_actions=[],
            # ç”± _generate_actionable_recommendations (ç‰¹åˆ«æ˜¯ _generate_opportunity_capture_actions) å¡«å……
            expected_impact="é€šè¿‡èšç„¦å’Œæ¨å¹¿é«˜è¡¨ç°äº§å“ï¼Œå¸¦åŠ¨æ•´ä½“é”€å”®é¢å’Œç”¨æˆ·å‚ä¸åº¦çš„æå‡ã€‚",
            implementation_difficulty="ä¸­ç­‰",
            data_sources=["/api/sta/product"],  # ä¸»è¦æ•°æ®æ¥æº
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="æœªæ¥1-3ä¸ªæœˆé‡ç‚¹æ¨å¹¿"
        )

    async def _create_product_utilization_insight(self, low_utilization_products: List[Dict]) -> BusinessInsight:
        """åˆ›å»ºäº§å“åˆ©ç”¨ç‡æ´å¯Ÿ"""

        product_names = [p.get('äº§å“åç§°', 'Unknown') for p in low_utilization_products]

        analysis_text = f"å‘ç°{len(low_utilization_products)}ä¸ªäº§å“åˆ©ç”¨ç‡åä½ï¼ŒåŒ…æ‹¬ï¼š{', '.join(product_names[:3])}ç­‰ã€‚"

        if self.claude_client:
            analysis_prompt = f"""
            åˆ†æäº§å“åˆ©ç”¨ç‡åä½çš„åŸå› å¹¶æä¾›ä¼˜åŒ–å»ºè®®ï¼š

            ä½åˆ©ç”¨ç‡äº§å“æ•°é‡: {len(low_utilization_products)}
            äº§å“ç¤ºä¾‹: {product_names[:3]}

            è¯·åˆ†æï¼š
            1. å¯èƒ½çš„åŸå› ï¼ˆä»·æ ¼ã€æœŸé™ã€æ”¶ç›Šç­‰ï¼‰
            2. ä¼˜åŒ–å»ºè®®ï¼ˆè°ƒæ•´ç­–ç•¥ã€è¥é”€æ¨å¹¿ç­‰ï¼‰
            3. å…·ä½“æ‰§è¡Œæ–¹æ¡ˆ
            """

            claude_result = await self.claude_client.analyze_complex_query(analysis_prompt,
                                                                           {'products': low_utilization_products})
            if claude_result.get('success'):
                analysis_text = claude_result.get('analysis', {}).get('detailed_analysis', analysis_text)

        return BusinessInsight(
            insight_id=f"product_utilization_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            insight_type=InsightType.PRODUCT_PERFORMANCE,
            priority=InsightPriority.MEDIUM,

            title="éƒ¨åˆ†äº§å“åˆ©ç”¨ç‡å¾…æå‡",
            summary=f"{len(low_utilization_products)}ä¸ªäº§å“éœ€è¦ä¼˜åŒ–æ¨å¹¿ç­–ç•¥",
            detailed_analysis=analysis_text,

            key_metrics={
                'low_utilization_count': len(low_utilization_products),
                'affected_products': product_names,
                'avg_utilization_rate': sum(
                    p.get('å½“å‰æŒæœ‰æ•°', 0) / max(p.get('æ€»è´­ä¹°æ¬¡æ•°', 1), 1) for p in low_utilization_products) / len(
                    low_utilization_products)
            },
            supporting_data={'products': low_utilization_products},
            confidence_score=0.75,

            recommended_actions=[],
            expected_impact="æå‡äº§å“é”€å”®æ•ˆç‡ï¼Œä¼˜åŒ–äº§å“ç»„åˆ",
            implementation_difficulty="ä¸­ç­‰",

            data_sources=['/api/sta/product'],
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="2-4å‘¨å†…è°ƒæ•´äº§å“ç­–ç•¥"
        )

    # ============= åˆ°æœŸç®¡ç†æ´å¯Ÿç”Ÿæˆ =============

    async def _generate_expiry_management_insights(self, processed_data: Dict[str, Any]) -> List[BusinessInsight]:
        """ç”Ÿæˆåˆ°æœŸç®¡ç†æ´å¯Ÿ"""
        insights = []

        try:
            expiry_data = processed_data.get('expiry_analysis', {})

            if not expiry_data:
                return insights

            # åˆ†æåˆ°æœŸé›†ä¸­åº¦é£é™©
            daily_expiry_amounts = expiry_data.get('daily_expiry_amounts', {})
            total_expiry = sum(daily_expiry_amounts.values()) if daily_expiry_amounts else 0

            rules = self.business_rules['cash_flow_management']

            # æ£€æŸ¥å•æ—¥åˆ°æœŸé£é™©
            high_expiry_days = []
            for date, amount in daily_expiry_amounts.items():
                if amount > rules['daily_expiry_limit']:
                    high_expiry_days.append({'date': date, 'amount': amount})

            if high_expiry_days:
                insight = await self._create_expiry_concentration_insight(high_expiry_days, total_expiry)
                insights.append(insight)

            # åˆ†æå¤æŠ•ç‡æœºä¼š
            expiry_trends = expiry_data.get('expiry_trends', {})
            if expiry_trends:
                insight = await self._create_reinvestment_opportunity_insight(expiry_trends)
                insights.append(insight)

        except Exception as e:
            logger.error(f"åˆ°æœŸç®¡ç†æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}")

        return insights

    async def _create_expiry_concentration_insight(self, high_expiry_days: List[Dict],
                                                   total_expiry: float) -> BusinessInsight:
        """åˆ›å»ºåˆ°æœŸé›†ä¸­é£é™©æ´å¯Ÿ"""

        max_expiry_day = max(high_expiry_days, key=lambda x: x['amount'])
        concentration_ratio = max_expiry_day['amount'] / total_expiry if total_expiry > 0 else 0

        analysis_text = f"å‘ç°{len(high_expiry_days)}å¤©å­˜åœ¨å¤§é¢åˆ°æœŸï¼Œæœ€é«˜å•æ—¥{max_expiry_day['amount']:,.0f}å…ƒï¼Œé›†ä¸­åº¦{concentration_ratio:.1%}ã€‚"

        if self.claude_client:
            analysis_prompt = f"""
            åˆ†æåˆ°æœŸé›†ä¸­é£é™©å¹¶æä¾›èµ„é‡‘ç®¡ç†å»ºè®®ï¼š

            é«˜é£é™©åˆ°æœŸå¤©æ•°: {len(high_expiry_days)}å¤©
            æœ€å¤§å•æ—¥åˆ°æœŸ: Â¥{max_expiry_day['amount']:,.0f}
            åˆ°æœŸé›†ä¸­åº¦: {concentration_ratio:.1%}

            è¯·æä¾›ï¼š
            1. èµ„é‡‘å‡†å¤‡å»ºè®®
            2. é£é™©ç¼“è§£æªæ–½
            3. å¤æŠ•æ¨å¹¿ç­–ç•¥
            """

            claude_result = await self.claude_client.analyze_complex_query(analysis_prompt,
                                                                           {'expiry_days': high_expiry_days})
            if claude_result.get('success'):
                analysis_text = claude_result.get('analysis', {}).get('detailed_analysis', analysis_text)

        return BusinessInsight(
            insight_id=f"expiry_concentration_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            insight_type=InsightType.EXPIRY_MANAGEMENT,
            priority=InsightPriority.HIGH,

            title="åˆ°æœŸé›†ä¸­åº¦é£é™©é¢„è­¦",
            summary=f"{len(high_expiry_days)}å¤©å­˜åœ¨å¤§é¢åˆ°æœŸï¼Œéœ€è¦æå‰å‡†å¤‡èµ„é‡‘",
            detailed_analysis=analysis_text,

            key_metrics={
                'high_expiry_days_count': len(high_expiry_days),
                'max_daily_expiry': max_expiry_day['amount'],
                'concentration_ratio': concentration_ratio,
                'total_expiry_amount': total_expiry
            },
            supporting_data={'high_expiry_days': high_expiry_days},
            confidence_score=0.9,

            recommended_actions=[],
            expected_impact="é™ä½æµåŠ¨æ€§é£é™©ï¼Œç¡®ä¿åˆ°æœŸèµ„é‡‘å……è¶³",
            implementation_difficulty="ä¸­ç­‰",

            data_sources=['/api/sta/product_end', '/api/sta/product_end_interval'],
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="æå‰3-5å¤©å‡†å¤‡èµ„é‡‘ï¼Œé•¿æœŸä¼˜åŒ–åˆ°æœŸåˆ†å¸ƒ"
        )

    async def _create_reinvestment_opportunity_insight(self, expiry_trends: Dict[str, Any]) -> BusinessInsight:
        """åˆ›å»ºå¤æŠ•æœºä¼šæ´å¯Ÿ"""

        # åˆ†æå¤æŠ•æ½œåŠ›
        estimated_reinvestment_rate = expiry_trends.get('estimated_reinvestment_rate', 0.5)
        potential_reinvestment = expiry_trends.get('potential_reinvestment_amount', 0)

        analysis_text = f"åŸºäºåˆ°æœŸè¶‹åŠ¿åˆ†æï¼Œé¢„ä¼°å¤æŠ•ç‡{estimated_reinvestment_rate:.1%}ï¼Œæœ‰æœºä¼šæå‡å¤æŠ•è½¬åŒ–ã€‚"

        if self.claude_client:
            analysis_prompt = f"""
            åˆ†æå¤æŠ•æœºä¼šå¹¶æä¾›æå‡ç­–ç•¥ï¼š

            å½“å‰é¢„ä¼°å¤æŠ•ç‡: {estimated_reinvestment_rate:.1%}
            æ½œåœ¨å¤æŠ•é‡‘é¢: Â¥{potential_reinvestment:,.0f}
            ç›®æ ‡å¤æŠ•ç‡: 60%

            è¯·æä¾›ï¼š
            1. å¤æŠ•ç‡æå‡çš„ç­–ç•¥å»ºè®®
            2. æ¿€åŠ±æªæ–½è®¾è®¡
            3. å…·ä½“æ‰§è¡Œæ—¶é—´ç‚¹
            """

            claude_result = await self.claude_client.analyze_complex_query(analysis_prompt, expiry_trends)
            if claude_result.get('success'):
                analysis_text = claude_result.get('analysis', {}).get('detailed_analysis', analysis_text)

        return BusinessInsight(
            insight_id=f"reinvestment_opportunity_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            insight_type=InsightType.OPPORTUNITY_IDENTIFICATION,
            priority=InsightPriority.MEDIUM,

            title="å¤æŠ•ç‡æå‡æœºä¼š",
            summary=f"å½“å‰å¤æŠ•ç‡{estimated_reinvestment_rate:.1%}ï¼Œå­˜åœ¨æå‡ç©ºé—´",
            detailed_analysis=analysis_text,

            key_metrics={
                'current_reinvestment_rate': estimated_reinvestment_rate,
                'target_reinvestment_rate': 0.6,
                'potential_increase': 0.6 - estimated_reinvestment_rate,
                'potential_reinvestment_amount': potential_reinvestment
            },
            supporting_data=expiry_trends,
            confidence_score=0.75,

            recommended_actions=[],
            expected_impact="æå‡èµ„é‡‘ç•™å­˜ç‡ï¼Œå‡å°‘ç°é‡‘æµå‡ºå‹åŠ›",
            implementation_difficulty="å®¹æ˜“",

            data_sources=['/api/sta/product_end_interval'],
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="åˆ°æœŸå‰1å‘¨å¼€å§‹æ¨å¹¿ï¼ŒæŒç»­ä¼˜åŒ–"
        )

    # ============= é£é™©é¢„è­¦æ´å¯Ÿç”Ÿæˆ =============

    async def _generate_risk_warning_insights(self, processed_data: Dict[str, Any]) -> List[BusinessInsight]:
        """ç”Ÿæˆé£é™©é¢„è­¦æ´å¯Ÿ"""
        insights = []

        try:
            # ç»¼åˆé£é™©è¯„ä¼°
            system_data = processed_data.get('system_data', {})
            daily_trends = processed_data.get('daily_trends', {})
            anomalies = processed_data.get('detected_anomalies', [])

            # å¼‚å¸¸æ•°æ®é£é™©
            if len(anomalies) > 5:  # å¼‚å¸¸ç‚¹è¿‡å¤š
                insight = await self._create_data_anomaly_risk_insight(anomalies)
                insights.append(insight)

            # ä¸šåŠ¡è¿ç»­æ€§é£é™©
            volatility = daily_trends.get('volatility', 0)
            if volatility > 0.2:  # æ³¢åŠ¨æ€§è¿‡é«˜
                insight = await self._create_business_continuity_risk_insight(volatility, daily_trends)
                insights.append(insight)

            # æµåŠ¨æ€§é£é™© (åŸºäºç³»ç»Ÿæ•°æ®)
            total_balance = float(system_data.get('æ€»ä½™é¢', 0))
            daily_outflow = daily_trends.get('avg_daily_outflow', 0)

            if daily_outflow > 0:
                liquidity_days = total_balance / daily_outflow
                if liquidity_days < 15:  # èµ„é‡‘æ”¯æ’‘ä¸åˆ°15å¤©
                    insight = await self._create_liquidity_critical_risk_insight(liquidity_days, total_balance,
                                                                                 daily_outflow)
                    insights.append(insight)

        except Exception as e:
            logger.error(f"é£é™©é¢„è­¦æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}")

        return insights

    async def _create_business_continuity_risk_insight(self, volatility_metric: float,
                                                       daily_trend_data: Dict[str, Any]) -> BusinessInsight:
        """
        (ç§æœ‰) åˆ›å»ºä¸šåŠ¡è¿ç»­æ€§é£é™©æ´å¯Ÿï¼ˆä¾‹å¦‚ï¼Œå…³é”®æŒ‡æ ‡æ³¢åŠ¨è¿‡å¤§ï¼‰ã€‚
        volatility_metric: ä¸€ä¸ªé‡åŒ–æ³¢åŠ¨æ€§çš„æŒ‡æ ‡å€¼ã€‚
        daily_trend_data: ç›¸å…³çš„æ—¥è¶‹åŠ¿æ•°æ®ä½œä¸ºä¸Šä¸‹æ–‡ã€‚
        """
        insight_id = f"biz_continuity_risk_{datetime.now().strftime('%Y%m%d%H%M%S%f')}"
        title = "ä¸šåŠ¡å…³é”®æŒ‡æ ‡æ³¢åŠ¨å¼‚å¸¸ï¼Œå…³æ³¨è¿ç»­æ€§é£é™©"
        summary = f"ç›‘æµ‹åˆ°è¿‘æœŸä¸šåŠ¡å…³é”®æŒ‡æ ‡ï¼ˆä¾‹å¦‚èµ„é‡‘ã€ç”¨æˆ·æ´»è·ƒåº¦ï¼‰å‡ºç°æ˜¾è‘—æ³¢åŠ¨ï¼ˆæ³¢åŠ¨æ€§æŒ‡æ ‡: {volatility_metric:.2f}ï¼‰ï¼Œå¯èƒ½å½±å“ä¸šåŠ¡çš„ç¨³å®šæ€§å’Œè¿ç»­æ€§ã€‚"
        detailed_analysis = f"{summary} é«˜æ³¢åŠ¨æ€§å¯èƒ½é¢„ç¤ºç€å¸‚åœºç¯å¢ƒå˜åŒ–ã€å†…éƒ¨è¿è¥é—®é¢˜æˆ–çªå‘äº‹ä»¶å½±å“ã€‚å»ºè®®æ·±å…¥åˆ†ææ³¢åŠ¨æ¥æºï¼Œè¯„ä¼°å…¶å¯¹æ ¸å¿ƒä¸šåŠ¡æµç¨‹çš„å½±å“ï¼Œå¹¶åˆ¶å®šåº”å¯¹é¢„æ¡ˆã€‚"
        key_metrics = {
            'è§‚æµ‹åˆ°çš„æ³¢åŠ¨æ€§æŒ‡æ ‡': volatility_metric,
            'é£é™©ç­‰çº§è¯„ä¼°': 'é«˜' if volatility_metric > 0.25 else 'ä¸­'  # ç¤ºä¾‹é˜ˆå€¼
        }
        confidence = 0.70 + (0.15 if volatility_metric > 0.25 else 0)
        priority = InsightPriority.HIGH if volatility_metric > 0.25 else InsightPriority.MEDIUM

        if self.claude_client:
            prompt = f"""
            å…¬å¸ä¸šåŠ¡æ•°æ®æ˜¾ç¤ºå…³é”®æŒ‡æ ‡å­˜åœ¨è¾ƒé«˜æ³¢åŠ¨æ€§ï¼š
            - é‡åŒ–çš„æ³¢åŠ¨æ€§æŒ‡æ ‡å€¼ä¸º: {volatility_metric:.3f} (ä¾‹å¦‚ï¼Œé«˜äº0.15æˆ–0.2å³ä¸ºæ˜¾è‘—)
            - ç›¸å…³æ—¥è¶‹åŠ¿æ•°æ®æ‘˜è¦: {json.dumps(daily_trend_data, ensure_ascii=False, indent=2, cls=CustomJSONEncoder)}

            è¯·ç”¨ä¸­æ–‡åˆ†æï¼š
            1. è¿™ç§é«˜æ³¢åŠ¨æ€§å¯¹ä¸šåŠ¡è¿ç»­æ€§å¯èƒ½é€ æˆçš„å…·ä½“é£é™©æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆä¾‹å¦‚ï¼šç°é‡‘æµè§„åˆ’å›°éš¾ã€ç”¨æˆ·ä¿¡ä»»åº¦ä¸‹é™ã€è¿è¥è®¡åˆ’æ‰“ä¹±ç­‰ï¼‰
            2. å»ºè®®ä»å“ªäº›æ–¹é¢è°ƒæŸ¥æ³¢åŠ¨äº§ç”Ÿçš„åŸå› ï¼Ÿ
            3. ä¸ºåº”å¯¹æ­¤ç±»æ³¢åŠ¨ï¼Œå¯ä»¥è€ƒè™‘å“ªäº›é£é™©ç®¡ç†æˆ–ä¸šåŠ¡è°ƒæ•´æªæ–½ï¼Ÿ

            è¯·æä¾›ä¸€ä¸ªåŒ…å«ä»¥ä¸‹é”®çš„JSONå¯¹è±¡ï¼š
            "detailed_analysis_text": "å¯¹æ³¢åŠ¨æ€§é£é™©çš„è¯¦ç»†ä¸­æ–‡åˆ†æã€‚",
            "potential_continuity_risks": ["å…·ä½“è¿ç»­æ€§é£é™©1", "é£é™©2"],
            "risk_management_suggestions": ["é£é™©ç®¡ç†å»ºè®®1", "å»ºè®®2"]
            """
            try:
                ai_response = await self.claude_client.analyze_complex_query(
                    query=prompt,
                    context={"volatility_data": daily_trend_data}
                )
                if ai_response and ai_response.get('success'):
                    analysis_content = ai_response.get('analysis', {})
                    if isinstance(analysis_content, str):
                        try:
                            analysis_content = json.loads(analysis_content)
                        except:
                            pass

                    if isinstance(analysis_content, dict):
                        detailed_analysis = analysis_content.get('detailed_analysis_text', detailed_analysis)
                        confidence = analysis_content.get('confidence', confidence)
                else:
                    logger.warning(
                        f"AI call for business continuity risk insight failed: {ai_response.get('error') if ai_response else 'N/A'}")
            except Exception as e:
                logger.error(f"Error during AI call for business continuity risk insight: {e}")

        return BusinessInsight(
            insight_id=insight_id,
            insight_type=InsightType.RISK_WARNING,
            priority=priority,
            title=title,
            summary=summary,
            detailed_analysis=detailed_analysis,
            key_metrics=key_metrics,
            supporting_data={"daily_trends_snapshot": daily_trend_data, "calculated_volatility": volatility_metric},
            confidence_score=confidence,
            recommended_actions=[],  # ç”± _generate_actionable_recommendations å¡«å……
            expected_impact="é€šè¿‡è¯†åˆ«å’Œç®¡ç†æ³¢åŠ¨æ€§ï¼Œå¢å¼ºä¸šåŠ¡éŸ§æ€§ï¼Œä¿éšœè¿è¥ç¨³å®šã€‚",
            implementation_difficulty="ä¸­ç­‰",
            data_sources=[f"{api_name}" for api_name in daily_trend_data.get("api_source_names", ["/api/sta/day"])],
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="éœ€æŒç»­ç›‘æ§ï¼Œ1-2å‘¨å†…åˆ¶å®šåº”å¯¹ç­–ç•¥"
        )

    async def _create_liquidity_critical_risk_insight(self, liquidity_days: float,
                                                      total_balance: float, daily_outflow: float) -> BusinessInsight:
        """åˆ›å»ºæµåŠ¨æ€§ä¸¥é‡é£é™©æ´å¯Ÿ"""

        analysis_text = f"æŒ‰å½“å‰å‡ºé‡‘é€Ÿåº¦ï¼Œèµ„é‡‘ä»…èƒ½æ”¯æ’‘{liquidity_days:.1f}å¤©ï¼Œå­˜åœ¨ä¸¥é‡æµåŠ¨æ€§é£é™©ã€‚"

        if self.claude_client:
            analysis_prompt = f"""
            ç´§æ€¥æµåŠ¨æ€§é£é™©åˆ†æå’Œåº”å¯¹æ–¹æ¡ˆï¼š

            å½“å‰èµ„é‡‘ä½™é¢: Â¥{total_balance:,.0f}
            æ—¥å‡å‡ºé‡‘: Â¥{daily_outflow:,.0f}
            æ”¯æ’‘å¤©æ•°: {liquidity_days:.1f}å¤©

            è¿™æ˜¯ç´§æ€¥æƒ…å†µï¼Œè¯·æä¾›ï¼š
            1. ç«‹å³æ‰§è¡Œçš„é£é™©æ§åˆ¶æªæ–½
            2. èµ„é‡‘ç­¹æªå»ºè®®
            3. ç´§æ€¥é¢„æ¡ˆå¯åŠ¨æ¡ä»¶
            """

            claude_result = await self.claude_client.analyze_complex_query(
                analysis_prompt,
                {'balance': total_balance, 'outflow': daily_outflow}
            )
            if claude_result.get('success'):
                analysis_text = claude_result.get('analysis', {}).get('detailed_analysis', analysis_text)

        return BusinessInsight(
            insight_id=f"liquidity_critical_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            insight_type=InsightType.RISK_WARNING,
            priority=InsightPriority.CRITICAL,

            title="æµåŠ¨æ€§ä¸¥é‡é£é™©é¢„è­¦",
            summary=f"èµ„é‡‘ä»…èƒ½æ”¯æ’‘{liquidity_days:.1f}å¤©ï¼Œéœ€è¦ç«‹å³è¡ŒåŠ¨",
            detailed_analysis=analysis_text,

            key_metrics={
                'liquidity_days': liquidity_days,
                'total_balance': total_balance,
                'daily_outflow': daily_outflow,
                'risk_level': 'critical',
                'urgency': 'immediate'
            },
            supporting_data={'balance': total_balance, 'outflow': daily_outflow},
            confidence_score=0.95,

            recommended_actions=[],
            expected_impact="é¿å…æµåŠ¨æ€§å±æœºï¼Œç»´æŠ¤ä¸šåŠ¡è¿ç»­æ€§",
            implementation_difficulty="é«˜",

            data_sources=['/api/sta/system', '/api/sta/day'],
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="ç«‹å³æ‰§è¡Œï¼Œ24å°æ—¶å†…åˆ¶å®šåº”å¯¹æ–¹æ¡ˆ"
        )

    # ============= å¯æ‰§è¡Œè¡ŒåŠ¨å»ºè®®ç”Ÿæˆ =============

    async def _generate_actionable_recommendations(self, insight: BusinessInsight,
                                                   processed_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä¸ºæ´å¯Ÿç”Ÿæˆå¯æ‰§è¡Œçš„è¡ŒåŠ¨å»ºè®®"""
        try:
            actions = []

            # æ ¹æ®æ´å¯Ÿç±»å‹ç”Ÿæˆç›¸åº”çš„è¡ŒåŠ¨å»ºè®®
            if insight.insight_type == InsightType.RISK_WARNING:
                actions = await self._generate_risk_mitigation_actions(insight, processed_data)
            elif insight.insight_type == InsightType.OPPORTUNITY_IDENTIFICATION:
                actions = await self._generate_opportunity_capture_actions(insight, processed_data)
            elif insight.insight_type == InsightType.FINANCIAL_HEALTH:
                actions = await self._generate_financial_optimization_actions(insight, processed_data)
            elif insight.insight_type == InsightType.USER_GROWTH_INSIGHT:
                actions = await self._generate_user_growth_actions(insight, processed_data)
            elif insight.insight_type == InsightType.EXPIRY_MANAGEMENT:
                actions = await self._generate_expiry_management_actions(insight, processed_data)
            else:
                actions = await self._generate_generic_actions(insight, processed_data)

            return actions

        except Exception as e:
            logger.error(f"è¡ŒåŠ¨å»ºè®®ç”Ÿæˆå¤±è´¥: {str(e)}")
            return []

    async def _generate_financial_optimization_actions(self, insight: BusinessInsight,
                                                       processed_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        (ç§æœ‰) ä¸ºè´¢åŠ¡å¥åº·ç›¸å…³çš„æ´å¯Ÿç”Ÿæˆå…·ä½“çš„è´¢åŠ¡ä¼˜åŒ–è¡ŒåŠ¨å»ºè®®ã€‚
        """
        actions: List[Dict[str, Any]] = []
        action_prefix = f"fin_opt_act_{insight.insight_id[-6:]}"  # åŸºäºæ´å¯ŸIDç”Ÿæˆå”¯ä¸€å‰ç¼€

        if not self.claude_client:
            logger.warning("ClaudeClient not available for generating financial optimization actions.")
            # æä¾›ä¸€äº›åŸºäºè§„åˆ™çš„é€šç”¨å»ºè®®
            if insight.priority in [InsightPriority.CRITICAL, InsightPriority.HIGH]:
                actions.append({
                    'action_id': f"{action_prefix}_review_cashflow", 'title': "ç´§æ€¥å®¡è§†ç°é‡‘æµ",
                    'description': "ç«‹å³å¯¹å½“å‰ç°é‡‘æµçŠ¶å†µè¿›è¡Œå…¨é¢å®¡æŸ¥ï¼Œè¯†åˆ«ä¸»è¦å‡ºé‡‘ç‚¹å’Œæ½œåœ¨é£é™©ã€‚",
                    'action_type': ActionType.IMMEDIATE_ACTION.value, 'priority': InsightPriority.HIGH.value
                })
            actions.append({
                'action_id': f"{action_prefix}_monitor_key_ratios", 'title': "ç›‘æ§å…³é”®è´¢åŠ¡æ¯”ç‡",
                'description': "æŒç»­ç›‘æ§å¦‚æµåŠ¨æ¯”ç‡ã€é€ŸåŠ¨æ¯”ç‡ã€å‡ºå…¥é‡‘æ¯”ç­‰å…³é”®è´¢åŠ¡å¥åº·æŒ‡æ ‡ã€‚",
                'action_type': ActionType.MONITORING.value, 'priority': InsightPriority.MEDIUM.value
            })
            return actions

        # ä½¿ç”¨AIç”Ÿæˆæ›´å…·ä½“çš„å»ºè®®
        # insight.summary å’Œ insight.detailed_analysis å·²ç»åŒ…å«äº†AIå¯¹è´¢åŠ¡çŠ¶å†µçš„åˆ†æ
        # insight.key_metrics åŒ…å«äº†ç›¸å…³æ•°æ®

        prompt_context = {
            "insight_title": insight.title,
            "insight_summary": insight.summary,
            "insight_priority": insight.priority.value,
            "key_financial_metrics": insight.key_metrics,  # åŒ…å«å…³é”®æ•°æ®
            "current_financial_analysis": insight.detailed_analysis  # AIä¹‹å‰çš„åˆ†æ
        }

        prompt = f"""
        æ‚¨æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„é¦–å¸­è´¢åŠ¡å®˜(CFO)ã€‚ä»¥ä¸‹æ˜¯ä¸€é¡¹å…³äºå…¬å¸è´¢åŠ¡çŠ¶å†µçš„ä¸šåŠ¡æ´å¯Ÿï¼š
        æ´å¯Ÿæ ‡é¢˜: "{insight.title}"
        æ´å¯Ÿæ‘˜è¦: "{insight.summary}"
        ä¼˜å…ˆçº§: {insight.priority.value}
        å…³é”®ç›¸å…³è´¢åŠ¡æŒ‡æ ‡: {json.dumps(insight.key_metrics, ensure_ascii=False, indent=2, cls=CustomJSONEncoder)}
        ç³»ç»Ÿç”Ÿæˆçš„è¯¦ç»†åˆ†æ:
        ---
        {insight.detailed_analysis}
        ---

        åŸºäºä»¥ä¸Šæ´å¯Ÿå’Œåˆ†æï¼Œè¯·æå‡º 2-3 æ¡å…·ä½“çš„ã€å¯æ“ä½œçš„è´¢åŠ¡ä¼˜åŒ–è¡ŒåŠ¨å»ºè®®ã€‚
        å¯¹äºæ¯æ¡å»ºè®®ï¼Œè¯·æ˜ç¡®ï¼š
        1.  `action_title`: å»ºè®®çš„ç®€æ´æ ‡é¢˜ (ä¾‹å¦‚ï¼šâ€œä¼˜åŒ–çŸ­æœŸå€ºåŠ¡ç»“æ„â€)
        2.  `action_description`: å»ºè®®çš„è¯¦ç»†æè¿°å’Œæ‰§è¡Œè¦ç‚¹ã€‚
        3.  `action_type`: ä»ä»¥ä¸‹é€‰æ‹©ï¼š{', '.join([e.value for e in ActionType])} (ä¾‹å¦‚ï¼š"short_term_plan")
        4.  `timeline_suggestion`: å»ºè®®çš„æ‰§è¡Œæ—¶é—´æ¡†æ¶ (ä¾‹å¦‚ï¼šâ€œ1å‘¨å†…å¯åŠ¨â€ï¼Œâ€œæŒç»­è¿›è¡Œâ€)
        5.  `expected_outcome_summary`: æ‰§è¡Œæ­¤å»ºè®®é¢„æœŸçš„ä¸»è¦æˆæœã€‚

        è¯·ä»¥JSONæ•°ç»„çš„æ ¼å¼è¿”å›è¿™äº›å»ºè®®ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåŒ…å«ä¸Šè¿°é”®çš„å­—å…¸ã€‚ä¾‹å¦‚ï¼š
        [
            {{
                "action_title": "...",
                "action_description": "...",
                "action_type": "...",
                "timeline_suggestion": "...",
                "expected_outcome_summary": "..."
            }}
        ]
        å¦‚æœæ´å¯Ÿè¡¨æ˜è´¢åŠ¡çŠ¶å†µè‰¯å¥½ï¼Œå»ºè®®å¯ä»¥æ˜¯â€œç»´æŒå¹¶ç›‘æ§â€æˆ–â€œæ¢ç´¢æ–°çš„æŠ•èµ„æœºä¼šâ€ã€‚
        å¦‚æœæ´å¯Ÿè¡¨æ˜å­˜åœ¨é£é™©ï¼Œå»ºè®®åº”ä¾§é‡äºé£é™©ç¼“è§£å’Œæ§åˆ¶ã€‚
        """
        try:
            ai_response = await self.claude_client.analyze_complex_query(query=prompt, context=prompt_context)
            if ai_response and ai_response.get('success'):
                response_content = ai_response.get('analysis', ai_response.get('response'))
                if isinstance(response_content, str):
                    try:
                        response_content = json.loads(response_content)  # æœŸæœ›è¿”å›JSONåˆ—è¡¨
                    except json.JSONDecodeError:
                        logger.error(f"AI response for financial actions is not valid JSON: {response_content[:200]}")
                        # å¯ä»¥å°è¯•ä»æ–‡æœ¬ä¸­è§£æï¼Œæˆ–è¿”å›é€šç”¨å»ºè®®

                if isinstance(response_content, list):
                    for idx, action_data in enumerate(response_content):
                        if isinstance(action_data, dict):
                            actions.append({
                                'action_id': f"{action_prefix}_{idx}",
                                'action_type': ActionType(
                                    action_data.get('action_type', ActionType.MEDIUM_TERM_PLAN.value)).value,
                                'title': action_data.get('action_title', f"è´¢åŠ¡ä¼˜åŒ–å»ºè®® {idx + 1}"),
                                'description': action_data.get('action_description', "æ ¹æ®AIåˆ†æçš„å…·ä½“å»ºè®®ã€‚"),
                                'priority': insight.priority.value,  # ç»§æ‰¿æ´å¯Ÿçš„ä¼˜å…ˆçº§æˆ–AIé‡æ–°è¯„ä¼°
                                'timeline': action_data.get('timeline_suggestion', "æ ¹æ®å®é™…æƒ…å†µåˆ¶å®š"),
                                'responsible_party': "è´¢åŠ¡éƒ¨é—¨/ç®¡ç†å±‚",  # é€šç”¨è´Ÿè´£äºº
                                'required_resources': ["è´¢åŠ¡æ•°æ®åˆ†æèƒ½åŠ›", "å†³ç­–æƒ"],
                                'success_metrics': [f"{action_data.get('expected_outcome_summary', 'è´¢åŠ¡æŒ‡æ ‡æ”¹å–„')}"],
                                'expected_outcome': action_data.get('expected_outcome_summary', "æ”¹å–„è´¢åŠ¡å¥åº·çŠ¶å†µ"),
                                'potential_risks': ["å¸‚åœºå˜åŒ–å¯èƒ½å½±å“æ•ˆæœ"]
                            })
                        else:
                            logger.warning(f"AI returned non-dict item in actions list: {action_data}")
            else:
                logger.warning(
                    f"AI call for financial optimization actions failed or no success: {ai_response.get('error') if ai_response else 'N/A'}")
        except Exception as e:
            logger.error(f"Error generating financial optimization actions with AI: {e}")

        # å¦‚æœAIå¤±è´¥æˆ–æ²¡æœ‰ç”Ÿæˆå…·ä½“è¡ŒåŠ¨ï¼Œè¡¥å……é€šç”¨å»ºè®®
        if not actions:
            actions.append({
                'action_id': f"{action_prefix}_default_monitor", 'title': "æŒç»­ç›‘æ§è´¢åŠ¡æŒ‡æ ‡",
                'description': "å®šæœŸå›é¡¾æ ¸å¿ƒè´¢åŠ¡æŠ¥è¡¨å’Œå…³é”®æ¯”ç‡ï¼Œç¡®ä¿è´¢åŠ¡å¥åº·ã€‚",
                'action_type': ActionType.MONITORING.value, 'priority': InsightPriority.MEDIUM.value,
                'timeline': "æŒç»­è¿›è¡Œ", 'responsible_party': "è´¢åŠ¡å›¢é˜Ÿ",
                'expected_outcome': "åŠæ—¶å‘ç°è´¢åŠ¡é£é™©å’Œæœºä¼š"
            })
        return actions
    async def _create_financial_opportunity_insight(self, outflow_ratio: float, net_flow: float,
                                                    system_data: Dict[str, Any]) -> BusinessInsight:
        """
        (ç§æœ‰) åˆ›å»ºç§¯æè´¢åŠ¡çŠ¶å†µä¸‹çš„æœºä¼šæ´å¯Ÿã€‚
        ä¾‹å¦‚ï¼šç°é‡‘æµå……è£•ï¼Œå‡ºé‡‘å æ¯”ä½ã€‚
        """
        insight_id = f"fin_opportunity_{datetime.now().strftime('%Y%m%d%H%M%S%f')}"
        title = "è´¢åŠ¡çŠ¶å†µå¥åº·ï¼Œç°é‡‘æµå……è£•"
        summary = f"å½“å‰å‡ºé‡‘ä¸å…¥é‡‘æ¯”ä¾‹ä¸º{outflow_ratio:.1%}ï¼Œå‡€ç°é‡‘æµä¸º Â¥{net_flow:,.0f}ï¼Œæ˜¾ç¤ºå…¬å¸èµ„é‡‘çŠ¶å†µè‰¯å¥½ï¼Œå­˜åœ¨è¿›ä¸€æ­¥å‘å±•çš„æœºä¼šã€‚"
        detailed_analysis = summary  # åˆå§‹åˆ†æä¸æ‘˜è¦ç›¸åŒï¼Œå¯ç”±AIä¸°å¯Œ
        key_metrics = {
            'å‡ºé‡‘å…¥é‡‘æ¯”': outflow_ratio,
            'å‡€ç°é‡‘æµ': net_flow,
            'æ€»ä½™é¢': float(system_data.get('æ€»ä½™é¢', 0)),
            'è¯„ä¼°': 'å¥åº·ä¸”æœ‰æœºä¼š'
        }
        confidence = 0.85
        priority = InsightPriority.MEDIUM  # é€šå¸¸æœºä¼šæ˜¯ä¸­é«˜ä¼˜å…ˆçº§

        if self.claude_client:
            prompt = f"""
            å½“å‰å…¬å¸è´¢åŠ¡æ•°æ®æ˜¾ç¤ºï¼š
            - å‡ºé‡‘ä¸å…¥é‡‘æ¯”ä¾‹: {outflow_ratio:.2%} (ä½äº50%è¢«è®¤ä¸ºæ˜¯å¥åº·çš„)
            - å‡€ç°é‡‘æµ: Â¥{net_flow:,.0f}
            - æ€»ä½™é¢: Â¥{float(system_data.get('æ€»ä½™é¢', 0)):,.0f}

            è¿™æ˜¯ä¸€ä¸ªç§¯æçš„è´¢åŠ¡ä¿¡å·ã€‚è¯·åŸºäºæ­¤ä¿¡æ¯ï¼Œç”¨ä¸­æ–‡åˆ†æï¼š
            1. è¿™ç§è‰¯å¥½è´¢åŠ¡çŠ¶å†µå¯èƒ½å¸¦æ¥çš„å…·ä½“ä¸šåŠ¡æœºä¼šï¼ˆä¾‹å¦‚ï¼šæ–°äº§å“æŠ•èµ„ã€å¸‚åœºæ‰©å¼ ã€è‚¡ä¸œåˆ†çº¢ã€å€ºåŠ¡å¿è¿˜ç­‰ï¼‰ã€‚
            2. å¦‚ä½•åˆ©ç”¨å½“å‰å……è£•çš„ç°é‡‘æµæ¥è¿›ä¸€æ­¥æå‡å…¬å¸ä»·å€¼æˆ–é™ä½æ½œåœ¨é£é™©ï¼Ÿ
            3. å¯¹è¿™ç§æœºä¼šçš„ç®€è¦è¯„ä¼°ï¼ˆä¾‹å¦‚ï¼Œæœºä¼šçª—å£ã€æ½œåœ¨å›æŠ¥ï¼‰ã€‚

            è¯·æä¾›ä¸€ä¸ªåŒ…å«ä»¥ä¸‹é”®çš„JSONå¯¹è±¡ï¼š
            "detailed_analysis_text": "è¯¦ç»†çš„ä¸­æ–‡åˆ†ææ–‡æœ¬ã€‚",
            "identified_opportunities": ["æœºä¼šç‚¹1çš„æè¿°", "æœºä¼šç‚¹2çš„æè¿°"],
            "strategic_suggestions": ["åˆ©ç”¨æ­¤æœºä¼šçš„ç­–ç•¥å»ºè®®1", "å»ºè®®2"]
            """
            try:
                ai_response = await self.claude_client.analyze_complex_query(
                    query=prompt,
                    context={"financial_data": system_data}
                )
                if ai_response and ai_response.get('success'):
                    analysis_content = ai_response.get('analysis', {})  # å‡è®¾ 'analysis' åŒ…å«æ‰€éœ€å†…å®¹
                    if isinstance(analysis_content, str):  # æœ‰æ—¶å€™AIå¯èƒ½ç›´æ¥è¿”å›æ–‡æœ¬
                        try:
                            analysis_content = json.loads(analysis_content)  # å°è¯•è§£æ
                        except:
                            pass

                    if isinstance(analysis_content, dict):
                        detailed_analysis = analysis_content.get('detailed_analysis_text', detailed_analysis)
                        # Opportunity insights might be directly part of the text, or structured
                        # For now, we'll assume the detailed_analysis from AI is comprehensive.
                        # Recommendations will be generated separately.
                        confidence = analysis_content.get('confidence', confidence)  # AIå¯èƒ½ç»™å‡ºç½®ä¿¡åº¦
                else:
                    logger.warning(
                        f"AI call for financial opportunity insight failed or returned no success: {ai_response.get('error') if ai_response else 'N/A'}")
            except Exception as e:
                logger.error(f"Error during AI call for financial opportunity insight: {e}")

        return BusinessInsight(
            insight_id=insight_id,
            insight_type=InsightType.OPPORTUNITY_IDENTIFICATION,  # æ›´å…·ä½“çš„ç±»å‹
            priority=priority,
            title=title,
            summary=summary,
            detailed_analysis=detailed_analysis,
            key_metrics=key_metrics,
            supporting_data={"system_snapshot": system_data},
            confidence_score=confidence,
            recommended_actions=[],  # å°†ç”± _generate_actionable_recommendations å¡«å……
            expected_impact="é€šè¿‡æœ‰æ•ˆåˆ©ç”¨ç°æœ‰èµ„é‡‘ä¼˜åŠ¿ï¼Œå¯èƒ½å®ç°ä¸šåŠ¡å¢é•¿æˆ–é£é™©é™ä½ã€‚",
            implementation_difficulty="ä¸­ç­‰",  # å–å†³äºå…·ä½“æœºä¼š
            data_sources=[f"{api_name}" for api_name in system_data.get("api_source_names", ["/api/sta/system"])],
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="æœªæ¥1-3ä¸ªæœˆ"
        )

    async def _create_growth_concern_insight(self, avg_registrations: float, growth_rate: float,
                                             daily_data: Dict[str, Any]) -> BusinessInsight:
        """
        (ç§æœ‰) åˆ›å»ºç”¨æˆ·å¢é•¿ç¼“æ…¢æˆ–æœªè¾¾æ ‡çš„å…³æ³¨ç‚¹æ´å¯Ÿã€‚
        """
        insight_id = f"user_growth_concern_{datetime.now().strftime('%Y%m%d%H%M%S%f')}"
        rules = self.business_rules['user_growth']
        title = "ç”¨æˆ·å¢é•¿é€Ÿåº¦éœ€å…³æ³¨å’Œæå‡"
        summary = f"æ—¥å‡æ–°å¢ç”¨æˆ·çº¦{avg_registrations:.0f}äººï¼Œå¢é•¿ç‡{growth_rate:.1%}ï¼Œå¯èƒ½ä½äºé¢„æœŸï¼ˆç›®æ ‡: {rules.get('healthy_daily_growth', 50)}äºº/å¤©ï¼‰ã€‚å»ºè®®åˆ†æåŸå› å¹¶é‡‡å–æªæ–½ã€‚"
        detailed_analysis = summary
        key_metrics = {
            'æ—¥å‡æ–°å¢æ³¨å†Œ': avg_registrations,
            'ç”¨æˆ·å¢é•¿ç‡': growth_rate,
            'ç›®æ ‡æ—¥æ–°å¢': rules.get('healthy_daily_growth', 50),
            'æ—¥æ–°å¢ç¼ºå£': rules.get('healthy_daily_growth', 50) - avg_registrations
        }
        confidence = 0.75  # åŸºäºè§„åˆ™çš„åˆ¤æ–­ï¼Œä½†åŸå› åˆ†æéœ€è¦AI
        priority = InsightPriority.MEDIUM

        if self.claude_client:
            prompt = f"""
            å½“å‰ç”¨æˆ·å¢é•¿æ•°æ®æ˜¾ç¤ºï¼š
            - æ—¥å‡æ–°å¢ç”¨æˆ·: {avg_registrations:.0f} äºº
            - è¿‘æœŸç”¨æˆ·å¢é•¿ç‡: {growth_rate:.1%}
            - ä¸šåŠ¡æœŸæœ›çš„æ—¥æ–°å¢ç”¨æˆ·æ•°çº¦ä¸º: {rules.get('healthy_daily_growth', 50)} äºº

            è¯¥å¢é•¿æ•°æ®å¯èƒ½æœªè¾¾ä¸šåŠ¡é¢„æœŸã€‚è¯·ç”¨ä¸­æ–‡åˆ†æï¼š
            1. ç”¨æˆ·å¢é•¿ç¼“æ…¢æˆ–æœªè¾¾é¢„æœŸçš„å¯èƒ½åŸå› ï¼ˆä¾‹å¦‚ï¼šå¸‚åœºæ¨å¹¿ä¸è¶³ã€äº§å“å¸å¼•åŠ›ä¸‹é™ã€ç”¨æˆ·ä½“éªŒé—®é¢˜ã€ç«äº‰å¯¹æ‰‹å½±å“ç­‰ï¼‰ã€‚
            2. é’ˆå¯¹è¿™äº›å¯èƒ½åŸå› ï¼Œå¯ä»¥ä»å“ªäº›æ–¹é¢å…¥æ‰‹è°ƒæŸ¥å’Œåˆ†æï¼Ÿ
            3. åˆæ­¥æå‡º1-2ä¸ªå¯ä»¥è€ƒè™‘çš„æå‡ç”¨æˆ·å¢é•¿çš„ç­–ç•¥æ–¹å‘ã€‚

            è¯·æä¾›ä¸€ä¸ªåŒ…å«ä»¥ä¸‹é”®çš„JSONå¯¹è±¡ï¼š
            "detailed_analysis_text": "è¯¦ç»†çš„ä¸­æ–‡åˆ†æï¼ŒåŒ…æ‹¬å¯èƒ½åŸå› å’Œè°ƒæŸ¥æ–¹å‘ã€‚",
            "preliminary_strategies": ["åˆæ­¥ç­–ç•¥æ–¹å‘1", "åˆæ­¥ç­–ç•¥æ–¹å‘2"]
            """
            try:
                ai_response = await self.claude_client.analyze_complex_query(
                    query=prompt,
                    context={"daily_user_data": daily_data}  # daily_data åŒ…å« avg_daily_registrations, user_growth_rate ç­‰
                )
                if ai_response and ai_response.get('success'):
                    analysis_content = ai_response.get('analysis', {})
                    if isinstance(analysis_content, str):
                        try:
                            analysis_content = json.loads(analysis_content)
                        except:
                            pass
                    if isinstance(analysis_content, dict):
                        detailed_analysis = analysis_content.get('detailed_analysis_text', detailed_analysis)
                        # Recommendations will be generated separately if needed
                        confidence = analysis_content.get('confidence', confidence)
                else:
                    logger.warning(
                        f"AI call for user growth concern insight failed: {ai_response.get('error') if ai_response else 'N/A'}")
            except Exception as e:
                logger.error(f"Error during AI call for user growth concern insight: {e}")

        return BusinessInsight(
            insight_id=insight_id,
            insight_type=InsightType.USER_GROWTH_INSIGHT,
            priority=priority,
            title=title,
            summary=summary,
            detailed_analysis=detailed_analysis,
            key_metrics=key_metrics,
            supporting_data={"daily_user_metrics": daily_data},
            confidence_score=confidence,
            recommended_actions=[],
            expected_impact="é€šè¿‡é’ˆå¯¹æ€§æªæ–½æå‡ç”¨æˆ·å¢é•¿é€Ÿç‡ï¼Œæ‰©å¤§ç”¨æˆ·åŸºç¡€ã€‚",
            implementation_difficulty="ä¸­è‡³é«˜",
            data_sources=[f"{api_name}" for api_name in
                          daily_data.get("api_source_names", ["/api/sta/day", "/api/sta/user_daily"])],
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="æœªæ¥1ä¸ªæœˆé‡ç‚¹å…³æ³¨"
        )

    async def _create_liquidity_warning_insight(self, sustainability_days: float, total_balance: float,
                                                daily_outflow_avg: float) -> BusinessInsight:
        """
        (ç§æœ‰) åˆ›å»ºæµåŠ¨æ€§é£é™©é¢„è­¦æ´å¯Ÿã€‚
        """
        insight_id = f"liquidity_warn_{datetime.now().strftime('%Y%m%d%H%M%S%f')}"
        rules = self.business_rules['financial_health']
        title = "æµåŠ¨æ€§é£é™©é¢„è­¦ï¼šèµ„é‡‘çŸ­æœŸæ”¯æ’‘èƒ½åŠ›éœ€å…³æ³¨"
        summary = f"æŒ‰å½“å‰æ—¥å‡å‡ºé‡‘çº¦ Â¥{daily_outflow_avg:,.0f} è®¡ç®—ï¼Œç°æœ‰æ€»ä½™é¢ Â¥{total_balance:,.0f} é¢„è®¡å¯æ”¯æ’‘ {sustainability_days:.1f} å¤©ï¼Œä½äº {rules.get('liquidity_warning_days', 30)} å¤©çš„è­¦æˆ’çº¿ã€‚"
        detailed_analysis = summary
        key_metrics = {
            'èµ„é‡‘å¯æ”¯æ’‘å¤©æ•°': sustainability_days,
            'æ€»ä½™é¢': total_balance,
            'æ—¥å‡å‡ºé‡‘': daily_outflow_avg,
            'è­¦æˆ’çº¿å¤©æ•°': rules.get('liquidity_warning_days', 30)
        }
        # æ ¹æ®å¤©æ•°å·®è·è®¾å®šä¼˜å…ˆçº§å’Œç½®ä¿¡åº¦
        priority = InsightPriority.HIGH
        confidence = 0.80
        if sustainability_days < (rules.get('liquidity_warning_days', 30) / 2):  # ä¾‹å¦‚å°‘äº15å¤©
            priority = InsightPriority.CRITICAL
            confidence = 0.90
        elif sustainability_days < rules.get('liquidity_warning_days', 30) * 0.75:  # ä¾‹å¦‚å°‘äº22.5å¤©
            priority = InsightPriority.HIGH
            confidence = 0.85

        if self.claude_client:
            prompt = f"""
            å…¬å¸è´¢åŠ¡æ•°æ®æ˜¾ç¤ºå­˜åœ¨æµåŠ¨æ€§é£é™©ï¼š
            - å½“å‰æ€»ä½™é¢: Â¥{total_balance:,.0f}
            - è¿‘æœŸæ—¥å‡å‡ºé‡‘: Â¥{daily_outflow_avg:,.0f}
            - è®¡ç®—å‡ºçš„èµ„é‡‘å¯æ”¯æ’‘å¤©æ•°: {sustainability_days:.1f} å¤©
            - ä¸šåŠ¡è®¾å®šçš„æµåŠ¨æ€§é¢„è­¦å¤©æ•°ä¸º: {rules.get('liquidity_warning_days', 30)} å¤©

            å½“å‰æ”¯æ’‘å¤©æ•°ä½äºè­¦æˆ’çº¿ã€‚è¯·ç”¨ä¸­æ–‡åˆ†æï¼š
            1. æ­¤æµåŠ¨æ€§é£é™©çš„æ½œåœ¨åŸå› ï¼ˆä¾‹å¦‚ï¼šè¿‘æœŸå¤§é¢é›†ä¸­å‡ºé‡‘ã€å…¥é‡‘å‡å°‘ã€æŠ•èµ„å‘¨æœŸé”™é…ç­‰ï¼‰ã€‚
            2. æ­¤é£é™©å¯èƒ½å¯¼è‡´çš„çŸ­æœŸå’Œä¸­æœŸä¸šåŠ¡å½±å“ã€‚
            3. é’ˆå¯¹æ­¤æƒ…å†µï¼Œå¯ä»¥ç«‹å³é‡‡å–çš„ç¼“è§£æªæ–½ï¼Œä»¥åŠä¸­é•¿æœŸæ”¹å–„æµåŠ¨æ€§ç®¡ç†çš„å»ºè®®ã€‚

            è¯·æä¾›ä¸€ä¸ªåŒ…å«ä»¥ä¸‹é”®çš„JSONå¯¹è±¡ï¼š
            "detailed_analysis_text": "è¯¦ç»†çš„ä¸­æ–‡é£é™©åˆ†æåŠåŸå› æ¨æµ‹ã€‚",
            "potential_impacts_text": "æ½œåœ¨å½±å“çš„æè¿°ã€‚",
            "mitigation_suggestions": ["ç¼“è§£æªæ–½å»ºè®®1", "å»ºè®®2"]
            """
            try:
                ai_response = await self.claude_client.analyze_complex_query(
                    query=prompt,
                    context={"balance_data": total_balance, "outflow_data": daily_outflow_avg}
                )
                if ai_response and ai_response.get('success'):
                    analysis_content = ai_response.get('analysis', {})
                    if isinstance(analysis_content, str):
                        try:
                            analysis_content = json.loads(analysis_content)
                        except:
                            pass  # Keep as string if not valid JSON

                    if isinstance(analysis_content, dict):
                        detailed_analysis = analysis_content.get('detailed_analysis_text', detailed_analysis)
                        # You might want to add potential_impacts_text to detailed_analysis or store separately
                        impact_text = analysis_content.get('potential_impacts_text', '')
                        if impact_text:
                            detailed_analysis += f"\n\næ½œåœ¨å½±å“ï¼š{impact_text}"
                        # Recommendations will be handled by _generate_actionable_recommendations
                        confidence = analysis_content.get('confidence', confidence)
                else:
                    logger.warning(
                        f"AI call for liquidity warning insight failed: {ai_response.get('error') if ai_response else 'N/A'}")
            except Exception as e:
                logger.error(f"Error during AI call for liquidity warning insight: {e}")

        return BusinessInsight(
            insight_id=insight_id,
            insight_type=InsightType.RISK_WARNING,
            priority=priority,
            title=title,
            summary=summary,
            detailed_analysis=detailed_analysis,
            key_metrics=key_metrics,
            supporting_data={"total_balance": total_balance, "daily_outflow_avg": daily_outflow_avg,
                             "sustainability_days": sustainability_days},
            confidence_score=confidence,
            recommended_actions=[],  # ç”± _generate_actionable_recommendations å¡«å……
            expected_impact="åŠæ—¶åº”å¯¹å¯é¿å…èµ„é‡‘é“¾ç´§å¼ ï¼Œä¿éšœä¸šåŠ¡æ­£å¸¸è¿è¥ã€‚",
            implementation_difficulty="ä¸­ç­‰è‡³é«˜ï¼Œå–å†³äºå…·ä½“æªæ–½",
            data_sources=["/api/sta/system", "/api/sta/day"],  # å‡è®¾æ•°æ®æ¥æº
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="ç«‹å³å…³æ³¨ï¼Œ1å‘¨å†…é‡‡å–åˆæ­¥æªæ–½"
        )

    async def _generate_user_growth_actions(self, insight: BusinessInsight,
                                            processed_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        (ç§æœ‰) ä¸ºç”¨æˆ·å¢é•¿ç›¸å…³çš„æ´å¯Ÿç”Ÿæˆå…·ä½“çš„è¡ŒåŠ¨å»ºè®®ã€‚
        """
        actions: List[Dict[str, Any]] = []
        action_prefix = f"user_growth_act_{insight.insight_id[-6:]}"

        if not self.claude_client:
            logger.warning("ClaudeClient not available for generating user growth actions.")
            actions.append({
                'action_id': f"{action_prefix}_analyze_channels", 'title': "åˆ†æè·å®¢æ¸ é“",
                'description': "è¯„ä¼°ä¸åŒç”¨æˆ·è·å–æ¸ é“çš„æˆæœ¬å’Œæ•ˆç›Šï¼Œä¼˜åŒ–æŠ•å…¥ã€‚",
                'action_type': ActionType.MEDIUM_TERM_PLAN.value, 'priority': InsightPriority.MEDIUM.value
            })
            return actions

        prompt_context = {
            "insight_title": insight.title,
            "insight_summary": insight.summary,
            "insight_priority": insight.priority.value,
            "key_user_metrics": insight.key_metrics,  # ä¾‹å¦‚ï¼šæ—¥æ–°å¢ã€å¢é•¿ç‡ã€æ´»è·ƒåº¦ç­‰
            "current_user_analysis": insight.detailed_analysis
        }

        prompt = f"""
        æ‚¨æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç”¨æˆ·å¢é•¿ç­–ç•¥å¸ˆã€‚ä»¥ä¸‹æ˜¯ä¸€é¡¹å…³äºå…¬å¸ç”¨æˆ·å¢é•¿çŠ¶å†µçš„ä¸šåŠ¡æ´å¯Ÿï¼š
        æ´å¯Ÿæ ‡é¢˜: "{insight.title}"
        æ´å¯Ÿæ‘˜è¦: "{insight.summary}"
        ä¼˜å…ˆçº§: {insight.priority.value}
        å…³é”®ç›¸å…³ç”¨æˆ·æŒ‡æ ‡: {json.dumps(insight.key_metrics, ensure_ascii=False, indent=2, cls=CustomJSONEncoder)}
        ç³»ç»Ÿç”Ÿæˆçš„è¯¦ç»†åˆ†æ:
        ---
        {insight.detailed_analysis}
        ---

        åŸºäºä»¥ä¸Šæ´å¯Ÿï¼ˆç‰¹åˆ«æ˜¯å¦‚æœå¢é•¿æœªè¾¾é¢„æœŸæˆ–å­˜åœ¨æœºä¼šï¼‰ï¼Œè¯·æå‡º 2-3 æ¡å…·ä½“çš„ã€å¯æ“ä½œçš„ç”¨ä»¥æå‡ç”¨æˆ·å¢é•¿æˆ–ç”¨æˆ·æ´»è·ƒåº¦çš„è¡ŒåŠ¨å»ºè®®ã€‚
        å¯¹äºæ¯æ¡å»ºè®®ï¼Œè¯·æ˜ç¡®ï¼š
        1.  `action_title`: å»ºè®®çš„ç®€æ´æ ‡é¢˜ (ä¾‹å¦‚ï¼šâ€œå¯åŠ¨æ–°ç”¨æˆ·æ¨èå¥–åŠ±è®¡åˆ’â€)
        2.  `action_description`: å»ºè®®çš„è¯¦ç»†æè¿°å’Œæ‰§è¡Œè¦ç‚¹ã€‚
        3.  `action_type`: ä»ä»¥ä¸‹é€‰æ‹©ï¼š{', '.join([e.value for e in ActionType])} (ä¾‹å¦‚ï¼š"short_term_plan")
        4.  `target_metric_to_improve`: æ­¤å»ºè®®ä¸»è¦é’ˆå¯¹å“ªä¸ªç”¨æˆ·æŒ‡æ ‡çš„æå‡ (ä¾‹å¦‚ï¼šâ€œæ—¥æ–°å¢ç”¨æˆ·æ•°â€ã€â€œç”¨æˆ·æ´»è·ƒç‡â€)
        5.  `success_criteria`: å¦‚ä½•è¡¡é‡æ­¤å»ºè®®çš„æˆåŠŸ (ä¾‹å¦‚ï¼šâ€œæ—¥æ–°å¢ç”¨æˆ·æå‡20%â€)

        è¯·ä»¥JSONæ•°ç»„çš„æ ¼å¼è¿”å›è¿™äº›å»ºè®®ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåŒ…å«ä¸Šè¿°é”®çš„å­—å…¸ã€‚
        å¦‚æœæ´å¯Ÿè¡¨æ˜ç”¨æˆ·å¢é•¿è‰¯å¥½ï¼Œå»ºè®®å¯ä»¥æ˜¯â€œç»´æŒç°æœ‰ç­–ç•¥å¹¶æ¢ç´¢æ–°æ¸ é“â€æˆ–â€œæå‡é«˜ä»·å€¼ç”¨æˆ·è½¬åŒ–â€ã€‚
        """
        try:
            ai_response = await self.claude_client.analyze_complex_query(query=prompt, context=prompt_context)
            if ai_response and ai_response.get('success'):
                response_content = ai_response.get('analysis', ai_response.get('response'))
                if isinstance(response_content, str):
                    try:
                        response_content = json.loads(response_content)
                    except json.JSONDecodeError:
                        logger.error(f"AI response for user growth actions is not valid JSON: {response_content[:200]}")

                if isinstance(response_content, list):
                    for idx, action_data in enumerate(response_content):
                        if isinstance(action_data, dict):
                            actions.append({
                                'action_id': f"{action_prefix}_{idx}",
                                'action_type': ActionType(
                                    action_data.get('action_type', ActionType.MEDIUM_TERM_PLAN.value)).value,
                                'title': action_data.get('action_title', f"ç”¨æˆ·å¢é•¿å»ºè®® {idx + 1}"),
                                'description': action_data.get('action_description', "æ ¹æ®AIåˆ†æçš„å…·ä½“ç”¨æˆ·å¢é•¿å»ºè®®ã€‚"),
                                'priority': insight.priority.value,
                                'timeline': action_data.get('timeline_suggestion', "æ ¹æ®ç›®æ ‡åˆ¶å®š"),  # AI å¯èƒ½ä¹Ÿè¿”å› timeline
                                'responsible_party': "å¸‚åœºéƒ¨é—¨/è¿è¥éƒ¨é—¨",
                                'required_resources': ["è¥é”€é¢„ç®—", "è¿è¥äººåŠ›"],
                                'success_metrics': [action_data.get('success_criteria',
                                                                    f"æå‡ç›®æ ‡æŒ‡æ ‡ {action_data.get('target_metric_to_improve', 'N/A')}")],
                                'expected_outcome': f"æå‡ {action_data.get('target_metric_to_improve', 'ç”¨æˆ·å¢é•¿ç›¸å…³')} æŒ‡æ ‡",
                                'potential_risks': ["å¸‚åœºç«äº‰æ¿€çƒˆ", "ç”¨æˆ·åå¥½å˜åŒ–"]
                            })
            else:
                logger.warning(
                    f"AI call for user growth actions failed or no success: {ai_response.get('error') if ai_response else 'N/A'}")
        except Exception as e:
            logger.error(f"Error generating user growth actions with AI: {e}")

        if not actions:
            actions.append({
                'action_id': f"{action_prefix}_default_engagement", 'title': "æå‡ç”¨æˆ·æ´»è·ƒå’Œç•™å­˜",
                'description': "åˆ†æç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œä¼˜åŒ–äº§å“ä½“éªŒï¼Œç­–åˆ’ç”¨æˆ·äº’åŠ¨æ´»åŠ¨ä»¥æé«˜ç”¨æˆ·ç²˜æ€§ã€‚",
                'action_type': ActionType.MEDIUM_TERM_PLAN.value, 'priority': InsightPriority.MEDIUM.value,
                'timeline': "æŒç»­ä¼˜åŒ–", 'responsible_party': "äº§å“/è¿è¥å›¢é˜Ÿ",
                'expected_outcome': "æé«˜ç”¨æˆ·æ´»è·ƒåº¦å’Œç•™å­˜ç‡"
            })
        return actions

    async def _create_user_growth_opportunity_insight(self, avg_registrations: float, growth_rate: float,
                                                      daily_data: Dict[str, Any]) -> BusinessInsight:
        """
        (ç§æœ‰) åˆ›å»ºç”¨æˆ·å¢é•¿è‰¯å¥½çš„æœºä¼šæ´å¯Ÿã€‚
        """
        insight_id = f"user_growth_opp_{datetime.now().strftime('%Y%m%d%H%M%S%f')}"
        title = "ç”¨æˆ·å¢é•¿åŠ¿å¤´å¼ºåŠ²ï¼Œå¯è¿›ä¸€æ­¥æ‰©å¤§ä¼˜åŠ¿"
        summary = f"è¿‘æœŸç”¨æˆ·å¢é•¿è¡¨ç°å‡ºè‰²ï¼Œæ—¥å‡æ–°å¢ç”¨æˆ·è¾¾åˆ°çº¦ {avg_registrations:.0f} äººï¼Œå¢é•¿ç‡é«˜è¾¾ {growth_rate:.1%}ã€‚è¿™æ˜¯ä¸€ä¸ªç§¯æçš„ä¿¡å·ï¼Œè¡¨æ˜å½“å‰è·å®¢ç­–ç•¥æœ‰æ•ˆï¼Œå¹¶å¯èƒ½å­˜åœ¨è¿›ä¸€æ­¥æ‰©å¤§å¸‚åœºä»½é¢çš„æœºä¼šã€‚"
        detailed_analysis = f"{summary} å»ºè®®åˆ†æå½“å‰é«˜æ•ˆçš„è·å®¢æ¸ é“å’Œç”¨æˆ·ç”»åƒï¼ŒåŠ å¤§æŠ•å…¥ï¼Œå¹¶æ¢ç´¢å¦‚ä½•æé«˜æ–°ç”¨æˆ·çš„ç•™å­˜å’Œè½¬åŒ–ã€‚"
        key_metrics = {
            'æ—¥å‡æ–°å¢æ³¨å†Œ': avg_registrations,
            'ç”¨æˆ·å¢é•¿ç‡': growth_rate,
            'å¢é•¿åŠ¿å¤´è¯„ä¼°': 'å¼ºåŠ²'
        }
        confidence = 0.90  # åŸºäºè‰¯å¥½æ•°æ®ï¼Œç½®ä¿¡åº¦è¾ƒé«˜
        priority = InsightPriority.HIGH

        if self.claude_client:
            prompt = f"""
            å…¬å¸ç”¨æˆ·å¢é•¿æ•°æ®æ˜¾ç¤ºå‡ºå¼ºåŠ²åŠ¿å¤´ï¼š
            - æ—¥å‡æ–°å¢ç”¨æˆ·: {avg_registrations:.0f} äºº
            - è¿‘æœŸç”¨æˆ·å¢é•¿ç‡: {growth_rate:.1%}

            è¿™æ˜¯ä¸€ä¸ªéå¸¸ç§¯æçš„ä¿¡å·ã€‚è¯·ç”¨ä¸­æ–‡åˆ†æï¼š
            1. è¿™ç§å¿«é€Ÿå¢é•¿å¯èƒ½çš„ä¸»è¦é©±åŠ¨å› ç´ æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆä¾‹å¦‚ï¼šæˆåŠŸçš„å¸‚åœºæ´»åŠ¨ã€äº§å“ç‰¹æ€§å¸å¼•ã€å£ç¢‘ä¼ æ’­ç­‰ï¼‰
            2. å¦‚ä½•ä¿æŒå¹¶è¿›ä¸€æ­¥åŠ é€Ÿè¿™ç§å¢é•¿åŠ¿å¤´ï¼Ÿæœ‰å“ªäº›å¯ä»¥æ”¾å¤§çš„ç­–ç•¥ï¼Ÿ
            3. åœ¨å¿«é€Ÿå¢é•¿çš„åŒæ—¶ï¼Œéœ€è¦æ³¨æ„å“ªäº›æ½œåœ¨çš„æŒ‘æˆ˜æˆ–é£é™©ï¼Ÿï¼ˆä¾‹å¦‚ï¼šæœåŠ¡æ‰¿è½½èƒ½åŠ›ã€æ–°ç”¨æˆ·è´¨é‡ã€ç•™å­˜é—®é¢˜ç­‰ï¼‰

            è¯·æä¾›ä¸€ä¸ªåŒ…å«ä»¥ä¸‹é”®çš„JSONå¯¹è±¡ï¼š
            "detailed_analysis_text": "å¯¹å¢é•¿é©±åŠ¨å› ç´ å’ŒæŒç»­å¢é•¿ç­–ç•¥çš„è¯¦ç»†ä¸­æ–‡åˆ†æã€‚",
            "acceleration_strategies": ["åŠ é€Ÿå¢é•¿ç­–ç•¥1", "ç­–ç•¥2"],
            "potential_challenges": ["æ½œåœ¨æŒ‘æˆ˜1", "æŒ‘æˆ˜2"]
            """
            try:
                ai_response = await self.claude_client.analyze_complex_query(
                    query=prompt,
                    context={"user_growth_data": daily_data}  # daily_data åŒ…å«ç›¸å…³æŒ‡æ ‡
                )
                if ai_response and ai_response.get('success'):
                    analysis_content = ai_response.get('analysis', {})
                    if isinstance(analysis_content, str):
                        try:
                            analysis_content = json.loads(analysis_content)
                        except:
                            pass

                    if isinstance(analysis_content, dict):
                        detailed_analysis = analysis_content.get('detailed_analysis_text', detailed_analysis)
                        confidence = analysis_content.get('confidence', confidence)
                else:
                    logger.warning(
                        f"AI call for user growth opportunity insight failed: {ai_response.get('error') if ai_response else 'N/A'}")
            except Exception as e:
                logger.error(f"Error during AI call for user growth opportunity insight: {e}")

        return BusinessInsight(
            insight_id=insight_id,
            insight_type=InsightType.OPPORTUNITY_IDENTIFICATION,  # ä¹Ÿå¯ä»¥æ˜¯ USER_GROWTH_INSIGHT ä½†æ›´åæœºä¼š
            priority=priority,
            title=title,
            summary=summary,
            detailed_analysis=detailed_analysis,
            key_metrics=key_metrics,
            supporting_data={"daily_user_metrics_snapshot": daily_data},
            confidence_score=confidence,
            recommended_actions=[],  # ç”± _generate_actionable_recommendations (ç‰¹åˆ«æ˜¯ _generate_user_growth_actions) å¡«å……
            expected_impact="å·©å›ºå¹¶æ‰©å¤§ç”¨æˆ·å¢é•¿ä¼˜åŠ¿ï¼Œå¿«é€Ÿæå‡å¸‚åœºå æœ‰ç‡ã€‚",
            implementation_difficulty="ä¸­ç­‰",
            data_sources=[f"{api_name}" for api_name in
                          daily_data.get("api_source_names", ["/api/sta/day", "/api/sta/user_daily"])],
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="æœªæ¥1-3ä¸ªæœˆæŠ“ä½å¢é•¿çª—å£æœŸ"
        )



    async def _create_user_activation_insight(self, activation_rate: float,
                                              user_data_context: Dict[str, Any]) -> BusinessInsight:
        """
        (ç§æœ‰) åˆ›å»ºç”¨æˆ·æ¿€æ´»ç‡åä½çš„æ”¹è¿›æ´å¯Ÿã€‚
        activation_rate: è®¡ç®—å¾—å‡ºçš„ç”¨æˆ·æ¿€æ´»ç‡ (ä¾‹å¦‚ï¼šæ´»è·ƒç”¨æˆ·/æ€»æ³¨å†Œç”¨æˆ·)ã€‚
        user_data_context: ç›¸å…³çš„ç”¨æˆ·æ•°æ®ä½œä¸ºä¸Šä¸‹æ–‡ã€‚
        """
        insight_id = f"user_activation_concern_{datetime.now().strftime('%Y%m%d%H%M%S%f')}"
        rules = self.business_rules['user_growth']  # å‡è®¾æ¿€æ´»ç‡ç›¸å…³çš„è§„åˆ™ä¹Ÿåœ¨è¿™é‡Œ
        target_activation_rate = rules.get('activation_target',
                                           rules.get('retention_warning_threshold', 0.7))  # ä½¿ç”¨ä¸€ä¸ªæ¿€æ´»ç›®æ ‡æˆ–ç•™å­˜é˜ˆå€¼

        title = "ç”¨æˆ·æ¿€æ´»æ•ˆç‡æœ‰æå‡ç©ºé—´"
        summary = f"å½“å‰ç”¨æˆ·æ¿€æ´»ç‡çº¦ä¸º {activation_rate:.1%}ï¼Œå¯èƒ½ä½äºä¸šåŠ¡ç›®æ ‡ï¼ˆä¾‹å¦‚ {target_activation_rate:.0%}ï¼‰ã€‚å»ºè®®ä¼˜åŒ–æ–°ç”¨æˆ·å¼•å¯¼æµç¨‹å’Œæ—©æœŸç”¨æˆ·ä½“éªŒï¼Œä»¥æé«˜æ¿€æ´»è½¬åŒ–ã€‚"
        detailed_analysis = f"{summary} ä½æ¿€æ´»ç‡å¯èƒ½æ„å‘³ç€æ–°ç”¨æˆ·åœ¨æ³¨å†Œåæœªèƒ½å……åˆ†ä½“éªŒäº§å“ä»·å€¼ï¼Œå¯¼è‡´æµå¤±ã€‚éœ€è¦å…³æ³¨æ–°ç”¨æˆ·è·¯å¾„ï¼Œè¯†åˆ«æµå¤±èŠ‚ç‚¹ã€‚"
        key_metrics = {
            'ç”¨æˆ·æ¿€æ´»ç‡': activation_rate,
            'ç›®æ ‡æ¿€æ´»ç‡': target_activation_rate,
            'æ¿€æ´»ç‡å·®è·': target_activation_rate - activation_rate,
        }
        confidence = 0.78
        priority = InsightPriority.MEDIUM

        if self.claude_client:
            prompt = f"""
            å…¬å¸ç”¨æˆ·æ•°æ®æ˜¾ç¤ºï¼Œå½“å‰ç”¨æˆ·æ¿€æ´»ç‡ï¼ˆä¾‹å¦‚ï¼šæ´»è·ƒç”¨æˆ·/æ³¨å†Œç”¨æˆ· æˆ– é¦–æ¬¡è´­ä¹°ç”¨æˆ·/æ³¨å†Œç”¨æˆ·ï¼‰çº¦ä¸º {activation_rate:.1%}ï¼Œ
            è€Œä¸šåŠ¡ç›®æ ‡é€šå¸¸æœŸæœ›è¾¾åˆ° {target_activation_rate:.0%} æˆ–æ›´é«˜ã€‚

            è¯·ç”¨ä¸­æ–‡åˆ†æï¼š
            1. ç”¨æˆ·æ¿€æ´»ç‡åä½å¯èƒ½å­˜åœ¨å“ªäº›å¸¸è§åŸå› ï¼Ÿï¼ˆä¾‹å¦‚ï¼šæ–°ç”¨æˆ·å¼•å¯¼å¤æ‚ã€äº§å“ä»·å€¼æœªè¢«å¿«é€Ÿæ„ŸçŸ¥ã€æ—©æœŸä½“éªŒä¸ä½³ã€æ¨é€æ¶ˆæ¯ä¸å½“ç­‰ï¼‰
            2. ä¸ºäº†æå‡ç”¨æˆ·æ¿€æ´»ç‡ï¼Œå¯ä»¥ä»å“ªäº›æ–¹é¢ç€æ‰‹æ”¹è¿›ï¼Ÿï¼ˆä¾‹å¦‚ï¼šä¼˜åŒ–æ³¨å†Œåå¼•å¯¼ã€æä¾›æ–°æ‰‹ä»»åŠ¡æˆ–å¥–åŠ±ã€ä¸ªæ€§åŒ–å†…å®¹æ¨èã€ä¼˜åŒ–é¦–æ¬¡ä½¿ç”¨ä½“éªŒç­‰ï¼‰
            3. å»ºè®®å¦‚ä½•é€šè¿‡æ•°æ®åˆ†ææ¥å®šä½æ¿€æ´»æµç¨‹ä¸­çš„å…·ä½“ç“¶é¢ˆï¼Ÿ

            è¯·æä¾›ä¸€ä¸ªåŒ…å«ä»¥ä¸‹é”®çš„JSONå¯¹è±¡ï¼š
            "detailed_analysis_text": "å¯¹æ¿€æ´»ç‡åä½åŸå› å’Œæ”¹è¿›æ–¹å‘çš„è¯¦ç»†ä¸­æ–‡åˆ†æã€‚",
            "activation_improvement_strategies": ["æå‡æ¿€æ´»ç‡ç­–ç•¥1", "ç­–ç•¥2"],
            "bottleneck_analysis_suggestions": ["å®šä½ç“¶é¢ˆçš„æ•°æ®åˆ†ææ–¹æ³•1", "æ–¹æ³•2"]
            """
            try:
                ai_response = await self.claude_client.analyze_complex_query(
                    query=prompt,
                    context={"user_activation_data": user_data_context}  # user_data_context åº”åŒ…å«è®¡ç®—æ¿€æ´»ç‡çš„åŸå§‹æ•°æ®
                )
                if ai_response and ai_response.get('success'):
                    analysis_content = ai_response.get('analysis', {})
                    if isinstance(analysis_content, str):
                        try:
                            analysis_content = json.loads(analysis_content)
                        except:
                            pass

                    if isinstance(analysis_content, dict):
                        detailed_analysis = analysis_content.get('detailed_analysis_text', detailed_analysis)
                        confidence = analysis_content.get('confidence', confidence)
                else:
                    logger.warning(
                        f"AI call for user activation insight failed: {ai_response.get('error') if ai_response else 'N/A'}")
            except Exception as e:
                logger.error(f"Error during AI call for user activation insight: {e}")

        return BusinessInsight(
            insight_id=insight_id,
            insight_type=InsightType.USER_GROWTH_INSIGHT,  # ä¹Ÿå¯ä»¥æ˜¯ OPERATIONAL_EFFICIENCY
            priority=priority,
            title=title,
            summary=summary,
            detailed_analysis=detailed_analysis,
            key_metrics=key_metrics,
            supporting_data={"user_conversion_metrics": user_data_context},
            confidence_score=confidence,
            recommended_actions=[],  # ç”± _generate_actionable_recommendations (ç‰¹åˆ«æ˜¯ _generate_user_growth_actions) å¡«å……
            expected_impact="æé«˜æ–°ç”¨æˆ·å‘æ´»è·ƒ/ä»˜è´¹ç”¨æˆ·çš„è½¬åŒ–ï¼Œæå‡ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼ã€‚",
            implementation_difficulty="ä¸­ç­‰",
            data_sources=[f"{api_name}" for api_name in
                          user_data_context.get("api_source_names", ["/api/sta/user_daily", "/api/sta/user"])],
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="æœªæ¥1-2ä¸ªæœˆå†…ä¼˜åŒ–æ¿€æ´»æµç¨‹"
        )
    async def _generate_generic_actions(self, insight: BusinessInsight,
                                        processed_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        (ç§æœ‰) ä¸ºé€šç”¨ç±»å‹çš„æ´å¯Ÿç”Ÿæˆæ™®é€‚æ€§çš„è¡ŒåŠ¨å»ºè®®ã€‚
        """
        actions: List[Dict[str, Any]] = []
        action_prefix = f"generic_act_{insight.insight_id[-6:]}"

        logger.info(f"Generating generic actions for insight: {insight.title} (Type: {insight.insight_type.value})")

        if not self.claude_client:
            logger.warning("ClaudeClient not available for generating generic actions.")
            actions.append({
                'action_id': f"{action_prefix}_follow_up", 'title': "è·Ÿè¿›æ­¤é¡¹æ´å¯Ÿ",
                'description': f"é’ˆå¯¹æ´å¯Ÿ '{insight.title}' è¿›è¡Œè¿›ä¸€æ­¥åˆ†æï¼Œå¹¶æ ¹æ®å…·ä½“æƒ…å†µåˆ¶å®šåç»­è®¡åˆ’ã€‚",
                'action_type': ActionType.SHORT_TERM_PLAN.value, 'priority': insight.priority.value
            })
            return actions

        prompt_context = {
            "insight_title": insight.title,
            "insight_summary": insight.summary,
            "insight_type": insight.insight_type.value,
            "insight_priority": insight.priority.value,
            "key_insight_metrics": insight.key_metrics,
            "detailed_insight_analysis": insight.detailed_analysis
        }

        prompt = f"""
        æ‚¨æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä¸šåŠ¡ç­–ç•¥é¡¾é—®ã€‚ä»¥ä¸‹æ˜¯ä¸€é¡¹ä¸šåŠ¡æ´å¯Ÿï¼š
        æ´å¯Ÿæ ‡é¢˜: "{insight.title}"
        æ´å¯Ÿç±»å‹: {insight.insight_type.value}
        æ´å¯Ÿæ‘˜è¦: "{insight.summary}"
        ä¼˜å…ˆçº§: {insight.priority.value}
        æ”¯æŒè¯¥æ´å¯Ÿçš„å…³é”®æŒ‡æ ‡: {json.dumps(insight.key_metrics, ensure_ascii=False, indent=2, cls=CustomJSONEncoder)}
        ç³»ç»Ÿå¯¹è¯¥æ´å¯Ÿçš„è¯¦ç»†åˆ†æå†…å®¹:
        ---
        {insight.detailed_analysis}
        ---

        åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œè¯·ä¸ºè¿™é¡¹æ´å¯Ÿæå‡º 1-2 æ¡æœ€ç›¸å…³çš„ã€å…·æœ‰æ™®éé€‚ç”¨æ€§çš„è¡ŒåŠ¨å»ºè®®ã€‚
        å¯¹äºæ¯æ¡å»ºè®®ï¼Œè¯·æä¾›ï¼š
        1.  `action_title`: å»ºè®®çš„ç®€æ´æ ‡é¢˜ã€‚
        2.  `action_description`: å»ºè®®çš„è¯¦ç»†æè¿°ã€‚
        3.  `action_type`: ï¼ˆä¾‹å¦‚ï¼š"monitoring", "short_term_plan", "medium_term_plan"ï¼‰ã€‚
        4.  `general_expected_outcome`: æ‰§è¡Œæ­¤å»ºè®®é€šå¸¸æœŸæœ›è¾¾åˆ°ä»€ä¹ˆç±»å‹çš„ç»“æœã€‚

        è¯·ä»¥JSONæ•°ç»„çš„æ ¼å¼è¿”å›è¿™äº›å»ºè®®ã€‚
        """
        try:
            ai_response = await self.claude_client.analyze_complex_query(query=prompt, context=prompt_context)
            if ai_response and ai_response.get('success'):
                response_content = ai_response.get('analysis', ai_response.get('response'))
                if isinstance(response_content, str):
                    try:
                        response_content = json.loads(response_content)
                    except json.JSONDecodeError:
                        logger.error(f"AI response for generic actions is not valid JSON: {response_content[:200]}")

                if isinstance(response_content, list):
                    for idx, action_data in enumerate(response_content):
                        if isinstance(action_data, dict):
                            actions.append({
                                'action_id': f"{action_prefix}_{idx}",
                                'action_type': ActionType(
                                    action_data.get('action_type', ActionType.MONITORING.value)).value,
                                'title': action_data.get('action_title', f"é€šç”¨å»ºè®® {idx + 1}"),
                                'description': action_data.get('action_description', "æ ¹æ®AIåˆ†æçš„é€šç”¨å»ºè®®ã€‚"),
                                'priority': insight.priority.value,  # ç»§æ‰¿æ´å¯Ÿä¼˜å…ˆçº§
                                'timeline': "æ ¹æ®ä¸šåŠ¡èŠ‚å¥å®‰æ’",
                                'responsible_party': "ç›¸å…³ä¸šåŠ¡å›¢é˜Ÿ",
                                'required_resources': ["ä¸šåŠ¡åˆ†æ", "å›¢é˜Ÿè®¨è®º"],
                                'success_metrics': [action_data.get('general_expected_outcome', "ç›¸å…³æŒ‡æ ‡æ”¹å–„")],
                                'expected_outcome': action_data.get('general_expected_outcome',
                                                                    "ä¸šåŠ¡æµç¨‹æˆ–æŒ‡æ ‡å¾—åˆ°ä¼˜åŒ–"),
                                'potential_risks': ["æ‰§è¡Œä¸åˆ°ä½å¯èƒ½å½±å“æ•ˆæœ"]
                            })
            else:
                logger.warning(
                    f"AI call for generic actions failed or no success: {ai_response.get('error') if ai_response else 'N/A'}")
        except Exception as e:
            logger.error(f"Error generating generic actions with AI: {e}")

        if not actions:  # å¦‚æœAIè°ƒç”¨å¤±è´¥æˆ–æœªè¿”å›æœ‰æ•ˆå†…å®¹
            actions.append({
                'action_id': f"{action_prefix}_default_discuss", 'title': "è®¨è®ºå¹¶åˆ¶å®šè¡ŒåŠ¨è®¡åˆ’",
                'description': f"é’ˆå¯¹æ´å¯Ÿ '{insight.title}' ({insight.summary[:50]}...)ï¼Œç»„ç»‡ç›¸å…³å›¢é˜Ÿè¿›è¡Œè®¨è®ºï¼Œè¯„ä¼°å…¶å½±å“å¹¶åˆ¶å®šå…·ä½“çš„åç»­è¡ŒåŠ¨è®¡åˆ’ã€‚",
                'action_type': ActionType.SHORT_TERM_PLAN.value, 'priority': insight.priority.value,
                'timeline': "1å‘¨å†…", 'responsible_party': "ç›¸å…³è´Ÿè´£äºº",
                'expected_outcome': "æ˜ç¡®æ­¤æ´å¯Ÿçš„åº”å¯¹ç­–ç•¥"
            })
        return actions
    def _extract_key_metrics_for_insight(self, analysis_result_item: Any, context_description: str = "") -> Dict[
        str, Any]:
        """
        (ç§æœ‰è¾…åŠ©) ä»å•ä¸ªåˆ†æç»“æœé¡¹ä¸­æå–å…³é”®æŒ‡æ ‡ï¼Œç”¨äºç‰¹å®šæ´å¯Ÿã€‚
        è¿™ä¸ªæ–¹æ³•ä¸ Orchestrator ä¸­çš„ _extract_key_metrics åŠŸèƒ½ç±»ä¼¼ä½†ä½œç”¨åŸŸæ›´å°ã€‚
        """
        metrics: Dict[str, Any] = {}
        if not analysis_result_item:
            return metrics

        data_to_search: Optional[Dict[str, Any]] = None
        if hasattr(analysis_result_item, 'to_dict') and callable(analysis_result_item.to_dict):
            data_to_search = analysis_result_item.to_dict()
        elif hasattr(analysis_result_item, '__dict__'):
            data_to_search = analysis_result_item.__dict__
        elif isinstance(analysis_result_item, dict):
            data_to_search = analysis_result_item

        if not data_to_search:
            return metrics

        # å°è¯•ä»å¸¸è§çš„æŒ‡æ ‡å®¹å™¨é”®ä¸­æå–
        metric_container_keys = ['key_metrics', 'metrics', 'main_prediction', 'data']
        for container_key in metric_container_keys:
            if container_key in data_to_search and isinstance(data_to_search[container_key], dict):
                for k, v in data_to_search[container_key].items():
                    # ç®€å•æå–ï¼Œä¸åŠ å¤æ‚å‰ç¼€ï¼Œå› ä¸ºè¿™æ˜¯é’ˆå¯¹å•ä¸ªæ´å¯Ÿçš„ä¸Šä¸‹æ–‡
                    # å¯ä»¥æ ¹æ® context_description è¿›ä¸€æ­¥ç­›é€‰ç›¸å…³æŒ‡æ ‡
                    if isinstance(v, (str, int, float, bool)):  # åªå–ç®€å•ç±»å‹ä½œä¸ºæŒ‡æ ‡å€¼
                        metrics[k] = v
                if metrics: break  # å¦‚æœåœ¨ä¸€ä¸ªå®¹å™¨ä¸­æ‰¾åˆ°ï¼Œå¯èƒ½å°±å¤Ÿäº†

        logger.debug(f"Extracted {len(metrics)} key metrics for insight context '{context_description}'.")
        return metrics

    async def _create_data_anomaly_risk_insight(self, anomalies: List[Dict[str, Any]]) -> BusinessInsight:
        """
        (ç§æœ‰) åˆ›å»ºæ•°æ®å¼‚å¸¸é£é™©æ´å¯Ÿã€‚
        anomalies: é€šå¸¸æ¥è‡ª FinancialDataAnalyzer.detect_anomalies çš„ç»“æœåˆ—è¡¨ã€‚
                  æ¯ä¸ª anomaly å­—å…¸åº”åŒ…å« 'metric', 'date', 'actual_value', 'expected_value', 'severity' ç­‰ã€‚
        """
        insight_id = f"data_anomaly_risk_{datetime.now().strftime('%Y%m%d%H%M%S%f')}"
        title = "æ•°æ®å¼‚å¸¸æ³¢åŠ¨é£é™©æç¤º"

        # æ€»ç»“å¼‚å¸¸æƒ…å†µ
        num_anomalies = len(anomalies)
        critical_anomalies_count = sum(
            1 for anom in anomalies if anom.get('severity', '').lower() in ['high', 'critical'])
        affected_metrics = list(set(anom.get('metric', 'æœªçŸ¥æŒ‡æ ‡') for anom in anomalies))

        summary = f"æ£€æµ‹åˆ° {num_anomalies} ä¸ªæ•°æ®ç‚¹å­˜åœ¨å¼‚å¸¸æ³¢åŠ¨ï¼Œå…¶ä¸­ {critical_anomalies_count} ä¸ªä¸ºé«˜é£é™©æˆ–ä¸¥é‡å¼‚å¸¸ã€‚ä¸»è¦å½±å“æŒ‡æ ‡åŒ…æ‹¬ï¼š{', '.join(affected_metrics[:3])}ã€‚"
        detailed_analysis = f"{summary} éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥è¿™äº›å¼‚å¸¸æ•°æ®ç‚¹äº§ç”Ÿçš„åŸå› ï¼Œè¯„ä¼°å…¶å¯¹ä¸šåŠ¡å†³ç­–çš„æ½œåœ¨å½±å“ã€‚"
        key_metrics = {
            'æ£€æµ‹åˆ°çš„å¼‚å¸¸æ€»æ•°': num_anomalies,
            'é«˜é£é™©/ä¸¥é‡å¼‚å¸¸æ•°': critical_anomalies_count,
            'å—å½±å“æŒ‡æ ‡ç¤ºä¾‹': affected_metrics[:3]
        }
        confidence = 0.80 + (0.10 if critical_anomalies_count > 0 else 0)  # å¦‚æœæœ‰ä¸¥é‡å¼‚å¸¸ï¼Œç½®ä¿¡åº¦æ›´é«˜
        priority = InsightPriority.HIGH if critical_anomalies_count > 0 else InsightPriority.MEDIUM

        if self.claude_client and anomalies:
            # é€‰å–å‰å‡ ä¸ªæœ€ä¸¥é‡çš„å¼‚å¸¸è¿›è¡Œåˆ†æ
            anomalies_for_ai = sorted(anomalies, key=lambda x: (
            x.get('severity', 'low') == 'critical', x.get('severity', 'low') == 'high',
            -float(x.get('deviation_score', 0))), reverse=True)[:3]

            prompt = f"""
            é‡‘èæ•°æ®åˆ†æç³»ç»Ÿæ£€æµ‹åˆ°ä»¥ä¸‹æ•°æ®å¼‚å¸¸ç‚¹ï¼š
            {json.dumps(anomalies_for_ai, ensure_ascii=False, indent=2, cls=CustomJSONEncoder)}

            è¯·ç”¨ä¸­æ–‡åˆ†æï¼š
            1. è¿™äº›å¼‚å¸¸æ•°æ®å¯èƒ½å…±åŒæŒ‡å‘çš„æ½œåœ¨ä¸šåŠ¡é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆä¾‹å¦‚ï¼šæ•°æ®é‡‡é›†é”™è¯¯ã€æ¬ºè¯ˆè¡Œä¸ºã€å¸‚åœºçªå˜ã€ç³»ç»Ÿæ•…éšœç­‰ï¼‰
            2. åŸºäºè¿™äº›å¼‚å¸¸ï¼Œæœ€éœ€è¦å…³æ³¨çš„é£é™©ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ
            3. ä¸ºäº†ç¡®è®¤å¼‚å¸¸åŸå› å¹¶è¯„ä¼°å½±å“ï¼Œå»ºè®®ç«‹å³é‡‡å–å“ªäº›è°ƒæŸ¥æ­¥éª¤ï¼Ÿ
            4. ç®€è¦è¯´æ˜è¿™äº›å¼‚å¸¸å¦‚æœå±å®ï¼Œå¯èƒ½å¯¹ä¸šåŠ¡å†³ç­–å¸¦æ¥å“ªäº›è¯¯å¯¼ã€‚

            è¯·æä¾›ä¸€ä¸ªåŒ…å«ä»¥ä¸‹é”®çš„JSONå¯¹è±¡ï¼š
            "detailed_analysis_text": "å¯¹å¼‚å¸¸çš„ç»¼åˆåˆ†æå’Œæ½œåœ¨åŸå› æ¨æµ‹ã€‚",
            "primary_risks_identified": ["ä¸»è¦é£é™©ç‚¹1", "é£é™©ç‚¹2"],
            "investigation_steps_suggested": ["è°ƒæŸ¥æ­¥éª¤1", "æ­¥éª¤2"]
            """
            try:
                ai_response = await self.claude_client.analyze_complex_query(
                    query=prompt,
                    context={"detected_anomalies_sample": anomalies_for_ai}
                )
                if ai_response and ai_response.get('success'):
                    analysis_content = ai_response.get('analysis', {})
                    if isinstance(analysis_content, str):
                        try:
                            analysis_content = json.loads(analysis_content)
                        except:
                            pass

                    if isinstance(analysis_content, dict):
                        detailed_analysis = analysis_content.get('detailed_analysis_text', detailed_analysis)
                        # Recommended actions can be derived from investigation_steps_suggested
                        confidence = analysis_content.get('confidence', confidence)
                else:
                    logger.warning(
                        f"AI call for data anomaly risk insight failed: {ai_response.get('error') if ai_response else 'N/A'}")
            except Exception as e:
                logger.error(f"Error during AI call for data anomaly risk insight: {e}")

        return BusinessInsight(
            insight_id=insight_id,
            insight_type=InsightType.RISK_WARNING,
            priority=priority,
            title=title,
            summary=summary,
            detailed_analysis=detailed_analysis,
            key_metrics=key_metrics,
            supporting_data={"anomalies_detected_sample": anomalies[:5]},  # åªå–å‰5ä¸ªå¼‚å¸¸ä½œä¸ºæ”¯æŒæ•°æ®
            confidence_score=confidence,
            recommended_actions=[],
            # ç”± _generate_actionable_recommendations (ç‰¹åˆ«æ˜¯ _generate_risk_mitigation_actions) å¡«å……
            expected_impact="åŠæ—¶å‘ç°å’Œå¤„ç†æ•°æ®å¼‚å¸¸ï¼Œå¯é¿å…åŸºäºé”™è¯¯æ•°æ®çš„å†³ç­–ï¼Œé™ä½è¿è¥é£é™©ã€‚",
            implementation_difficulty="ä¸­ç­‰",
            data_sources=["Varies (based on anomaly source)"],  # éœ€è¦ä»anomalieså¯¹è±¡ä¸­æå–
            analysis_timestamp=datetime.now().isoformat(),
            applicable_timeframe="éœ€ç«‹å³å…³æ³¨å’Œè°ƒæŸ¥"
        )



    async def _generate_risk_mitigation_actions(self, insight: BusinessInsight,
                                                processed_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆé£é™©ç¼“è§£è¡ŒåŠ¨"""
        actions = []

        if insight.priority == InsightPriority.CRITICAL:
            # ç´§æ€¥é£é™©æ§åˆ¶
            actions.append({
                'action_id': f"emergency_control_{datetime.now().strftime('%H%M%S')}",
                'action_type': ActionType.IMMEDIATE_ACTION,
                'title': "å¯åŠ¨ç´§æ€¥é£é™©æ§åˆ¶",
                'description': "ç«‹å³é™åˆ¶å¤§é¢å‡ºé‡‘ï¼Œå¯åŠ¨é£é™©åº”æ€¥é¢„æ¡ˆ",
                'timeline': "ç«‹å³æ‰§è¡Œ",
                'responsible_party': "é£æ§éƒ¨é—¨",
                'priority': InsightPriority.CRITICAL,
                'success_metrics': ["å‡ºé‡‘é‡æ§åˆ¶åœ¨å®‰å…¨èŒƒå›´", "æµåŠ¨æ€§æ¯”ä¾‹æå‡åˆ°å®‰å…¨æ°´å¹³"]
            })

            actions.append({
                'action_id': f"emergency_funding_{datetime.now().strftime('%H%M%S')}",
                'action_type': ActionType.IMMEDIATE_ACTION,
                'title': "ç´§æ€¥èµ„é‡‘ç­¹æª",
                'description': "å¯åŠ¨ç´§æ€¥èèµ„æ¸ é“ï¼Œç¡®ä¿çŸ­æœŸæµåŠ¨æ€§",
                'timeline': "24å°æ—¶å†…",
                'responsible_party': "è´¢åŠ¡éƒ¨é—¨",
                'priority': InsightPriority.CRITICAL,
                'success_metrics': ["è·å¾—åº”æ€¥èµ„é‡‘", "æµåŠ¨æ€§å¤©æ•°å»¶é•¿è‡³30å¤©ä»¥ä¸Š"]
            })

        else:
            # å¸¸è§„é£é™©ç®¡ç†
            actions.append({
                'action_id': f"risk_monitoring_{datetime.now().strftime('%H%M%S')}",
                'action_type': ActionType.SHORT_TERM_PLAN,
                'title': "åŠ å¼ºé£é™©ç›‘æ§",
                'description': "å»ºç«‹æ—¥åº¦é£é™©ç›‘æ§æœºåˆ¶ï¼Œè®¾ç½®é¢„è­¦é˜ˆå€¼",
                'timeline': "1å‘¨å†…å»ºç«‹",
                'responsible_party': "é£æ§å›¢é˜Ÿ",
                'priority': insight.priority,
                'success_metrics': ["é£é™©ç›‘æ§ä½“ç³»å»ºç«‹", "é¢„è­¦æœºåˆ¶æ­£å¸¸è¿è¡Œ"]
            })

        return actions

    async def _generate_opportunity_capture_actions(self, insight: BusinessInsight,
                                                    processed_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæœºä¼šæ•è·è¡ŒåŠ¨"""
        actions = []

        if insight.insight_type == InsightType.OPPORTUNITY_IDENTIFICATION:
            # å¤æŠ•ç‡æå‡è¡ŒåŠ¨
            if 'reinvestment' in insight.title.lower():
                actions.append({
                    'action_id': f"reinvest_promotion_{datetime.now().strftime('%H%M%S')}",
                    'action_type': ActionType.SHORT_TERM_PLAN,
                    'title': "å¤æŠ•æ¿€åŠ±æ´»åŠ¨",
                    'description': "æ¨å‡ºå¤æŠ•å¥–åŠ±è®¡åˆ’ï¼Œæé«˜åˆ°æœŸèµ„é‡‘ç•™å­˜ç‡",
                    'timeline': "2å‘¨å†…è®¾è®¡å¹¶å®æ–½",
                    'responsible_party': "äº§å“è¿è¥éƒ¨",
                    'priority': insight.priority,
                    'success_metrics': ["å¤æŠ•ç‡æå‡5%", "èµ„é‡‘ç•™å­˜ç‡æ”¹å–„"]
                })

                actions.append({
                    'action_id': f"expiry_communication_{datetime.now().strftime('%H%M%S')}",
                    'action_type': ActionType.MEDIUM_TERM_PLAN,
                    'title': "åˆ°æœŸæé†’ä¼˜åŒ–",
                    'description': "ä¼˜åŒ–åˆ°æœŸæé†’æœºåˆ¶ï¼Œå¢åŠ å¤æŠ•å¼•å¯¼",
                    'timeline': "1ä¸ªæœˆå†…å®Œæˆ",
                    'responsible_party': "æŠ€æœ¯å¼€å‘éƒ¨",
                    'priority': InsightPriority.MEDIUM,
                    'success_metrics': ["æé†’è§¦è¾¾ç‡95%", "å¤æŠ•è½¬åŒ–ç‡æå‡"]
                })

        return actions

    async def _generate_expiry_management_actions(self, insight: BusinessInsight,
                                                  processed_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆåˆ°æœŸç®¡ç†è¡ŒåŠ¨"""
        actions = []

        # èµ„é‡‘å‡†å¤‡è¡ŒåŠ¨
        actions.append({
            'action_id': f"cash_preparation_{datetime.now().strftime('%H%M%S')}",
            'action_type': ActionType.SHORT_TERM_PLAN,
            'title': "å¤§é¢åˆ°æœŸèµ„é‡‘å‡†å¤‡",
            'description': "æå‰3å¤©å‡†å¤‡å¤§é¢åˆ°æœŸæ‰€éœ€èµ„é‡‘ï¼Œç¡®ä¿å……è¶³æµåŠ¨æ€§",
            'timeline': "åˆ°æœŸå‰3å¤©",
            'responsible_party': "è´¢åŠ¡éƒ¨é—¨",
            'priority': insight.priority,
            'success_metrics': ["èµ„é‡‘å‡†å¤‡å……è¶³", "åˆ°æœŸå…‘ä»˜100%"]
        })

        # åˆ°æœŸåˆ†å¸ƒä¼˜åŒ–
        actions.append({
            'action_id': f"expiry_optimization_{datetime.now().strftime('%H%M%S')}",
            'action_type': ActionType.MEDIUM_TERM_PLAN,
            'title': "ä¼˜åŒ–åˆ°æœŸåˆ†å¸ƒ",
            'description': "è°ƒæ•´äº§å“æœŸé™è®¾è®¡ï¼Œåˆ†æ•£åˆ°æœŸé›†ä¸­åº¦é£é™©",
            'timeline': "1ä¸ªæœˆå†…è°ƒæ•´",
            'responsible_party': "äº§å“è®¾è®¡éƒ¨",
            'priority': InsightPriority.MEDIUM,
            'success_metrics': ["å•æ—¥åˆ°æœŸå æ¯”é™ä½è‡³30%ä»¥ä¸‹", "åˆ°æœŸåˆ†å¸ƒæ›´å‡åŒ€"]
        })

        return actions

    # ============= æ´å¯Ÿå¤„ç†å’ŒéªŒè¯ =============

    async def _preprocess_analysis_results(self, analysis_results: List[Any]) -> Dict[str, Any]:
        """é¢„å¤„ç†åˆ†æç»“æœ"""
        processed_data = {
            'system_data': {},
            'daily_trends': {},
            'user_statistics': {},
            'product_data': {},
            'expiry_analysis': {},
            'detected_anomalies': []
        }

        try:
            for result in analysis_results:
                if hasattr(result, 'analysis_type'):
                    if result.analysis_type.value == 'trend_analysis':
                        processed_data['daily_trends'] = {
                            'growth_rate': result.metrics.get('growth_rate', 0),
                            'volatility': result.metrics.get('volatility', 0),
                            'trend_direction': result.metrics.get('trend_direction', 'stable'),
                            'avg_daily_outflow': result.metrics.get('mean_value', 0)
                        }
                    elif result.analysis_type.value == 'anomaly_detection':
                        processed_data['detected_anomalies'] = result.anomalies

                # å¤„ç†å…¶ä»–æ•°æ®æº
                if hasattr(result, 'supporting_data'):
                    if 'ç³»ç»Ÿ' in str(result.supporting_data) or 'system' in str(result.supporting_data):
                        processed_data['system_data'].update(result.supporting_data)

        except Exception as e:
            logger.error(f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {str(e)}")

        return processed_data

    async def _identify_business_patterns(self, processed_data: Dict[str, Any]) -> Dict[str, Any]:
        """è¯†åˆ«ä¸šåŠ¡æ¨¡å¼"""
        patterns = {
            'growth_pattern': 'stable',
            'risk_level': 'low',
            'user_engagement': 'normal',
            'cash_flow_health': 'good'
        }

        try:
            # åˆ†æå¢é•¿æ¨¡å¼
            daily_trends = processed_data.get('daily_trends', {})
            growth_rate = daily_trends.get('growth_rate', 0)

            if growth_rate > 0.1:
                patterns['growth_pattern'] = 'high_growth'
            elif growth_rate < -0.05:
                patterns['growth_pattern'] = 'declining'

            # åˆ†æé£é™©æ°´å¹³
            volatility = daily_trends.get('volatility', 0)
            if volatility > 0.2:
                patterns['risk_level'] = 'high'
            elif volatility > 0.1:
                patterns['risk_level'] = 'medium'

            # åˆ†æç°é‡‘æµå¥åº·åº¦
            system_data = processed_data.get('system_data', {})
            if system_data:
                total_inflow = float(system_data.get('æ€»å…¥é‡‘', 0))
                total_outflow = float(system_data.get('æ€»å‡ºé‡‘', 0))

                if total_inflow > 0:
                    outflow_ratio = total_outflow / total_inflow
                    if outflow_ratio > 0.8:
                        patterns['cash_flow_health'] = 'concerning'
                    elif outflow_ratio > 0.6:
                        patterns['cash_flow_health'] = 'moderate'

        except Exception as e:
            logger.error(f"ä¸šåŠ¡æ¨¡å¼è¯†åˆ«å¤±è´¥: {str(e)}")

        return patterns

    def _prioritize_and_deduplicate_insights(self, insights: List[BusinessInsight]) -> List[BusinessInsight]:
        """ä¼˜å…ˆçº§æ’åºå’Œå»é‡"""
        if not insights:
            return []

        # å»é‡ - åŸºäºæ´å¯Ÿç±»å‹å’Œå…³é”®æŒ‡æ ‡
        unique_insights = {}
        for insight in insights:
            key = f"{insight.insight_type.value}_{insight.title}"
            if key not in unique_insights or insight.priority.value == 'critical':
                unique_insights[key] = insight

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        priority_order = {'critical': 0, 'high': 1, 'medium': 2, 'low': 3}
        sorted_insights = sorted(
            unique_insights.values(),
            key=lambda x: (priority_order.get(x.priority.value, 4), -x.confidence_score)
        )

        return sorted_insights

    async def _validate_insights_quality(self, insights: List[BusinessInsight]) -> List[BusinessInsight]:
        """éªŒè¯æ´å¯Ÿè´¨é‡"""
        validated_insights = []

        for insight in insights:
            # åŸºç¡€è´¨é‡æ£€æŸ¥
            if self._is_insight_valid(insight):
                # è°ƒæ•´ç½®ä¿¡åº¦
                adjusted_confidence = self._adjust_confidence_score(insight)
                insight.confidence_score = adjusted_confidence

                # åªä¿ç•™é«˜è´¨é‡æ´å¯Ÿ
                if adjusted_confidence >= 0.6:
                    validated_insights.append(insight)

        return validated_insights

    def _is_insight_valid(self, insight: BusinessInsight) -> bool:
        """æ£€æŸ¥æ´å¯Ÿæ˜¯å¦æœ‰æ•ˆ"""
        return (
                insight.title and
                insight.summary and
                insight.confidence_score > 0.5 and
                insight.key_metrics
        )

    def _adjust_confidence_score(self, insight: BusinessInsight) -> float:
        """è°ƒæ•´ç½®ä¿¡åº¦è¯„åˆ†"""
        base_confidence = insight.confidence_score

        # åŸºäºæ•°æ®æºæ•°é‡è°ƒæ•´
        data_source_bonus = min(0.1, len(insight.data_sources) * 0.02)

        # åŸºäºå…³é”®æŒ‡æ ‡æ•°é‡è°ƒæ•´
        metrics_bonus = min(0.1, len(insight.key_metrics) * 0.02)

        # åŸºäºAIåˆ†æè°ƒæ•´
        ai_bonus = 0.05 if self.claude_client else 0

        adjusted_confidence = min(0.95, base_confidence + data_source_bonus + metrics_bonus + ai_bonus)

        return adjusted_confidence

    # ============= ç»Ÿè®¡å’Œå·¥å…·æ–¹æ³• =============

    def _count_insights_by_priority(self, insights: List[BusinessInsight]) -> Dict[str, int]:
        """ç»Ÿè®¡å„ä¼˜å…ˆçº§æ´å¯Ÿæ•°é‡"""
        counts = {'critical': 0, 'high': 0, 'medium': 0, 'low': 0}

        for insight in insights:
            priority = insight.priority.value
            if priority in counts:
                counts[priority] += 1

        return counts

    def _extract_data_sources(self, processed_data: Dict[str, Any]) -> List[str]:
        """æå–ä½¿ç”¨çš„æ•°æ®æº"""
        sources = set()

        # æ ¹æ®processed_dataçš„å†…å®¹æ¨æ–­æ•°æ®æº
        if processed_data.get('system_data'):
            sources.add('/api/sta/system')
        if processed_data.get('daily_trends'):
            sources.add('/api/sta/day')
        if processed_data.get('product_data'):
            sources.add('/api/sta/product')
        if processed_data.get('expiry_analysis'):
            sources.add('/api/sta/product_end_interval')

        return list(sources)

    def _calculate_confidence_distribution(self, insights: List[BusinessInsight]) -> Dict[str, float]:
        """è®¡ç®—ç½®ä¿¡åº¦åˆ†å¸ƒ"""
        if not insights:
            return {'high': 0, 'medium': 0, 'low': 0}

        high_confidence = sum(1 for i in insights if i.confidence_score >= 0.8)
        medium_confidence = sum(1 for i in insights if 0.6 <= i.confidence_score < 0.8)
        low_confidence = sum(1 for i in insights if i.confidence_score < 0.6)

        total = len(insights)

        return {
            'high': high_confidence / total,
            'medium': medium_confidence / total,
            'low': low_confidence / total
        }

    def _update_insight_stats(self, insights: List[BusinessInsight]):
        """æ›´æ–°æ´å¯Ÿç»Ÿè®¡ä¿¡æ¯"""
        self.insight_stats['total_insights_generated'] += len(insights)

        for insight in insights:
            insight_type = insight.insight_type.value
            if insight_type not in self.insight_stats['insights_by_type']:
                self.insight_stats['insights_by_type'][insight_type] = 0
            self.insight_stats['insights_by_type'][insight_type] += 1

            if insight.recommended_actions:
                self.insight_stats['actionable_insights'] += 1

            if insight.priority == InsightPriority.CRITICAL:
                self.insight_stats['critical_insights'] += 1

        # æ›´æ–°å¹³å‡ç½®ä¿¡åº¦
        if insights:
            total_confidence = sum(i.confidence_score for i in insights)
            avg_confidence = total_confidence / len(insights)

            current_total = self.insight_stats['total_insights_generated']
            current_avg = self.insight_stats['avg_confidence_score']

            new_avg = ((current_avg * (current_total - len(insights))) + total_confidence) / current_total
            self.insight_stats['avg_confidence_score'] = new_avg

    # ============= å¤–éƒ¨æ¥å£æ–¹æ³• =============

    def get_insight_stats(self) -> Dict[str, Any]:
        """è·å–æ´å¯Ÿç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        return self.insight_stats.copy()

    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        return {
            "status": "healthy",
            "ai_clients": {
                "claude_available": self.claude_client is not None,
                "gpt_available": self.gpt_client is not None
            },
            "business_rules_loaded": bool(self.business_rules),
            "insight_stats": self.insight_stats,
            "timestamp": datetime.now().isoformat()
        }


# ============= å·¥å‚å‡½æ•° =============

def create_insight_generator(claude_client=None, gpt_client=None) -> InsightGenerator:
    """
    åˆ›å»ºæ´å¯Ÿç”Ÿæˆå™¨å®ä¾‹

    Args:
        claude_client: Claudeå®¢æˆ·ç«¯å®ä¾‹
        gpt_client: GPTå®¢æˆ·ç«¯å®ä¾‹

    Returns:
        InsightGenerator: æ´å¯Ÿç”Ÿæˆå™¨å®ä¾‹
    """
    return InsightGenerator(claude_client, gpt_client)


# ============= ä½¿ç”¨ç¤ºä¾‹ =============

async def main():
    """ä½¿ç”¨ç¤ºä¾‹"""

    # åˆ›å»ºæ´å¯Ÿç”Ÿæˆå™¨
    generator = create_insight_generator()

    print("=== ä¸šåŠ¡æ´å¯Ÿç”Ÿæˆå™¨æµ‹è¯• ===")

    # æ¨¡æ‹Ÿåˆ†æç»“æœæ•°æ®
    mock_analysis_results = []

    # ç”Ÿæˆç»¼åˆæ´å¯Ÿ
    insights, metadata = await generator.generate_comprehensive_insights(
        analysis_results=mock_analysis_results,
        user_context=None,
        focus_areas=['financial_health', 'risk_management']
    )

    print(f"ç”Ÿæˆæ´å¯Ÿæ•°é‡: {len(insights)}")
    print(f"å¤„ç†æ—¶é—´: {metadata.get('generation_time', 0):.2f}ç§’")

    # æ˜¾ç¤ºæ´å¯Ÿè¯¦æƒ…
    for i, insight in enumerate(insights[:3], 1):
        print(f"\n=== æ´å¯Ÿ {i} ===")
        print(f"æ ‡é¢˜: {insight.title}")
        print(f"ä¼˜å…ˆçº§: {insight.priority.value}")
        print(f"æ‘˜è¦: {insight.summary}")
        print(f"ç½®ä¿¡åº¦: {insight.confidence_score:.2f}")
        print(f"æ•°æ®æº: {insight.data_sources}")
        print(f"è¡ŒåŠ¨å»ºè®®æ•°: {len(insight.recommended_actions)}")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = generator.get_insight_stats()
    print(f"\n=== ç»Ÿè®¡ä¿¡æ¯ ===")
    print(f"æ€»ç”Ÿæˆæ´å¯Ÿ: {stats['total_insights_generated']}")
    print(f"å¯æ‰§è¡Œæ´å¯Ÿ: {stats['actionable_insights']}")
    print(f"ç´§æ€¥æ´å¯Ÿ: {stats['critical_insights']}")
    print(f"å¹³å‡ç½®ä¿¡åº¦: {stats['avg_confidence_score']:.2f}")


if __name__ == "__main__":
    asyncio.run(main())