# core/orchestrator/intelligent_qa_orchestrator.py - é‡æ„ç®€åŒ–ç‰ˆ
"""
ğŸ§  Claudeé©±åŠ¨çš„æ™ºèƒ½é—®ç­”ç¼–æ’å™¨ - ç®€åŒ–ç‰ˆ
èŒè´£æ˜ç¡®ï¼šClaudeç†è§£ + APIè·å– + GPTè®¡ç®— + Claudeå›ç­”

é‡æ„æ”¹è¿›ï¼š
- åˆ é™¤å†—ä½™çš„ processor
- ç®€åŒ–æµç¨‹ï¼šClaude â†’ API â†’ è®¡ç®— â†’ å›ç­”
- ä½¿ç”¨ç»Ÿä¸€è®¡ç®—å™¨
- ä¿æŒå¯¹è¯ç®¡ç†åŠŸèƒ½
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import asyncio
import json
import time
import uuid
from dataclasses import dataclass, field
from enum import Enum
import hashlib
import traceback

# ğŸ¯ ç®€åŒ–åçš„æ ¸å¿ƒç»„ä»¶å¯¼å…¥
from core.analyzers.query_parser import (
    SmartQueryParser, create_smart_query_parser, QueryAnalysisResult,
    QueryComplexity, QueryType, BusinessScenario
)
from core.data_orchestration.smart_data_fetcher import (
    SmartDataFetcher, create_smart_data_fetcher,
    ExecutionResult as FetcherExecutionResult,
    DataQualityLevel as FetcherDataQualityLevel,
    ExecutionStatus as FetcherExecutionStatus
)
from core.analyzers.insight_generator import (
    InsightGenerator, create_insight_generator, BusinessInsight
)

# ğŸ†• ä½¿ç”¨ä½ çš„ç»Ÿä¸€è®¡ç®—å™¨
from utils.calculators.statistical_calculator import (
    UnifiedCalculator, create_unified_calculator, UnifiedCalculationResult,
    CalculationType
)

# å·¥å…·ç±»å’Œå…¶ä»–å¿…è¦ç»„ä»¶
from utils.helpers.date_utils import DateUtils, create_date_utils
from utils.formatters.financial_formatter import FinancialFormatter, create_financial_formatter
from utils.formatters.chart_generator import ChartGenerator, create_chart_generator, ChartType
from utils.formatters.report_generator import ReportGenerator, create_report_generator
from data.models.conversation import ConversationManager, create_conversation_manager
from data.connectors.database_connector import DatabaseConnector, create_database_connector

# AI å®¢æˆ·ç«¯å¯¼å…¥
from core.models.claude_client import ClaudeClient, CustomJSONEncoder
from core.models.openai_client import OpenAIClient
from config import Config as AppConfig

logger = logging.getLogger(__name__)


class ProcessingStrategy(Enum):
    """ç®€åŒ–çš„å¤„ç†ç­–ç•¥"""
    SIMPLE_DATA = "simple_data"  # ç®€å•æ•°æ®è·å–
    DATA_WITH_CALC = "data_with_calc"  # æ•°æ®è·å– + è®¡ç®—
    COMPREHENSIVE = "comprehensive"  # å…¨é¢åˆ†æ
    ERROR_HANDLING = "error_handling"  # é”™è¯¯å¤„ç†


@dataclass
class ProcessingResult:
    """å¤„ç†ç»“æœ - ä¿æŒå…¼å®¹æ€§"""
    session_id: str
    query_id: str
    success: bool
    response_text: str
    insights: List[BusinessInsight] = field(default_factory=list)
    key_metrics: Dict[str, Any] = field(default_factory=dict)
    visualizations: List[Dict[str, Any]] = field(default_factory=list)
    processing_strategy: ProcessingStrategy = ProcessingStrategy.SIMPLE_DATA
    processors_used: List[str] = field(default_factory=list)
    ai_collaboration_summary: Dict[str, Any] = field(default_factory=dict)
    confidence_score: float = 0.0
    data_quality_score: float = 0.0
    response_completeness: float = 0.0
    total_processing_time: float = 0.0
    ai_processing_time: float = 0.0
    data_fetching_time: float = 0.0
    processing_metadata: Dict[str, Any] = field(default_factory=dict)
    error_info: Optional[Dict[str, Any]] = None
    conversation_id: Optional[str] = None
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    query_analysis_snapshot: Optional[Dict[str, Any]] = None


class IntelligentQAOrchestrator:
    """ğŸ§  ç®€åŒ–ç‰ˆæ™ºèƒ½é—®ç­”ç¼–æ’å™¨"""

    _instance: Optional['IntelligentQAOrchestrator'] = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(IntelligentQAOrchestrator, cls).__new__(cls)
        return cls._instance

    def __init__(self, claude_client_instance: Optional[ClaudeClient] = None,
                 gpt_client_instance: Optional[OpenAIClient] = None,
                 db_connector_instance: Optional[DatabaseConnector] = None,
                 app_config_instance: Optional[AppConfig] = None):

        if hasattr(self, 'initialized') and self.initialized:
            return  # é¿å…é‡å¤åˆå§‹åŒ–

        # åŸºç¡€é…ç½®
        self.claude_client = claude_client_instance
        self.gpt_client = gpt_client_instance
        self.db_connector = db_connector_instance
        self.app_config = app_config_instance if app_config_instance is not None else AppConfig()
        self.config = self._load_orchestrator_config()

        self.initialized = False
        self._initialize_component_placeholders()

        # ç»Ÿè®¡å’Œç¼“å­˜
        self.orchestrator_stats = self._default_stats()
        self.result_cache: Dict[str, Dict[str, Any]] = {}
        self.cache_ttl = self.config.get('cache_ttl_seconds', 1800)

        logger.info("ç®€åŒ–ç‰ˆ IntelligentQAOrchestrator åˆ›å»ºå®Œæˆ")

    def _initialize_component_placeholders(self):
        """åˆå§‹åŒ–ç»„ä»¶å ä½ç¬¦ - ğŸ¯ å¤§å¹…ç®€åŒ–"""
        # ğŸ¯ æ ¸å¿ƒç»„ä»¶ - åªä¿ç•™å¿…è¦çš„
        self.query_parser: Optional[SmartQueryParser] = None
        self.data_fetcher: Optional[SmartDataFetcher] = None
        self.statistical_calculator: Optional[UnifiedCalculator] = None  # ğŸ†• ä½¿ç”¨ç»Ÿä¸€è®¡ç®—å™¨
        self.insight_generator: Optional[InsightGenerator] = None

        # å·¥å…·ç»„ä»¶
        self.date_utils: Optional[DateUtils] = None
        self.financial_formatter: Optional[FinancialFormatter] = None
        self.chart_generator: Optional[ChartGenerator] = None
        self.report_generator: Optional[ReportGenerator] = None
        self.conversation_manager: Optional[ConversationManager] = None

        # âŒ åˆ é™¤çš„å†—ä½™ç»„ä»¶
        # self.data_requirements_analyzer = None  # åŠŸèƒ½å·²åˆå¹¶åˆ°query_parser
        # self.financial_data_analyzer = None     # åŠŸèƒ½å·²åˆå¹¶åˆ°statistical_calculator
        # self.current_data_processor = None      # å®Œå…¨å†—ä½™
        # self.historical_analysis_processor = None  # è®¡ç®—é€»è¾‘å·²æå–åˆ°statistical_calculator
        # self.prediction_processor = None        # è®¡ç®—é€»è¾‘å·²æå–åˆ°statistical_calculator

    def _load_orchestrator_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½® - ä¿æŒä¸å˜"""
        cfg = {
            'max_processing_time': getattr(self.app_config, 'MAX_PROCESSING_TIME', 120),
            'enable_intelligent_caching': getattr(self.app_config, 'ENABLE_INTELLIGENT_CACHING', True),
            'min_confidence_threshold': getattr(self.app_config, 'MIN_CONFIDENCE_THRESHOLD', 0.6),
            'cache_ttl_seconds': getattr(self.app_config, 'CACHE_TTL', 1800),
            'claude_timeout': getattr(self.app_config, 'CLAUDE_TIMEOUT', 60),
            'gpt_timeout': getattr(self.app_config, 'GPT_TIMEOUT', 40),
            'DEBUG': getattr(self.app_config, 'DEBUG', False),
            'version': getattr(self.app_config, 'VERSION', '2.2.0-simplified')
        }

        # APIé…ç½®
        if hasattr(self.app_config, 'CLAUDE_API_KEY'):
            cfg['CLAUDE_API_KEY'] = self.app_config.CLAUDE_API_KEY
        if hasattr(self.app_config, 'OPENAI_API_KEY'):
            cfg['OPENAI_API_KEY'] = self.app_config.OPENAI_API_KEY
        if hasattr(self.app_config, 'DATABASE_CONFIG'):
            cfg['DATABASE_CONFIG'] = self.app_config.DATABASE_CONFIG

        # APIè¿æ¥å™¨é…ç½®
        api_connector_cfg = {}
        if hasattr(self.app_config, 'FINANCE_API_BASE_URL'):
            api_connector_cfg['base_url'] = self.app_config.FINANCE_API_BASE_URL
        if hasattr(self.app_config, 'FINANCE_API_KEY'):
            api_connector_cfg['api_key'] = self.app_config.FINANCE_API_KEY
        if api_connector_cfg:
            cfg['api_connector_config'] = api_connector_cfg

        return cfg

    async def initialize(self):
        """ğŸ¯ ç®€åŒ–ç‰ˆåˆå§‹åŒ–"""
        if self.initialized:
            logger.debug("Orchestrator already initialized.")
            return

        logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–ç®€åŒ–ç‰ˆæ™ºèƒ½ç¼–æ’å™¨...")
        start_init_time = time.time()

        try:
            # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
            if not self.claude_client and self.config.get('CLAUDE_API_KEY'):
                self.claude_client = ClaudeClient(api_key=self.config['CLAUDE_API_KEY'])
            if not self.gpt_client and self.config.get('OPENAI_API_KEY'):
                self.gpt_client = OpenAIClient(api_key=self.config['OPENAI_API_KEY'])

            # æ•°æ®åº“è¿æ¥å™¨
            if not self.db_connector and self.config.get('DATABASE_CONFIG'):
                db_cfg = self.config['DATABASE_CONFIG']
                if all(key in db_cfg for key in ['user', 'password', 'host', 'database']):
                    self.db_connector = create_database_connector(db_cfg)
                    logger.info("DatabaseConnector åˆå§‹åŒ–å®Œæˆ")

            # ğŸ¯ æ ¸å¿ƒç»„ä»¶åˆå§‹åŒ– - å¤§å¹…ç®€åŒ–
            self.query_parser = create_smart_query_parser(self.claude_client, self.gpt_client)

            fetcher_config = self.config.get('api_connector_config', {})
            self.data_fetcher = create_smart_data_fetcher(self.claude_client, self.gpt_client, fetcher_config)

            # ğŸ†• ä½¿ç”¨ç»Ÿä¸€è®¡ç®—å™¨
            self.statistical_calculator = create_unified_calculator(self.gpt_client, precision=6)

            self.insight_generator = create_insight_generator(self.claude_client, self.gpt_client)

            # å·¥å…·ç»„ä»¶
            self.date_utils = create_date_utils(self.claude_client)
            self.financial_formatter = create_financial_formatter()
            self.chart_generator = create_chart_generator()
            self.report_generator = create_report_generator()

            # å¯¹è¯ç®¡ç†å™¨
            if self.db_connector:
                self.conversation_manager = create_conversation_manager(self.db_connector)
                logger.info("ConversationManager åˆå§‹åŒ–å®Œæˆ")
            else:
                logger.warning("æ•°æ®åº“è¿æ¥å™¨ä¸å¯ç”¨ï¼ŒConversationManager ä½¿ç”¨å†…å­˜æ¨¡å¼")
                self.conversation_manager = ConversationManager(database_connector=None)

            self.initialized = True
            init_duration = time.time() - start_init_time
            logger.info(f"âœ… ç®€åŒ–ç‰ˆæ™ºèƒ½ç¼–æ’å™¨åˆå§‹åŒ–å®Œæˆ (è€—æ—¶: {init_duration:.2f}s)")

        except Exception as e:
            self.initialized = False
            logger.error(f"âŒ æ™ºèƒ½ç¼–æ’å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}\n{traceback.format_exc()}")

    # ================================================================
    # ğŸ¯ æ ¸å¿ƒæ–¹æ³•ï¼šç®€åŒ–ç‰ˆæ™ºèƒ½æŸ¥è¯¢å¤„ç†
    # ================================================================

    async def process_intelligent_query(self, user_query: str, user_id: int = 0,
                                        conversation_id: Optional[str] = None,
                                        preferences: Optional[Dict[str, Any]] = None) -> ProcessingResult:
        """ğŸ¯ ç®€åŒ–ç‰ˆæ™ºèƒ½æŸ¥è¯¢å¤„ç† - æ ¸å¿ƒæµç¨‹"""

        if not self.initialized:
            await self.initialize()
            if not self.initialized:
                return self._create_error_result("ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥", user_query)

        session_id = str(uuid.uuid4())
        query_id = f"q_{datetime.now().strftime('%Y%m%d%H%M%S%f')}_{hashlib.md5(user_query.encode('utf-8')).hexdigest()[:6]}"
        start_time = time.time()

        logger.info(f"ğŸ¯ QueryID: {query_id} - å¼€å§‹ç®€åŒ–ç‰ˆå¤„ç†: '{user_query[:50]}...'")
        self.orchestrator_stats['total_queries'] += 1

        # å¤„ç†å¯¹è¯ID
        conversation_id_for_db = self._parse_conversation_id(conversation_id)

        # ä¿å­˜ç”¨æˆ·è¾“å…¥
        user_message_saved = await self._save_user_message_if_needed(
            conversation_id_for_db, user_query, query_id)

        try:
            # ğŸ¯ ç®€åŒ–çš„å¤„ç†æµç¨‹
            timing = {}

            # 1ï¸âƒ£ Claude ç†è§£æŸ¥è¯¢
            start_t = time.time()
            query_analysis = await self._claude_understand_query(user_query, conversation_id_for_db)
            timing['parsing'] = time.time() - start_t

            # 2ï¸âƒ£ è·å–æ•°æ®
            start_t = time.time()
            data_result = await self._execute_data_acquisition(query_analysis)
            timing['data_fetching'] = time.time() - start_t

            # 3ï¸âƒ£ è®¡ç®—å¤„ç† (å¦‚æœéœ€è¦)
            start_t = time.time()
            calculation_result = None
            if query_analysis.needs_calculation:
                calculation_result = await self._execute_calculation(query_analysis, data_result)
            timing['calculation'] = time.time() - start_t

            # 4ï¸âƒ£ ç”Ÿæˆæ´å¯Ÿ
            start_t = time.time()
            insights = await self._generate_insights(data_result, calculation_result, query_analysis)
            timing['insights'] = time.time() - start_t

            # 5ï¸âƒ£ Claude ç”Ÿæˆæœ€ç»ˆå›ç­”
            start_t = time.time()
            response_text = await self._claude_generate_response(
                user_query, query_analysis, data_result, calculation_result, insights)
            timing['response_generation'] = time.time() - start_t

            # 6ï¸âƒ£ ç”Ÿæˆå¯è§†åŒ–
            start_t = time.time()
            visualizations = await self._generate_visualizations(data_result, calculation_result)
            timing['visualization'] = time.time() - start_t

            # æ„å»ºç»“æœ
            total_processing_time = time.time() - start_time
            confidence = self._calculate_confidence(query_analysis, data_result, calculation_result, insights)

            result = ProcessingResult(
                session_id=session_id,
                query_id=query_id,
                success=True,
                response_text=response_text,
                insights=insights,
                key_metrics=self._extract_key_metrics(data_result, calculation_result),
                visualizations=visualizations,
                processing_strategy=self._determine_strategy(query_analysis),
                processors_used=self._get_processors_used(query_analysis, calculation_result),
                ai_collaboration_summary=self._get_ai_summary(timing),
                confidence_score=confidence,
                data_quality_score=getattr(data_result, 'confidence_level', 0.8),
                response_completeness=self._calculate_completeness(data_result, calculation_result, insights),
                total_processing_time=total_processing_time,
                ai_processing_time=timing.get('parsing', 0) + timing.get('response_generation', 0),
                data_fetching_time=timing.get('data_fetching', 0),
                processing_metadata={
                    'query_complexity': query_analysis.complexity.value,
                    'query_type': query_analysis.query_type.value,
                    'step_times': timing,
                    'simplified_architecture': True
                },
                conversation_id=conversation_id,
                query_analysis_snapshot=query_analysis.to_dict()
            )

            # æ›´æ–°ç»Ÿè®¡å’Œç¼“å­˜
            self._update_stats(result)
            await self._cache_result_if_appropriate(result)

            # ä¿å­˜AIå“åº”
            if conversation_id_for_db and user_message_saved:
                await self._save_ai_response_if_needed(conversation_id_for_db, result, query_id)

            logger.info(f"âœ… QueryID: {query_id} - å¤„ç†æˆåŠŸï¼Œè€—æ—¶: {total_processing_time:.2f}s")
            return result

        except Exception as e:
            error_time = time.time() - start_time
            logger.error(f"âŒ QueryID: {query_id} - å¤„ç†å¤±è´¥: {str(e)}\n{traceback.format_exc()}")
            return await self._handle_error(session_id, query_id, user_query, str(e), error_time, conversation_id)

    # ================================================================
    # ğŸ¯ ç®€åŒ–åçš„æ ¸å¿ƒå¤„ç†æ–¹æ³•
    # ================================================================

    async def _claude_understand_query(self, user_query: str,
                                       conversation_id_for_db: Optional[int]) -> QueryAnalysisResult:
        """1ï¸âƒ£ Claude ç†è§£æŸ¥è¯¢"""
        logger.debug(f"ğŸ§  Claude ç†è§£æŸ¥è¯¢: {user_query[:50]}...")

        # è·å–å¯¹è¯ä¸Šä¸‹æ–‡
        context = {}
        if conversation_id_for_db and self.conversation_manager:
            try:
                context = self.conversation_manager.get_context(conversation_id_for_db)
            except Exception as e:
                logger.warning(f"è·å–å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")

        # è°ƒç”¨é‡æ„åçš„ query_parser
        query_analysis = await self.query_parser.parse_complex_query(user_query, context)

        if not query_analysis or query_analysis.confidence_score < 0.3:
            logger.warning("Claude ç†è§£å¤±è´¥ï¼Œä½¿ç”¨é™çº§è§£æ")
            # query_parser å†…éƒ¨å·²æœ‰é™çº§é€»è¾‘

        return query_analysis

    async def _execute_data_acquisition(self, query_analysis: QueryAnalysisResult) -> FetcherExecutionResult:
        """2ï¸âƒ£ æ‰§è¡Œæ•°æ®è·å–"""
        logger.debug(f"ğŸ“Š æ‰§è¡Œæ•°æ®è·å–: {len(query_analysis.api_calls_needed)} ä¸ªAPIè°ƒç”¨")

        if not self.data_fetcher:
            raise RuntimeError("SmartDataFetcher æœªåˆå§‹åŒ–")

        # æ„å»ºæ•°æ®è·å–è®¡åˆ’ (ç®€åŒ–ç‰ˆ)
        api_calls = query_analysis.api_calls_needed

        if not api_calls:
            # é»˜è®¤è·å–ç³»ç»Ÿæ•°æ®
            api_calls = [{"method": "get_system_data", "params": {}, "reason": "é»˜è®¤æ•°æ®è·å–"}]

        # æ‰§è¡ŒAPIè°ƒç”¨
        data_result = await self.data_fetcher.execute_api_calls_batch(api_calls)

        return data_result

    async def _execute_calculation(self, query_analysis: QueryAnalysisResult,
                                   data_result: FetcherExecutionResult) -> Optional[Dict[str, Any]]:
        """3ï¸âƒ£ æ‰§è¡Œè®¡ç®—å¤„ç†"""
        if not query_analysis.needs_calculation:
            return None

        logger.debug(f"ğŸ§® æ‰§è¡Œè®¡ç®—: {query_analysis.calculation_type}")

        if not self.statistical_calculator:
            logger.error("ç»Ÿä¸€è®¡ç®—å™¨æœªåˆå§‹åŒ–")
            return None

        try:
            # å‡†å¤‡è®¡ç®—æ•°æ®
            calc_data = self._prepare_calculation_data(data_result)
            calc_params = self._extract_calculation_params(query_analysis)

            # ğŸ†• ä½¿ç”¨ç»Ÿä¸€è®¡ç®—å™¨
            calc_result = await self.statistical_calculator.calculate(
                calculation_type=query_analysis.calculation_type,
                data=calc_data,
                params=calc_params
            )

            return {
                'calculation_result': calc_result,
                'calculation_type': query_analysis.calculation_type,
                'success': calc_result.success if calc_result else False,
                'confidence': calc_result.confidence if calc_result else 0.5
            }

        except Exception as e:
            logger.error(f"è®¡ç®—æ‰§è¡Œå¤±è´¥: {e}")
            return {
                'calculation_result': None,
                'calculation_type': query_analysis.calculation_type,
                'success': False,
                'error': str(e)
            }

    async def _generate_insights(self, data_result: FetcherExecutionResult,
                                 calculation_result: Optional[Dict[str, Any]],
                                 query_analysis: QueryAnalysisResult) -> List[BusinessInsight]:
        """4ï¸âƒ£ ç”Ÿæˆä¸šåŠ¡æ´å¯Ÿ"""
        logger.debug("ğŸ’¡ ç”Ÿæˆä¸šåŠ¡æ´å¯Ÿ")

        if not self.insight_generator:
            return []

        try:
            # å‡†å¤‡åˆ†æç»“æœ
            analysis_results = []

            if data_result:
                analysis_results.append(data_result)

            if calculation_result and calculation_result.get('success'):
                analysis_results.append(calculation_result['calculation_result'])

            if not analysis_results:
                return []

            # ç”Ÿæˆæ´å¯Ÿ
            insights, _ = await self.insight_generator.generate_comprehensive_insights(
                analysis_results=analysis_results,
                user_context={},
                focus_areas=self._determine_focus_areas(query_analysis)
            )

            return insights

        except Exception as e:
            logger.error(f"æ´å¯Ÿç”Ÿæˆå¤±è´¥: {e}")
            return []

    async def _claude_generate_response(self, user_query: str, query_analysis: QueryAnalysisResult,
                                        data_result: FetcherExecutionResult,
                                        calculation_result: Optional[Dict[str, Any]],
                                        insights: List[BusinessInsight]) -> str:
        """5ï¸âƒ£ Claude ç”Ÿæˆæœ€ç»ˆå›ç­”"""
        logger.debug("âœï¸ Claude ç”Ÿæˆæœ€ç»ˆå›ç­”")

        if not self.claude_client:
            return self._generate_fallback_response(user_query, data_result, calculation_result, insights)

        try:
            # æ„å»ºç»™Claudeçš„ä¸Šä¸‹æ–‡
            context_for_claude = {
                "user_query": user_query,
                "query_analysis": {
                    "type": query_analysis.query_type.value,
                    "complexity": query_analysis.complexity.value,
                    "confidence": query_analysis.confidence_score
                },
                "data_summary": self._summarize_data_for_claude(data_result),
                "calculation_summary": self._summarize_calculation_for_claude(calculation_result),
                "insights_summary": [
                    {"title": getattr(insight, 'title', ''), "summary": getattr(insight, 'summary', '')}
                    for insight in insights[:3]
                ]
            }

            prompt = f"""
ä½œä¸ºä¸“ä¸šçš„AIé‡‘èåˆ†æåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ä¸ºç”¨æˆ·ç”Ÿæˆä¸€ä¸ªå…¨é¢ã€å‡†ç¡®ã€æ˜“æ‡‚çš„ä¸­æ–‡å›ç­”ã€‚

ç”¨æˆ·æŸ¥è¯¢ï¼š"{user_query}"

åˆ†æä¸Šä¸‹æ–‡ï¼š
{json.dumps(context_for_claude, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆä¸€ä¸ªç»“æ„æ¸…æ™°çš„å›ç­”ï¼ŒåŒ…æ‹¬ï¼š
1. ç›´æ¥å›ç­”ç”¨æˆ·çš„æ ¸å¿ƒé—®é¢˜
2. å…³é”®æ•°æ®å’Œå‘ç°
3. é‡è¦çš„ä¸šåŠ¡æ´å¯Ÿ
4. å¦‚æœæœ‰è®¡ç®—ç»“æœï¼Œæ¸…æ¥šåœ°è§£é‡Šæ•°å­—çš„å«ä¹‰
5. å¿…è¦çš„å»ºè®®æˆ–åç»­è¡ŒåŠ¨

è¦æ±‚ï¼š
- ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€
- çªå‡ºæœ€é‡è¦çš„ä¿¡æ¯
- å¦‚æœæ•°æ®æœ‰é™æˆ–ä¸ç¡®å®šï¼Œè¯·è¯šå®è¯´æ˜
- å›ç­”é•¿åº¦æ§åˆ¶åœ¨300-800å­—
"""

            # è°ƒç”¨Claude
            response = await self.claude_client.generate_text(prompt, max_tokens=2000)

            if response and response.get('success'):
                return response.get('text', '').strip()
            else:
                logger.warning("Claude å›ç­”ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                return self._generate_fallback_response(user_query, data_result, calculation_result, insights)

        except Exception as e:
            logger.error(f"Claude å›ç­”ç”Ÿæˆå¼‚å¸¸: {e}")
            return self._generate_fallback_response(user_query, data_result, calculation_result, insights)

    # ================================================================
    # ğŸ› ï¸ è¾…åŠ©æ–¹æ³•
    # ================================================================

    def _prepare_calculation_data(self, data_result: FetcherExecutionResult) -> Dict[str, Any]:
        """å‡†å¤‡è®¡ç®—æ•°æ®"""
        if not data_result:
            return {}

        calc_data = {}

        # ä» processed_data æå–
        if hasattr(data_result, 'processed_data') and data_result.processed_data:
            calc_data.update(data_result.processed_data)

        # ä» fetched_data æå–
        if hasattr(data_result, 'fetched_data') and data_result.fetched_data:
            calc_data.update(data_result.fetched_data)

        return calc_data

    def _extract_calculation_params(self, query_analysis: QueryAnalysisResult) -> Dict[str, Any]:
        """æå–è®¡ç®—å‚æ•°"""
        params = {}

        # æ—¶é—´èŒƒå›´
        if query_analysis.time_range:
            params.update(query_analysis.time_range)

        # å¤„ç†å…ƒæ•°æ®
        if query_analysis.processing_metadata:
            params.update(query_analysis.processing_metadata)

        return params

    def _summarize_data_for_claude(self, data_result: FetcherExecutionResult) -> Dict[str, Any]:
        """ä¸ºClaudeæ€»ç»“æ•°æ®"""
        if not data_result:
            return {"status": "æ— æ•°æ®"}

        summary = {
            "status": "æ•°æ®è·å–æˆåŠŸ" if getattr(data_result, 'execution_status', None) else "æ•°æ®è·å–å¤±è´¥",
            "data_quality": getattr(data_result, 'confidence_level', 0.5),
            "data_sources": getattr(data_result, 'data_sources_used', [])
        }

        # æ·»åŠ å…³é”®æ•°æ®æ‘˜è¦
        if hasattr(data_result, 'processed_data') and data_result.processed_data:
            summary["key_data_points"] = len(data_result.processed_data)

        return summary

    def _summarize_calculation_for_claude(self, calculation_result: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """ä¸ºClaudeæ€»ç»“è®¡ç®—ç»“æœ"""
        if not calculation_result:
            return {"status": "æ— è®¡ç®—"}

        if not calculation_result.get('success'):
            return {"status": "è®¡ç®—å¤±è´¥", "error": calculation_result.get('error')}

        calc_res = calculation_result.get('calculation_result')
        if not calc_res:
            return {"status": "è®¡ç®—ç»“æœä¸ºç©º"}

        return {
            "status": "è®¡ç®—æˆåŠŸ",
            "calculation_type": calculation_result.get('calculation_type'),
            "confidence": calculation_result.get('confidence', 0.5),
            "has_detailed_results": bool(getattr(calc_res, 'detailed_results', None))
        }

    def _generate_fallback_response(self, user_query: str, data_result: FetcherExecutionResult,
                                    calculation_result: Optional[Dict[str, Any]],
                                    insights: List[BusinessInsight]) -> str:
        """ç”Ÿæˆé™çº§å›ç­”"""
        response_parts = ["æ ¹æ®ç³»ç»Ÿåˆ†æï¼š\n"]

        # æ•°æ®çŠ¶æ€
        if data_result and hasattr(data_result, 'execution_status'):
            response_parts.append(f"æ•°æ®è·å–çŠ¶æ€ï¼š{'æˆåŠŸ' if data_result.execution_status else 'éƒ¨åˆ†æˆåŠŸ'}")

        # è®¡ç®—ç»“æœ
        if calculation_result and calculation_result.get('success'):
            calc_res = calculation_result.get('calculation_result')
            if calc_res and hasattr(calc_res, 'primary_result'):
                response_parts.append(f"è®¡ç®—ç»“æœï¼š{calc_res.primary_result}")

        # æ´å¯Ÿ
        if insights:
            response_parts.append("\nå…³é”®æ´å¯Ÿï¼š")
            for i, insight in enumerate(insights[:2], 1):
                title = getattr(insight, 'title', f'æ´å¯Ÿ{i}')
                summary = getattr(insight, 'summary', '...')
                response_parts.append(f"{i}. {title}: {summary}")

        if len(response_parts) == 1:  # åªæœ‰å¼€å¤´
            response_parts.append("æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•æä¾›è¯¦ç»†åˆ†æã€‚è¯·ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚")

        return "\n".join(response_parts)

    def _determine_strategy(self, query_analysis: QueryAnalysisResult) -> ProcessingStrategy:
        """ç¡®å®šå¤„ç†ç­–ç•¥"""
        if query_analysis.needs_calculation:
            return ProcessingStrategy.DATA_WITH_CALC
        elif query_analysis.complexity in [QueryComplexity.COMPLEX, QueryComplexity.EXPERT]:
            return ProcessingStrategy.COMPREHENSIVE
        else:
            return ProcessingStrategy.SIMPLE_DATA

    def _get_processors_used(self, query_analysis: QueryAnalysisResult,
                             calculation_result: Optional[Dict[str, Any]]) -> List[str]:
        """è·å–ä½¿ç”¨çš„å¤„ç†å™¨"""
        processors = ["Claude", "SmartDataFetcher"]

        if query_analysis.needs_calculation and calculation_result:
            processors.append("UnifiedCalculator")

        return processors

    def _calculate_confidence(self, query_analysis: QueryAnalysisResult,
                              data_result: FetcherExecutionResult,
                              calculation_result: Optional[Dict[str, Any]],
                              insights: List[BusinessInsight]) -> float:
        """è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦"""
        confidence_factors = []

        # æŸ¥è¯¢ç†è§£ç½®ä¿¡åº¦
        confidence_factors.append(query_analysis.confidence_score)

        # æ•°æ®è´¨é‡
        if data_result:
            confidence_factors.append(getattr(data_result, 'confidence_level', 0.5))

        # è®¡ç®—ç½®ä¿¡åº¦
        if calculation_result:
            confidence_factors.append(calculation_result.get('confidence', 0.5))

        # æ´å¯Ÿè´¨é‡
        if insights:
            insight_confidence = sum(getattr(insight, 'confidence_score', 0.7) for insight in insights) / len(insights)
            confidence_factors.append(insight_confidence)

        return sum(confidence_factors) / len(confidence_factors) if confidence_factors else 0.5

    def _calculate_completeness(self, data_result: FetcherExecutionResult,
                                calculation_result: Optional[Dict[str, Any]],
                                insights: List[BusinessInsight]) -> float:
        """è®¡ç®—å›ç­”å®Œæ•´æ€§"""
        completeness = 0.0

        if data_result and hasattr(data_result, 'execution_status'):
            completeness += 0.4

        if calculation_result and calculation_result.get('success'):
            completeness += 0.3

        if insights:
            completeness += 0.3

        return min(completeness, 1.0)

    def _extract_key_metrics(self, data_result: FetcherExecutionResult,
                             calculation_result: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """æå–å…³é”®æŒ‡æ ‡"""
        metrics = {}

        # ä»è®¡ç®—ç»“æœæå–
        if calculation_result and calculation_result.get('success'):
            calc_res = calculation_result.get('calculation_result')
            if calc_res and hasattr(calc_res, 'detailed_results'):
                metrics.update(calc_res.detailed_results)

        # ä»æ•°æ®ç»“æœæå–åŸºç¡€æŒ‡æ ‡
        if data_result and hasattr(data_result, 'processed_data'):
            processed_data = data_result.processed_data
            if isinstance(processed_data, dict):
                # æå–ç³»ç»Ÿæ¦‚è§ˆæ•°æ®ä¸­çš„å…³é”®æŒ‡æ ‡
                for key, value in processed_data.items():
                    if isinstance(value, dict) and 'æ€»ä½™é¢' in value:
                        metrics.update({
                            'æ€»ä½™é¢': value.get('æ€»ä½™é¢'),
                            'æ€»å…¥é‡‘': value.get('æ€»å…¥é‡‘'),
                            'æ€»å‡ºé‡‘': value.get('æ€»å‡ºé‡‘')
                        })
                        break

        return metrics

    # ================================================================
    # ğŸ¯ ä¿ç•™çš„å¿…è¦æ–¹æ³• (ç®€åŒ–ç‰ˆ)
    # ================================================================

    def _parse_conversation_id(self, conversation_id: Optional[str]) -> Optional[int]:
        """è§£æå¯¹è¯ID"""
        if not conversation_id:
            return None
        try:
            return int(conversation_id)
        except ValueError:
            logger.warning(f"æ— æ•ˆçš„å¯¹è¯ID: {conversation_id}")
            return None

    async def _save_user_message_if_needed(self, conversation_id_for_db: Optional[int],
                                           user_query: str, query_id: str) -> bool:
        """ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        if not conversation_id_for_db or not self.conversation_manager:
            return False

        try:
            # ç®€å•çš„é‡å¤æ£€æŸ¥
            recent_messages = getattr(self.conversation_manager, 'get_recent_messages', lambda *args: [])(
                conversation_id_for_db, 2)

            # æ£€æŸ¥æœ€è¿‘çš„ç”¨æˆ·æ¶ˆæ¯æ˜¯å¦ç›¸åŒ
            for msg in recent_messages:
                if isinstance(msg, dict):
                    is_user = msg.get('is_user', False)
                    content = msg.get('content', '')
                    if is_user and content.strip() == user_query.strip():
                        return False  # è·³è¿‡é‡å¤ä¿å­˜

            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            self.conversation_manager.add_message(conversation_id_for_db, True, user_query)
            return True

        except Exception as e:
            logger.error(f"ä¿å­˜ç”¨æˆ·æ¶ˆæ¯å¤±è´¥: {e}")
            return False

    async def _save_ai_response_if_needed(self, conversation_id_for_db: int,
                                          result: ProcessingResult, query_id: str):
        """ä¿å­˜AIå“åº”ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        if not self.conversation_manager:
            return

        try:
            # ä¿å­˜AIå“åº”
            ai_message_id = self.conversation_manager.add_message(
                conversation_id_for_db, False, result.response_text)

            # ä¿å­˜å¯è§†åŒ–ï¼ˆå¦‚æœæ”¯æŒï¼‰
            if result.visualizations and hasattr(self.conversation_manager, 'add_visual'):
                for i, vis in enumerate(result.visualizations):
                    if isinstance(vis, dict):
                        self.conversation_manager.add_visual(
                            message_id=ai_message_id,
                            visual_type=vis.get('type', 'chart'),
                            visual_order=i,
                            title=vis.get('title', 'å›¾è¡¨'),
                            data=vis.get('data_payload', {})
                        )
        except Exception as e:
            logger.error(f"ä¿å­˜AIå“åº”å¤±è´¥: {e}")

    def _default_stats(self) -> Dict[str, Any]:
        """é»˜è®¤ç»Ÿè®¡"""
        return {
            'total_queries': 0,
            'successful_queries': 0,
            'failed_queries': 0,
            'avg_processing_time': 0.0,
            'avg_confidence_score': 0.0,
            'cache_hits': 0,
            'cache_misses': 0
        }

    def _update_stats(self, result: ProcessingResult):
        """æ›´æ–°ç»Ÿè®¡"""
        if result.success:
            self.orchestrator_stats['successful_queries'] += 1
        else:
            self.orchestrator_stats['failed_queries'] += 1

        # æ›´æ–°å¹³å‡å€¼
        total = self.orchestrator_stats['total_queries']
        if total > 0:
            current_avg_time = self.orchestrator_stats['avg_processing_time']
            self.orchestrator_stats['avg_processing_time'] = (
                    (current_avg_time * (total - 1) + result.total_processing_time) / total)

            current_avg_conf = self.orchestrator_stats['avg_confidence_score']
            self.orchestrator_stats['avg_confidence_score'] = (
                    (current_avg_conf * (total - 1) + result.confidence_score) / total)

    async def _cache_result_if_appropriate(self, result: ProcessingResult):
        """ç¼“å­˜ç»“æœï¼ˆå¦‚æœåˆé€‚ï¼‰"""
        if (self.config.get('enable_intelligent_caching', True) and
                result.success and result.confidence_score > 0.7):
            cache_key = f"result_{result.query_id}"
            self.result_cache[cache_key] = {
                'data': result,
                'timestamp': time.time()
            }

    def _create_error_result(self, error_msg: str, user_query: str,
                             query_id: str = None) -> ProcessingResult:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return ProcessingResult(
            session_id=str(uuid.uuid4()),
            query_id=query_id or f"error_{int(time.time())}",
            success=False,
            response_text=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æŸ¥è¯¢æ—¶é‡åˆ°é—®é¢˜ï¼š{error_msg}",
            processing_strategy=ProcessingStrategy.ERROR_HANDLING,
            processors_used=["ErrorHandler"],
            error_info={"message": error_msg, "query": user_query}
        )

    async def _handle_error(self, session_id: str, query_id: str, user_query: str,
                            error_msg: str, processing_time: float,
                            conversation_id: Optional[str]) -> ProcessingResult:
        """å¤„ç†é”™è¯¯"""
        self.orchestrator_stats['failed_queries'] += 1

        return ProcessingResult(
            session_id=session_id,
            query_id=query_id,
            success=False,
            response_text=f"å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯ã€‚æˆ‘ä»¬å·²è®°å½•æ­¤é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚",
            processing_strategy=ProcessingStrategy.ERROR_HANDLING,
            processors_used=["ErrorHandler"],
            total_processing_time=processing_time,
            error_info={"message": error_msg, "query": user_query},
            conversation_id=conversation_id
        )

    # ================================================================
    # ğŸ”§ æ¥å£æ–¹æ³• (ä¿æŒå…¼å®¹æ€§)
    # ================================================================

    def get_orchestrator_stats(self) -> Dict[str, Any]:
        """è·å–ç¼–æ’å™¨ç»Ÿè®¡"""
        stats = self.orchestrator_stats.copy()
        total = stats.get('total_queries', 0)
        if total > 0:
            stats['success_rate'] = stats.get('successful_queries', 0) / total
            stats['failure_rate'] = stats.get('failed_queries', 0) / total
        return stats

    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        if not self.initialized:
            try:
                await self.initialize()
            except Exception as e:
                return {
                    'status': 'unhealthy',
                    'reason': 'Initialization failed',
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }

        return {
            'status': 'healthy',
            'architecture': 'simplified',
            'version': self.config.get('version', '2.2.0-simplified'),
            'components': {
                'claude_available': self.claude_client is not None,
                'gpt_available': self.gpt_client is not None,
                'query_parser_ready': self.query_parser is not None,
                'data_fetcher_ready': self.data_fetcher is not None,
                'calculator_ready': self.statistical_calculator is not None,
                'insight_generator_ready': self.insight_generator is not None
            },
            'statistics': self.get_orchestrator_stats(),
            'timestamp': datetime.now().isoformat()
        }

    async def close(self):
        """å…³é—­ç¼–æ’å™¨"""
        logger.info("å…³é—­ç®€åŒ–ç‰ˆæ™ºèƒ½ç¼–æ’å™¨...")

        if self.data_fetcher and hasattr(self.data_fetcher, 'close'):
            await self.data_fetcher.close()

        if self.db_connector and hasattr(self.db_connector, 'close'):
            await self.db_connector.close()

        self.result_cache.clear()
        self.initialized = False

        logger.info("ç®€åŒ–ç‰ˆæ™ºèƒ½ç¼–æ’å™¨å·²å…³é—­")

    # ================================================================
    # ğŸ”§ ç¼ºå¤±çš„æ–¹æ³•å®ç°
    # ================================================================

    def _determine_focus_areas(self, query_analysis: QueryAnalysisResult) -> List[str]:
        """ç¡®å®šæ´å¯Ÿå…³æ³¨é¢†åŸŸ"""
        focus_areas = []

        query_type = query_analysis.query_type.value if query_analysis.query_type else ""
        business_scenario = query_analysis.business_scenario.value if query_analysis.business_scenario else ""

        if 'financial' in business_scenario or 'data_retrieval' in query_type:
            focus_areas.append('financial_health')

        if 'trend' in query_type or 'historical' in business_scenario:
            focus_areas.append('trend_analysis')

        if 'prediction' in query_type or 'future' in business_scenario:
            focus_areas.append('future_outlook')

        if 'user' in business_scenario:
            focus_areas.append('user_behavior')

        return focus_areas if focus_areas else ['general_analysis']

    def _get_ai_summary(self, timing: Dict[str, float]) -> Dict[str, Any]:
        """è·å–AIåä½œæ‘˜è¦"""
        return {
            'claude_used': self.claude_client is not None,
            'gpt_used': self.gpt_client is not None,
            'total_ai_time': timing.get('parsing', 0) + timing.get('response_generation', 0),
            'architecture': 'simplified_claude_dominant'
        }

    async def _generate_visualizations(self, data_result: FetcherExecutionResult,
                                       calculation_result: Optional[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå¯è§†åŒ–"""
        visualizations = []

        if not self.chart_generator:
            return visualizations

        try:
            # ä»æ•°æ®ç»“æœç”Ÿæˆå›¾è¡¨
            if data_result and hasattr(data_result, 'processed_data'):
                # ç”ŸæˆåŸºç¡€æ•°æ®å›¾è¡¨çš„é€»è¾‘
                pass

            # ä»è®¡ç®—ç»“æœç”Ÿæˆå›¾è¡¨
            if calculation_result and calculation_result.get('success'):
                calc_res = calculation_result.get('calculation_result')
                if calc_res and hasattr(calc_res, 'detailed_results'):
                    # ç”Ÿæˆè®¡ç®—ç»“æœå›¾è¡¨çš„é€»è¾‘
                    pass

        except Exception as e:
            logger.error(f"å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")

        return visualizations


# ================================================================
# ğŸ­ å·¥å‚å‡½æ•°å’Œå…¨å±€å®ä¾‹ç®¡ç†
# ================================================================

_orchestrator_instance: Optional[IntelligentQAOrchestrator] = None


def get_orchestrator(claude_client_instance: Optional[ClaudeClient] = None,
                     gpt_client_instance: Optional[OpenAIClient] = None,
                     db_connector_instance: Optional[DatabaseConnector] = None,
                     app_config_instance: Optional[AppConfig] = None) -> IntelligentQAOrchestrator:
    """è·å–ç¼–æ’å™¨å®ä¾‹"""
    global _orchestrator_instance

    if _orchestrator_instance is None:
        logger.info("åˆ›å»ºæ–°çš„ç®€åŒ–ç‰ˆæ™ºèƒ½ç¼–æ’å™¨å®ä¾‹")
        _orchestrator_instance = IntelligentQAOrchestrator(
            claude_client_instance, gpt_client_instance,
            db_connector_instance, app_config_instance
        )

    return _orchestrator_instance